[{"path":[]},{"path":"/CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"interest fostering open welcoming environment, contributors maintainers pledge making participation project community harassment-free experience everyone, regardless age, body size, disability, ethnicity, gender identity expression, level experience, nationality, personal appearance, race, religion, sexual identity orientation.","code":""},{"path":"/CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes creating positive environment include: Using welcoming inclusive language respectful differing viewpoints experiences Gracefully accepting constructive criticism Focusing best community Showing empathy towards community members Examples unacceptable behavior participants include: use sexualized language imagery unwelcome sexual attention advances Trolling, insulting/derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical electronic address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"/CONDUCT.html","id":"our-responsibilities","dir":"","previous_headings":"","what":"Our Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Project maintainers responsible clarifying standards acceptable behavior expected take appropriate fair corrective action response instances unacceptable behavior. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, ban temporarily permanently contributor behaviors deem inappropriate, threatening, offensive, harmful.","code":""},{"path":"/CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within project spaces public spaces individual representing project community. Examples representing project community include using official project e-mail address, posting via official social media account, acting appointed representative online offline event. Representation project may defined clarified project maintainers.","code":""},{"path":"/CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported contacting project team jacob.long@sc.edu. complaints reviewed investigated result response deemed necessary appropriate circumstances. project team obligated maintain confidentiality regard reporter incident. details specific enforcement policies may posted separately. Project maintainers follow enforce Code Conduct good faith may face temporary permanent repercussions determined members project’s leadership.","code":""},{"path":"/CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 1.4, available https://www.contributor-covenant.org/version/1/4/code--conduct/","code":""},{"path":"/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing","title":"Contributing","text":"Contributions jtools whether form bug fixes, issue reports, new code documentation improvement welcome. Please use Github issue tracker remotely possible. pull request please link open corresponding issue issue tracker.","code":""},{"path":"/CONTRIBUTING.html","id":"tests","dir":"","previous_headings":"","what":"Tests","title":"Contributing","text":"jtools uses testthat testing. Please try provide complete test coverage submitted code always check existing tests continue pass. aren’t familiar testthat writing tests general, please indicate pull request likely able add tests.","code":""},{"path":"/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"","what":"Code style","title":"Contributing","text":"Generally speaking, tidyverse style guide won’t steer wrong. specific things note, however: <- must used assignment. may reject pull requests using =. Avoid using periods function names separate words _ function names. function arguments, use periods separate words (_). convention designed consistent package clearly differentiate function arguments objects. prefer commented code, especially ’s ambiguity sections code first read.","code":""},{"path":"/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing","text":"contributing jtools must follow code conduct defined CONDUCT.md","code":""},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"/LICENSE.html","id":"0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"/LICENSE.html","id":"1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"/LICENSE.html","id":"2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"/LICENSE.html","id":"3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"/LICENSE.html","id":"4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"/LICENSE.html","id":"5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"/LICENSE.html","id":"6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"/LICENSE.html","id":"7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"/LICENSE.html","id":"8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"/LICENSE.html","id":"9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"/LICENSE.html","id":"10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"/LICENSE.html","id":"11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"/LICENSE.html","id":"12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"/LICENSE.html","id":"13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"/LICENSE.html","id":"14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"/LICENSE.html","id":"15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"/LICENSE.html","id":"16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"/LICENSE.html","id":"17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"/articles/effect_plot.html","id":"linear-model-example","dir":"Articles","previous_headings":"","what":"Linear model example","title":"Visualizing regression model predictions","text":"illustrate, let’s create model using mpg data ggplot2 package. data comprise information 234 cars several years. predicting gas mileage cities (cty) using several variables, including engine displacement (displ), model year (year), # engine cylinders (cyl), class car (class), fuel type (fl). ’s model summary courtesy summ: Let’s explore effect engine displacement gas mileage:  clear, predictions set continuous variables displ mean value. can tweaked via centered argument (“none” vector variables center options). Factor variables set base level logical variables set FALSE. plot, case, super illuminating. Let’s see uncertainty around line.  Now ’re getting somewhere. want get feel data distributed, can add known rug plot.  direct look model relates observed data, can use plot.points = TRUE argument.  Now ’re really learning something model—things aren’t looking great. seems like simple linear model may even appropriate. Let’s try fitting polynomial displ term capture curvature.  Okay, now ’re getting closer even though predicted line curiously grazes top observed data. panic, let’s introduce another feature might clear things .","code":"library(ggplot2) data(mpg) fit <- lm(cty ~ displ + year + cyl + class + fl, data = mpg[mpg$fl != \"c\",]) summ(fit) ## MODEL INFO: ## Observations: 233 ## Dependent Variable: cty ## Type: OLS linear regression  ##  ## MODEL FIT: ## F(12,220) = 107.19, p = 0.00 ## R² = 0.85 ## Adj. R² = 0.85  ##  ## Standard errors: OLS ## ------------------------------------------------------- ##                            Est.    S.E.   t val.      p ## --------------------- --------- ------- -------- ------ ## (Intercept)             -193.86   50.92    -3.81   0.00 ## displ                     -1.02    0.29    -3.53   0.00 ## year                       0.12    0.03     4.52   0.00 ## cyl                       -0.85    0.20    -4.26   0.00 ## classcompact              -2.81    1.00    -2.83   0.01 ## classmidsize              -2.95    0.97    -3.05   0.00 ## classminivan              -5.08    1.05    -4.82   0.00 ## classpickup               -5.89    0.92    -6.37   0.00 ## classsubcompact           -2.63    1.01    -2.61   0.01 ## classsuv                  -5.59    0.88    -6.33   0.00 ## fle                      -11.06    0.99   -11.13   0.00 ## flp                       -8.91    0.81   -11.03   0.00 ## flr                       -7.62    0.77    -9.96   0.00 ## ------------------------------------------------------- effect_plot(fit, pred = displ) effect_plot(fit, pred = displ, interval = TRUE) effect_plot(fit, pred = displ, interval = TRUE, rug = TRUE) effect_plot(fit, pred = displ, interval = TRUE, plot.points = TRUE) fit_poly <- lm(cty ~ poly(displ, 2) + year + cyl + class + fl, data = mpg) effect_plot(fit_poly, pred = displ, interval = TRUE, plot.points = TRUE)"},{"path":"/articles/effect_plot.html","id":"partial-residuals-plots","dir":"Articles","previous_headings":"","what":"Partial residuals plots","title":"Visualizing regression model predictions","text":"complex regressions like one running example, plotting observed data can sometimes relatively uninformative points seem place. typical effects plot shows predicted values cty across different values displ, included included lot predictors besides displ model may accounting variation. partial residual plots designed help . Using argument partial.residuals = TRUE, plotted instead observed data effects control variables accounted . words, value cty observed data based values displ model error. Let’s take look.  go! polynomial term displ looking much better now. tell previous plot without partial residuals shape predictions right, predicted line just high. partial residuals set controls value shifted observations (case) predictions . means model good job explaining away discrepancy can see clearly polynomial term displ works better linear main effect. can learn technique theory Fox Weisberg (2018). Another place generate partial residual plots Fox’s effects package.","code":"effect_plot(fit_poly, pred = displ, interval = TRUE, partial.residuals = TRUE)"},{"path":"/articles/effect_plot.html","id":"generalized-linear-models","dir":"Articles","previous_headings":"","what":"Generalized linear models","title":"Visualizing regression model predictions","text":"Plotting can even essential understands models like GLMs (e.g., logit, probit, poisson).","code":""},{"path":"/articles/effect_plot.html","id":"logit-and-probit","dir":"Articles","previous_headings":"Generalized linear models","what":"Logit and probit","title":"Visualizing regression model predictions","text":"’ll use bacteria data MASS package explore binary dependent variable models. data come study children bacterial illness provided either active drug placebo given extra encouragement take medicine doctor. conditions represented trt variable. Patients checked presence absence bacteria (y) every weeks (week). Let’s check effect time.  time goes , fewer patients test positive bacteria. Note probit models work way:","code":"library(MASS) data(bacteria) l_mod <- glm(y ~ trt + week, data = bacteria, family = binomial) summ(l_mod) ## MODEL INFO: ## Observations: 220 ## Dependent Variable: y ## Type: Generalized linear model ##   Family: binomial  ##   Link function: logit  ##  ## MODEL FIT: ## χ²(3) = 13.57, p = 0.00 ## Pseudo-R² (Cragg-Uhler) = 0.10 ## Pseudo-R² (McFadden) = 0.06 ## AIC = 211.81, BIC = 225.38  ##  ## Standard errors: MLE ## ------------------------------------------------ ##                      Est.   S.E.   z val.      p ## ----------------- ------- ------ -------- ------ ## (Intercept)          2.55   0.41     6.28   0.00 ## trtdrug             -1.11   0.43    -2.60   0.01 ## trtdrug+            -0.65   0.45    -1.46   0.14 ## week                -0.12   0.04    -2.62   0.01 ## ------------------------------------------------ effect_plot(l_mod, pred = week, interval = TRUE, y.label = \"% testing positive\") pr_mod <- update(l_mod, family = binomial(link = \"probit\")) effect_plot(pr_mod, pred = week, interval = TRUE, y.label = \"% testing positive\")"},{"path":"/articles/effect_plot.html","id":"poisson","dir":"Articles","previous_headings":"Generalized linear models","what":"Poisson","title":"Visualizing regression model predictions","text":"poisson example, ’ll use Insurance data MASS package. ’re predicting number car insurance claims people different combinations car type, region, age. Age ordered factor, ’ll convert continuous variable sake demonstration. Claims count variable, poisson distribution appropriate modeling approach. Okay, age significant predictor number claims. Note offset term, count ’re predicting like rate. , modeling many claims adjusting amount policyholders.  mean? Critical understanding scale outcome variable. offset, must pick value offset generate predictions . effect_plot, default, sets offset 1. means predictions see can interpreted percentage; every policyholder, 0.16 0.10 claims. can also see age goes , proportion policyholders claims goes . Now let’s take look observed data…  Oops! doesn’t look right, ? problem offset. age groups many policyholders others 1, set offset predictions. extreme version problem linear model previously, let’s use solution: partial residuals.  Now ’re getting somewhere. difficulty interpreting overlapping points. Let’s use jitter argument add random bit noise observation can see just many points clearly.  didn’t want alter height points, provided vector 0.1 (referring horizontal position) 0 (referring vertical position) jitter argument.","code":"library(MASS) data(Insurance) Insurance$age_n <- as.numeric(Insurance$Age) p_mod <- glm(Claims ~ District + Group + age_n, data = Insurance,              offset = log(Holders), family = poisson) summ(p_mod) ## MODEL INFO: ## Observations: 64 ## Dependent Variable: Claims ## Type: Generalized linear model ##   Family: poisson  ##   Link function: log  ##  ## MODEL FIT: ## χ²(7) = 184.71, p = 0.00 ## Pseudo-R² (Cragg-Uhler) = 0.94 ## Pseudo-R² (McFadden) = 0.33 ## AIC = 384.87, BIC = 402.14  ##  ## Standard errors: MLE ## ------------------------------------------------ ##                      Est.   S.E.   z val.      p ## ----------------- ------- ------ -------- ------ ## (Intercept)         -1.37   0.07   -20.16   0.00 ## District2            0.03   0.04     0.60   0.55 ## District3            0.04   0.05     0.76   0.45 ## District4            0.23   0.06     3.80   0.00 ## Group.L              0.43   0.05     8.71   0.00 ## Group.Q              0.00   0.04     0.11   0.91 ## Group.C             -0.03   0.03    -0.88   0.38 ## age_n               -0.18   0.02    -9.56   0.00 ## ------------------------------------------------ effect_plot(p_mod, pred = age_n, interval = TRUE) effect_plot(p_mod, pred = age_n, interval = TRUE, plot.points = TRUE) effect_plot(p_mod, pred = age_n, interval = TRUE, partial.residuals = TRUE) effect_plot(p_mod, pred = age_n, interval = TRUE, partial.residuals = TRUE,             jitter = c(0.1,0))"},{"path":"/articles/effect_plot.html","id":"categorical-predictors","dir":"Articles","previous_headings":"","what":"Categorical predictors","title":"Visualizing regression model predictions","text":"methods don’t work clearly predictor isn’t continuous. Luckily, effect_plot automatically handles cases offers number options visualizing effects categorical predictors. Using first example, predicting gas mileage, let’s focus class car predictor.  can clearly see diesel (“d”) associated best mileage far ethanol (“e”) worst little bit. can plot observed data types plots well:  seem bit far predictions. Let’s see partial residuals little line expectations.  Now things make little sense can see range possibilities within category accounting model year . Diesel particular seems spaced observations take overly seriously. Let’s also look bacteria example, using treatment type predictor interest.  Now can see receiving drug clearly superior placebo, drug plus encouragement better drug alone, ’s hardly better placebo. course, can also tell confidence intervals fairly wide, won’t say data tell us anything definitively besides superiority drug placebo. may also want use lines convey ordered nature predictor.","code":"effect_plot(fit, pred = fl, interval = TRUE) effect_plot(fit, pred = fl, interval = TRUE, plot.points = TRUE,             jitter = .2) effect_plot(fit, pred = fl, interval = TRUE, partial.residuals = TRUE,             jitter = .2) effect_plot(l_mod, pred = trt, interval = TRUE, y.label = \"% testing positive\") effect_plot(l_mod, pred = trt, interval = TRUE, y.label = \"% testing positive\",             cat.geom = \"line\")"},{"path":"/articles/summ.html","id":"summ","dir":"Articles","previous_headings":"","what":"summ","title":"Tools for summarizing and visualizing regression models","text":"sharing analyses colleagues unfamiliar R, found output generally clear . Things even worse wanted give information included summary like robust standard errors, scaled coefficients, VIFs since functions estimating don’t append typical regression table. creating output tables “hand” multiple occasions, thought best pack things reusable function: became summ. user-specified arguments except fitted model, output summ looks like : Like output, one somewhat opinionated — information shown perhaps everyone interested , may missing. , course, motivation behind creation function; didn’t like choices made R’s core team summary! ’s quick (comprehensive) list functionality supported summ: Summaries lm, glm, svyglm (survey), merMod (lme4), rq (quantreg) models. Variable scaling centering Robust standard errors (lm glm plus quantreg’s built-options rq models) Confidence intervals, VIFs, partial correlations (lm ) can optionally included output p-values can dropped output R^2 (lm, linear svyglm), pseudo-R^2 (glm, merMod), R^1 (rq), model fit statistics calculated reported. can also suppressed don’t want . Ability choose defaults many options using set_summ_defaults reduce need redundant typing interactive use. Model types supported lm, glm, svyglm, merMod, rq, though reviewed detail . Note: output vignette mimic looks R console, generating RMarkdown documents kableExtra installed, ’ll instead get prettier looking tables like : can force knitr give console style output setting chunk option render = 'normal_print'.","code":"# Fit model states <- as.data.frame(state.x77) fit <- lm(Income ~ Frost + Illiteracy + Murder, data = states) summ(fit) ## MODEL INFO: ## Observations: 50 ## Dependent Variable: Income ## Type: OLS linear regression  ##  ## MODEL FIT: ## F(3,46) = 4.05, p = 0.01 ## R² = 0.21 ## Adj. R² = 0.16  ##  ## Standard errors: OLS ## ---------------------------------------------------- ##                        Est.     S.E.   t val.      p ## ----------------- --------- -------- -------- ------ ## (Intercept)         5111.10   416.58    12.27   0.00 ## Frost                 -1.25     2.11    -0.59   0.56 ## Illiteracy          -610.71   213.14    -2.87   0.01 ## Murder                23.07    30.94     0.75   0.46 ## ---------------------------------------------------- summ(fit)"},{"path":"/articles/summ.html","id":"report-robust-standard-errors","dir":"Articles","previous_headings":"summ","what":"Report robust standard errors","title":"Tools for summarizing and visualizing regression models","text":"One problems originally motivated creation function desire efficiently report robust standard errors — easy enough experienced R user calculate robust standard errors, many simple ways include results regression table common likes Stata, SPSS, etc. Robust standard errors require user sandwich package installed. need loaded. multiple types robust standard errors may use, ranging “HC0” “HC5”. Per recommendation authors sandwich package, default “HC3” get set robust = TRUE. Stata’s default “HC1”, may want use goal replicate Stata analyses. toggle type robust errors, provide desired type argument robust. Robust standard errors can also calculated generalized linear models (.e., glm objects) though debate whether used models fit iteratively non-normal errors. case svyglm, standard errors package calculates already robust heteroskedasticity, argument robust ignored warning. may also specify cluster argument name variable input data vector clusters get cluster-robust standard errors.","code":"summ(fit, robust = \"HC1\") ## MODEL INFO: ## Observations: 50 ## Dependent Variable: Income ## Type: OLS linear regression  ##  ## MODEL FIT: ## F(3,46) = 4.05, p = 0.01 ## R² = 0.21 ## Adj. R² = 0.16  ##  ## Standard errors: Robust, type = HC1 ## ---------------------------------------------------- ##                        Est.     S.E.   t val.      p ## ----------------- --------- -------- -------- ------ ## (Intercept)         5111.10   492.45    10.38   0.00 ## Frost                 -1.25     2.62    -0.48   0.63 ## Illiteracy          -610.71   183.31    -3.33   0.00 ## Murder                23.07    33.90     0.68   0.50 ## ----------------------------------------------------"},{"path":"/articles/summ.html","id":"standardizedscaled-coefficients","dir":"Articles","previous_headings":"summ","what":"Standardized/scaled coefficients","title":"Tools for summarizing and visualizing regression models","text":"prefer use scaled coefficients order avoid dismissing effect “small” just units measure small. scaled betas used instead scale = TRUE. clear, since meaning “standardized beta” can vary depending talk , option mean-centers predictors well alter dependent variable whatsoever. want scale dependent variable , just add transform.response = TRUE argument. can also choose different number standard deviations divide standardization. Andrew Gelman proponent dividing 2 standard deviations; want things way, give argument n.sd = 2. Note achieved refitting model. model took long time fit initially, expect similarly long time refit .","code":"summ(fit, scale = TRUE) ## MODEL INFO: ## Observations: 50 ## Dependent Variable: Income ## Type: OLS linear regression  ##  ## MODEL FIT: ## F(3,46) = 4.05, p = 0.01 ## R² = 0.21 ## Adj. R² = 0.16  ##  ## Standard errors: OLS ## ---------------------------------------------------- ##                        Est.     S.E.   t val.      p ## ----------------- --------- -------- -------- ------ ## (Intercept)         4435.80    79.77    55.61   0.00 ## Frost                -65.19   109.69    -0.59   0.56 ## Illiteracy          -372.25   129.91    -2.87   0.01 ## Murder                85.18   114.22     0.75   0.46 ## ---------------------------------------------------- ##  ## Continuous predictors are mean-centered and scaled by 1 s.d. summ(fit, scale = TRUE, n.sd = 2) ## MODEL INFO: ## Observations: 50 ## Dependent Variable: Income ## Type: OLS linear regression  ##  ## MODEL FIT: ## F(3,46) = 4.05, p = 0.01 ## R² = 0.21 ## Adj. R² = 0.16  ##  ## Standard errors: OLS ## ---------------------------------------------------- ##                        Est.     S.E.   t val.      p ## ----------------- --------- -------- -------- ------ ## (Intercept)         4435.80    79.77    55.61   0.00 ## Frost               -130.38   219.37    -0.59   0.56 ## Illiteracy          -744.50   259.83    -2.87   0.01 ## Murder               170.36   228.43     0.75   0.46 ## ---------------------------------------------------- ##  ## Continuous predictors are mean-centered and scaled by 2 s.d."},{"path":"/articles/summ.html","id":"mean-centered-variables","dir":"Articles","previous_headings":"summ > Standardized/scaled coefficients","what":"Mean-centered variables","title":"Tools for summarizing and visualizing regression models","text":"vein standardization feature, can keep original scale still mean-centering predictors center = TRUE argument. scale, applied response variable unless transform.response = TRUE.","code":"summ(fit, center = TRUE) ## MODEL INFO: ## Observations: 50 ## Dependent Variable: Income ## Type: OLS linear regression  ##  ## MODEL FIT: ## F(3,46) = 4.05, p = 0.01 ## R² = 0.21 ## Adj. R² = 0.16  ##  ## Standard errors: OLS ## ---------------------------------------------------- ##                        Est.     S.E.   t val.      p ## ----------------- --------- -------- -------- ------ ## (Intercept)         4435.80    79.77    55.61   0.00 ## Frost                 -1.25     2.11    -0.59   0.56 ## Illiteracy          -610.71   213.14    -2.87   0.01 ## Murder                23.07    30.94     0.75   0.46 ## ---------------------------------------------------- ##  ## Continuous predictors are mean-centered."},{"path":"/articles/summ.html","id":"confidence-intervals","dir":"Articles","previous_headings":"summ","what":"Confidence intervals","title":"Tools for summarizing and visualizing regression models","text":"many cases, ’ll learn looking confidence intervals p-values. can request summ. can adjust width confidence intervals, default 95% CIs.","code":"summ(fit, confint = TRUE, digits = 3) ## MODEL INFO: ## Observations: 50 ## Dependent Variable: Income ## Type: OLS linear regression  ##  ## MODEL FIT: ## F(3,46) = 4.049, p = 0.012 ## R² = 0.209 ## Adj. R² = 0.157  ##  ## Standard errors: OLS ## -------------------------------------------------------------------- ##                         Est.        2.5%      97.5%   t val.       p ## ----------------- ---------- ----------- ---------- -------- ------- ## (Intercept)         5111.097    4272.572   5949.621   12.269   0.000 ## Frost                 -1.254      -5.502      2.993   -0.594   0.555 ## Illiteracy          -610.715   -1039.739   -181.691   -2.865   0.006 ## Murder                23.074     -39.206     85.354    0.746   0.460 ## -------------------------------------------------------------------- summ(fit, confint = TRUE, ci.width = .5) ## MODEL INFO: ## Observations: 50 ## Dependent Variable: Income ## Type: OLS linear regression  ##  ## MODEL FIT: ## F(3,46) = 4.05, p = 0.01 ## R² = 0.21 ## Adj. R² = 0.16  ##  ## Standard errors: OLS ## --------------------------------------------------------------- ##                        Est.       25%       75%   t val.      p ## ----------------- --------- --------- --------- -------- ------ ## (Intercept)         5111.10   4827.88   5394.31    12.27   0.00 ## Frost                 -1.25     -2.69      0.18    -0.59   0.56 ## Illiteracy          -610.71   -755.62   -465.81    -2.87   0.01 ## Murder                23.07      2.04     44.11     0.75   0.46 ## ---------------------------------------------------------------"},{"path":"/articles/summ.html","id":"removing-p-values","dir":"Articles","previous_headings":"summ","what":"Removing p values","title":"Tools for summarizing and visualizing regression models","text":"might also want drop p-values altogether. Remember can omit p-values regardless whether requested confidence intervals.","code":"summ(fit, confint = TRUE, pvals = FALSE) ## MODEL INFO: ## Observations: 50 ## Dependent Variable: Income ## Type: OLS linear regression  ##  ## MODEL FIT: ## F(3,46) = 4.05, p = 0.01 ## R² = 0.21 ## Adj. R² = 0.16  ##  ## Standard errors: OLS ## --------------------------------------------------------- ##                        Est.       2.5%     97.5%   t val. ## ----------------- --------- ---------- --------- -------- ## (Intercept)         5111.10    4272.57   5949.62    12.27 ## Frost                 -1.25      -5.50      2.99    -0.59 ## Illiteracy          -610.71   -1039.74   -181.69    -2.87 ## Murder                23.07     -39.21     85.35     0.75 ## ---------------------------------------------------------"},{"path":"/articles/summ.html","id":"generalized-and-mixed-models","dir":"Articles","previous_headings":"summ","what":"Generalized and Mixed models","title":"Tools for summarizing and visualizing regression models","text":"summ expanding range supported model types. glm natural extension cover use cases. exponential family models, especially logit Poisson, may interested getting exponentiated coefficients rather linear estimates. summ can handle ! Standard errors omitted odds ratio estimates since confidence intervals symmetrical. can also get summaries merMod objects, mixed models lme4 package. Note summary linear mixed models omit p-values default unless  package installed linear models. ’s clear-cut way derive p-values linear mixed models treating t-values like OLS models lead inflated Type 1 error rates. Confidence intervals better, perfect. Kenward-Roger calculated degrees freedom fairly good many circumstances used default  package installed. aware larger datasets, procedure can take long time. See documentation (?summ.merMod) info. also get estimated model R-squared mixed models using Nakagawa & Schielzeth (2013) procedure code adapted piecewiseSEM package.","code":"fitg <- glm(vs ~ drat + mpg, data = mtcars, family = binomial)  summ(fitg) ## MODEL INFO: ## Observations: 32 ## Dependent Variable: vs ## Type: Generalized linear model ##   Family: binomial  ##   Link function: logit  ##  ## MODEL FIT: ## χ²(2) = 18.51, p = 0.00 ## Pseudo-R² (Cragg-Uhler) = 0.59 ## Pseudo-R² (McFadden) = 0.42 ## AIC = 31.35, BIC = 35.75  ##  ## Standard errors: MLE ## ------------------------------------------------ ##                      Est.   S.E.   z val.      p ## ----------------- ------- ------ -------- ------ ## (Intercept)         -7.76   4.00    -1.94   0.05 ## drat                -0.56   1.33    -0.42   0.67 ## mpg                  0.48   0.20     2.38   0.02 ## ------------------------------------------------ summ(fitg, exp = TRUE) ## MODEL INFO: ## Observations: 32 ## Dependent Variable: vs ## Type: Generalized linear model ##   Family: binomial  ##   Link function: logit  ##  ## MODEL FIT: ## χ²(2) = 18.51, p = 0.00 ## Pseudo-R² (Cragg-Uhler) = 0.59 ## Pseudo-R² (McFadden) = 0.42 ## AIC = 31.35, BIC = 35.75  ##  ## Standard errors: MLE ## ------------------------------------------------------------ ##                     exp(Est.)   2.5%   97.5%   z val.      p ## ----------------- ----------- ------ ------- -------- ------ ## (Intercept)              0.00   0.00    1.09    -1.94   0.05 ## drat                     0.57   0.04    7.77    -0.42   0.67 ## mpg                      1.61   1.09    2.39     2.38   0.02 ## ------------------------------------------------------------ library(lme4) fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)  summ(fm1) ## MODEL INFO: ## Observations: 180 ## Dependent Variable: Reaction ## Type: Mixed effects linear regression  ##  ## MODEL FIT: ## AIC = 1755.63, BIC = 1774.79 ## Pseudo-R² (fixed effects) = 0.28 ## Pseudo-R² (total) = 0.80  ##  ## FIXED EFFECTS: ## --------------------------------------------------------- ##                       Est.   S.E.   t val.    d.f.      p ## ----------------- -------- ------ -------- ------- ------ ## (Intercept)         251.41   6.82    36.84   17.00   0.00 ## Days                 10.47   1.55     6.77   17.00   0.00 ## --------------------------------------------------------- ##  ## p values calculated using Satterthwaite d.f. ##  ## RANDOM EFFECTS: ## ------------------------------------ ##   Group      Parameter    Std. Dev.  ## ---------- ------------- ----------- ##  Subject    (Intercept)     24.74    ##  Subject       Days         5.92     ##  Residual                   25.59    ## ------------------------------------ ##  ## Grouping variables: ## --------------------------- ##   Group    # groups   ICC   ## --------- ---------- ------ ##  Subject      18      0.48  ## ---------------------------"},{"path":"/articles/summ.html","id":"svyglm","dir":"Articles","previous_headings":"summ > Generalized and Mixed models","what":"svyglm","title":"Tools for summarizing and visualizing regression models","text":"won’t run examples , svyglm models supported provide near-equivalent output see depending whether linear models generalized linear models.","code":""},{"path":"/articles/summ.html","id":"effect_plot","dir":"Articles","previous_headings":"","what":"effect_plot","title":"Tools for summarizing and visualizing regression models","text":"Sometimes really understand model telling , need see kind predictions give . , can use effect_plot, sounds like. separate vignette available explore can offer, ’s basic example linear model:  Now ’re really learning something model—looks like linear fit basically correct.","code":"effect_plot(fit, pred = Illiteracy, interval = TRUE, plot.points = TRUE)"},{"path":"/articles/summ.html","id":"plot_summs-and-plot_coefs","dir":"Articles","previous_headings":"","what":"plot_summs and plot_coefs","title":"Tools for summarizing and visualizing regression models","text":"comes time share findings, especially talks, tables often best way capture people’s attention quickly convey results. Variants known “forest plots” gaining popularity presenting regression results. , jtools provides plot_summs plot_coefs. plot_summs gives plotting interface summ allows multiple models simultaneously (assuming want apply arguments model). ’s basic, single-model use case.  Note intercept omitted default often distorts scale generally isn’t theoretical interest. can change behavior omit coefficients omit.coefs argument. example, differing scales variables makes kind difficult make quick assessment. problem, can just use tools built summ .  See? Now better idea uncertainty magnitude effect differs variables. Note default width confidence interval .95, can changed ci_level argument. can also add thicker band convey narrow interval using inner_ci_level argument:  Another compelling use case plot_summs robust standard errors ( just use robust argument).","code":"plot_summs(fit) plot_summs(fit, scale = TRUE) plot_summs(fit, scale = TRUE, inner_ci_level = .9)"},{"path":"/articles/summ.html","id":"plot-coefficient-uncertainty-as-normal-distributions","dir":"Articles","previous_headings":"plot_summs and plot_coefs","what":"Plot coefficient uncertainty as normal distributions","title":"Tools for summarizing and visualizing regression models","text":"commonly used regression models make assumption coefficient estimates asymptotically normally distributed, derive confidence intervals, p values, . Using plot.distributions = TRUE argument, can plot normal distribution along width specified interval convey uncertainty. also great didactic purposes. common OLS model assumes t distribution, decided visually sufficiently close opted try plot points along t distribution.","code":"plot_summs(fit, scale = TRUE, plot.distributions = TRUE, inner_ci_level = .9)"},{"path":"/articles/summ.html","id":"comparing-model-coefficients-visually","dir":"Articles","previous_headings":"plot_summs and plot_coefs","what":"Comparing model coefficients visually","title":"Tools for summarizing and visualizing regression models","text":"Comparison multiple models simultaneously another benefit plotting. especially true models nested. Let’s fit second model compare.  classic case adding new predictor causes another one’s estimate get much closer zero. plot.distributions = TRUE creates nice effect:  providing list summ arguments plot_summs, can compare results different summ arguments (item list corresponds one model; second list item second model, etc.). instance, can look standard errors differ different robust arguments:  plot_coefs similar plot_summs, offer features summ . tradeoff, though, allows model types summ — model supported tidy broom package work. provide unsupported model types plot_summs, just passes plot_coefs.","code":"fit2 <- lm(Income ~ Frost + Illiteracy + Murder + `HS Grad`,            data = states) plot_summs(fit, fit2, scale = TRUE) plot_summs(fit, fit2, scale = TRUE, plot.distributions = TRUE) plot_summs(fit, fit, fit, scale = TRUE, robust = list(FALSE, \"HC0\", \"HC3\"),            model.names = c(\"OLS\", \"HC0\", \"HC3\"))"},{"path":"/articles/summ.html","id":"table-output-for-word-and-rmarkdown-documents","dir":"Articles","previous_headings":"","what":"Table output for Word and RMarkdown documents","title":"Tools for summarizing and visualizing regression models","text":"Sometimes really want table, can’t standard R output. , can use export_summs. wrapper around huxtable’s huxreg function give nice looking output used RMarkdown documents , requested, printed Word file. latter case, complicated models often need fine-tuning Word, gets started. Like plot_summs, export_summs designed give features available summ, can request things like robust standard errors variable scaling. ’s example expect document like one: using RMarkdown, set results = 'asis' chunk export_summs get right formatting whatever type output document (HTML, PDF, etc.) format error statistics, simply put statistics desired curly braces wherever want character string. example, want standard error parentheses, argument \"({std.error})\", default. ideas: \"({statistic})\", gives test statistic parentheses. \"({statistic}, p = {p.value})\", gives test statistic followed “p =” p value parentheses. Note ’ll pay special attention rounding keep cells sufficiently narrow. \"[{conf.low}, {conf.high}]\", gives confidence interval standard bracket notation. also explicitly write confidence level, e.g., \"95% CI [{conf.low}, {conf.high}]\". ’s example confidence intervals instead standard errors: ’s lot customization ’m covering : Renaming columns, renaming/excluding coefficients, realigning errors, . want save Word doc, use .file argument (requires officer flextable packages): can likewise export PDF (\"PDF\"), HTML (\"HTML\"), Excel format (\"xlsx\").","code":"export_summs(fit, fit2, scale = TRUE) export_summs(fit, fit2, scale = TRUE,              error_format = \"[{conf.low}, {conf.high}]\") export_summs(fit, fit2, scale = TRUE, to.file = \"docx\", file.name = \"test.docx\")"},{"path":[]},{"path":"/articles/summ.html","id":"adding-and-removing-written-output","dir":"Articles","previous_headings":"Other options","what":"Adding and removing written output","title":"Tools for summarizing and visualizing regression models","text":"Much output summ can removed several pieces information hood users can ask . remove written output beginning, set model.info = FALSE /model.fit = FALSE.","code":"summ(fit, model.info = FALSE, model.fit = FALSE) ## Standard errors: OLS ## ---------------------------------------------------- ##                        Est.     S.E.   t val.      p ## ----------------- --------- -------- -------- ------ ## (Intercept)         5111.10   416.58    12.27   0.00 ## Frost                 -1.25     2.11    -0.59   0.56 ## Illiteracy          -610.71   213.14    -2.87   0.01 ## Murder                23.07    30.94     0.75   0.46 ## ----------------------------------------------------"},{"path":"/articles/summ.html","id":"choose-how-many-digits-past-the-decimal-to-round-to","dir":"Articles","previous_headings":"Other options","what":"Choose how many digits past the decimal to round to","title":"Tools for summarizing and visualizing regression models","text":"digits = argument, can decide precise want outputted numbers . often inappropriate distracting report quantities many digits past decimal due inability measure precisely interpret applied settings. cases, may necessary use digits due way measures calculated. default argument digits = 2. can pre-set number digits want printed jtools functions jtools-digits option. Note return object non-rounded values wish use later.","code":"summ(fit, model.info = FALSE, digits = 5) ## MODEL FIT: ## F(3,46) = 4.04857, p = 0.01232 ## R² = 0.20888 ## Adj. R² = 0.15729  ##  ## Standard errors: OLS ## --------------------------------------------------------------- ##                           Est.        S.E.     t val.         p ## ----------------- ------------ ----------- ---------- --------- ## (Intercept)         5111.09665   416.57608   12.26930   0.00000 ## Frost                 -1.25407     2.11012   -0.59432   0.55521 ## Illiteracy          -610.71471   213.13769   -2.86535   0.00626 ## Murder                23.07403    30.94034    0.74576   0.45961 ## --------------------------------------------------------------- summ(fit, model.info = FALSE, digits = 1) ## MODEL FIT: ## F(3,46) = 4.0, p = 0.0 ## R² = 0.2 ## Adj. R² = 0.2  ##  ## Standard errors: OLS ## ------------------------------------------------- ##                       Est.    S.E.   t val.     p ## ----------------- -------- ------- -------- ----- ## (Intercept)         5111.1   416.6     12.3   0.0 ## Frost                 -1.3     2.1     -0.6   0.6 ## Illiteracy          -610.7   213.1     -2.9   0.0 ## Murder                23.1    30.9      0.7   0.5 ## ------------------------------------------------- options(\"jtools-digits\" = 2) summ(fit, model.info = FALSE) ## MODEL FIT: ## F(3,46) = 4.05, p = 0.01 ## R² = 0.21 ## Adj. R² = 0.16  ##  ## Standard errors: OLS ## ---------------------------------------------------- ##                        Est.     S.E.   t val.      p ## ----------------- --------- -------- -------- ------ ## (Intercept)         5111.10   416.58    12.27   0.00 ## Frost                 -1.25     2.11    -0.59   0.56 ## Illiteracy          -610.71   213.14    -2.87   0.01 ## Murder                23.07    30.94     0.75   0.46 ## ---------------------------------------------------- j <- summ(fit, digits = 3)  j$coeftable ##                    Est.       S.E.     t val.            p ## (Intercept) 5111.096650 416.576083 12.2692993 4.146240e-16 ## Frost         -1.254074   2.110117 -0.5943151 5.552133e-01 ## Illiteracy  -610.714712 213.137691 -2.8653529 6.259724e-03 ## Murder        23.074026  30.940339  0.7457587 4.596073e-01"},{"path":"/articles/summ.html","id":"set-default-arguments-to-summ","dir":"Articles","previous_headings":"Other options","what":"Set default arguments to summ","title":"Tools for summarizing and visualizing regression models","text":"may like options afforded summ may like inconvenience typing . streamline sessions, can use set_summ_defaults function avoid redundant typing. works like : , 2 digits output, p values displayed, “HC3” sandwich robust standard errors summ output rest R session. can also use .RProfile, remember included scripts code runs every computer every session. options can toggled via set_summ_defaults: digits model.info model.fit pvals robust confint ci.width vifs conf.method (merMod models )","code":"set_summ_defaults(digits = 2, pvals = FALSE, robust = \"HC3\")"},{"path":"/articles/summ.html","id":"calculate-and-report-variance-inflation-factors-vif","dir":"Articles","previous_headings":"Other options","what":"Calculate and report variance inflation factors (VIF)","title":"Tools for summarizing and visualizing regression models","text":"multicollinearity concern, can useful VIFs reported alongside variable. can particularly helpful model comparison checking impact newly-added variables. get VIFs reported output table, just set vifs = TRUE. many standards researchers apply deciding whether VIF large. domains, VIF 2 worthy suspicion. Others set bar higher, 5 10. Others still say shouldn’t pay attention . Ultimately, main thing consider small effects likely “drowned ” higher VIFs, may just natural, unavoidable fact model.","code":"summ(fit, vifs = TRUE) ## MODEL INFO: ## Observations: 50 ## Dependent Variable: Income ## Type: OLS linear regression  ##  ## MODEL FIT: ## F(3,46) = 4.05, p = 0.01 ## R² = 0.21 ## Adj. R² = 0.16  ##  ## Standard errors: OLS ## ----------------------------------------------------------- ##                        Est.     S.E.   t val.      p    VIF ## ----------------- --------- -------- -------- ------ ------ ## (Intercept)         5111.10   416.58    12.27   0.00        ## Frost                 -1.25     2.11    -0.59   0.56   1.85 ## Illiteracy          -610.71   213.14    -2.87   0.01   2.60 ## Murder                23.07    30.94     0.75   0.46   2.01 ## -----------------------------------------------------------"},{"path":"/articles/svycor.html","id":"basic-use","dir":"Articles","previous_headings":"","what":"Basic use","title":"Calculate correlations and correlation tables with complex survey data","text":"necessary arguments different using svyvar. Specify, using equation, variables (design) include. doesn’t matter side equation variables . can specify digits = argument many digits past decimal point printed. arguments normally pass svyvar used well, though cases may affect output.","code":"svycor(~api00 + api99, design = dstrat) api00 api99 api00  1.00  0.98 api99  0.98  1.00 svycor(~api00 + api99, design = dstrat, digits = 4) api00  api99 api00 1.0000 0.9759 api99 0.9759 1.0000"},{"path":"/articles/svycor.html","id":"statistical-significance-tests","dir":"Articles","previous_headings":"","what":"Statistical significance tests","title":"Calculate correlations and correlation tables with complex survey data","text":"One thing survey won’t give p values null hypothesis \\(r = 0\\). first blush finding p value might seem like simple procedure, complex surveys almost always violate important distributional assumptions go along simple hypothesis tests correlation coefficient. clear consensus appropriate way conduct hypothesis tests context, due part fact analyses complex surveys occurs context multiple regression rather simple bivariate cases. sig.stats = TRUE, svycor use wtd.cor function weights package conduct hypothesis tests. p values derived bootstrap procedure weights define sampling probability. bootn = argument given wtd.cor define number simulations run. can significantly increase running time large samples /large numbers simulations. mean1 argument tells wtd.cor whether treat sample size number observations survey design (number rows data frame) sum weights. Usually, former desired, default value mean1 TRUE. using sig.stats = TRUE, correlation parameter estimates come bootstrap procedure rather simpler method based survey-weighted covariance matrix sig.stats = FALSE. saving output function, can extract non-rounded coefficients, p values, standard errors.","code":"svycor(~api00 + api99, design = dstrat, digits = 4, sig.stats = TRUE, bootn = 2000, mean1 = TRUE) api00   api99   api00 1       0.9759* api99 0.9759* 1 c <- svycor(~api00 + api99, design = dstrat, digits = 4, sig.stats = TRUE, bootn = 2000, mean1 = TRUE)  c$cors api00     api99 api00 1.0000000 0.9759047 api99 0.9759047 1.0000000 c$p.values api00 api99 api00     0     0 api99     0     0 c$std.err api00       api99 api00 0.000000000 0.003634155 api99 0.003634155 0.000000000"},{"path":"/articles/svycor.html","id":"technical-details","dir":"Articles","previous_headings":"","what":"Technical details","title":"Calculate correlations and correlation tables with complex survey data","text":"heavy lifting behind scenes done svyvar, output may realize also calculates covariance. save svyvar object, can see ’s meets eye. know , ’s just matter using R’s cov2cor function cleaning output. Now get rid covariance matrix… svycor print method, won’t see many digits past decimal point. can extract un-rounded matrix, however.","code":"svyvar(~api00 + api99, design = dstrat) variance     SE api00    15191 1255.7 api99    16518 1318.4 var <- svyvar(~api00 + api99, design = dstrat) var <- as.matrix(var) var api00    api99 api00 15190.59 15458.83 api99 15458.83 16518.24 attr(,\"var\")         api00   api00   api99   api99 api00 1576883 1580654 1580654 1561998 api00 1580654 1630856 1630856 1657352 api99 1580654 1630856 1630856 1657352 api99 1561998 1657352 1657352 1738266 attr(,\"statistic\") [1] \"variance\" cor <- cov2cor(var) cor api00     api99 api00 1.0000000 0.9759047 api99 0.9759047 1.0000000 attr(,\"var\")         api00   api00   api99   api99 api00 1576883 1580654 1580654 1561998 api00 1580654 1630856 1630856 1657352 api99 1580654 1630856 1630856 1657352 api99 1561998 1657352 1657352 1738266 attr(,\"statistic\") [1] \"variance\" cor <- cor[1:nrow(cor), 1:nrow(cor)] cor api00     api99 api00 1.0000000 0.9759047 api99 0.9759047 1.0000000 out <- svycor(~api99 + api00, design = dstrat) out$cors api99     api00 api99 1.0000000 0.9759047 api00 0.9759047 1.0000000"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jacob . Long. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Long JA (2022). jtools: Analysis Presentation Social Scientific Data. R package version 2.2.0, https://cran.r-project.org/package=jtools.","code":"@Manual{jtools,   title = {jtools: Analysis and Presentation of Social Scientific Data},   author = {Jacob A. Long},   year = {2022},   note = {R package version 2.2.0},   url = {https://cran.r-project.org/package=jtools}, }"},{"path":"/index.html","id":"jtools-","dir":"","previous_headings":"","what":"Analysis and Presentation of Social Scientific Data","title":"Analysis and Presentation of Social Scientific Data","text":"package consists series functions created author (Jacob) automate otherwise tedious research tasks. juncture, unifying theme efficient presentation regression analyses. number functions programming statistical purposes well. Support survey package’s svyglm objects well weighted regressions common theme throughout. Notice: jtools version 2.0.0, functions dealing interactions (e.g., interact_plot(), sim_slopes(), johnson_neyman()) moved new package, aptly named interactions.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Analysis and Presentation of Social Scientific Data","text":"stable version, simply install CRAN. want latest features bug fixes can download Github. need devtools installed don’t already: install package Github. also check dev branch repository latest greatest changes, also latest greatest bugs. see features roadmap, check issues section repository, especially “enhancement” tag.","code":"install.packages(\"jtools\") install.packages(\"devtools\") devtools::install_github(\"jacob-long/jtools\")"},{"path":"/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Analysis and Presentation of Social Scientific Data","text":"’s synopsis current functions package:","code":""},{"path":"/index.html","id":"console-regression-summaries-summ","dir":"","previous_headings":"Usage","what":"Console regression summaries (summ())","title":"Analysis and Presentation of Social Scientific Data","text":"summ() replacement summary() provides user several options formatting regression summaries. supports glm, svyglm, merMod objects input well. supports calculation reporting robust standard errors via sandwich package. Basic use: several conveniences, like re-fitting model scaled variables (scale = TRUE). option leave outcome variable original scale (transform.response = TRUE), default scaled models. ’m fan Andrew Gelman’s 2 SD standardization method, can specify many standard deviations like rescale (n.sd = 2). can also get variance inflation factors (VIFs) partial/semipartial (AKA part) correlations. Partial correlations available OLS models. may also substitute confidence intervals place standard errors can choose whether show p values. Cluster-robust standard errors: course, summ() like summary() best-suited interactive use. comes sharing results others, want sharper output probably graphics. jtools options , .","code":"data(movies) fit <- lm(metascore ~ budget + us_gross + year, data = movies) summ(fit) #> MODEL INFO: #> Observations: 831 (10 missing obs. deleted) #> Dependent Variable: metascore #> Type: OLS linear regression  #>  #> MODEL FIT: #> F(3,827) = 26.23, p = 0.00 #> R² = 0.09 #> Adj. R² = 0.08  #>  #> Standard errors: OLS #> -------------------------------------------------- #>                      Est.     S.E.   t val.      p #> ----------------- ------- -------- -------- ------ #> (Intercept)         52.06   139.67     0.37   0.71 #> budget              -0.00     0.00    -5.89   0.00 #> us_gross             0.00     0.00     7.61   0.00 #> year                 0.01     0.07     0.08   0.94 #> -------------------------------------------------- summ(fit, scale = TRUE, vifs = TRUE, part.corr = TRUE, confint = TRUE, pvals = FALSE) #> MODEL INFO: #> Observations: 831 (10 missing obs. deleted) #> Dependent Variable: metascore #> Type: OLS linear regression  #>  #> MODEL FIT: #> F(3,827) = 26.23, p = 0.00 #> R² = 0.09 #> Adj. R² = 0.08  #>  #> Standard errors: OLS #> ------------------------------------------------------------------------------ #>                      Est.    2.5%   97.5%   t val.    VIF   partial.r   part.r #> ----------------- ------- ------- ------- -------- ------ ----------- -------- #> (Intercept)         63.01   61.91   64.11   112.23                             #> budget              -3.78   -5.05   -2.52    -5.89   1.31       -0.20    -0.20 #> us_gross             5.28    3.92    6.64     7.61   1.52        0.26     0.25 #> year                 0.05   -1.18    1.28     0.08   1.24        0.00     0.00 #> ------------------------------------------------------------------------------ #>  #> Continuous predictors are mean-centered and scaled by 1 s.d. data(\"PetersenCL\", package = \"sandwich\") fit2 <- lm(y ~ x, data = PetersenCL) summ(fit2, robust = \"HC3\", cluster = \"firm\") #> MODEL INFO: #> Observations: 5000 #> Dependent Variable: y #> Type: OLS linear regression  #>  #> MODEL FIT: #> F(1,4998) = 1310.74, p = 0.00 #> R² = 0.21 #> Adj. R² = 0.21  #>  #> Standard errors: Cluster-robust, type = HC3 #> ----------------------------------------------- #>                     Est.   S.E.   t val.      p #> ----------------- ------ ------ -------- ------ #> (Intercept)         0.03   0.07     0.44   0.66 #> x                   1.03   0.05    20.36   0.00 #> -----------------------------------------------"},{"path":"/index.html","id":"latex--word--and-rmarkdown-friendly-regression-summary-tables-export_summs","dir":"","previous_headings":"Usage","what":"LaTeX-, Word-, and RMarkdown-friendly regression summary tables (export_summs())","title":"Analysis and Presentation of Social Scientific Data","text":"tabular output, export_summs() interface huxtable package’s huxreg() function preserves niceties summ(), particularly facilities robust standard errors standardization. also concatenates multiple models single table. RMarkdown documents, using export_summs() chunk option results = 'asis' give nice-looking tables HTML PDF output. Using .word = TRUE argument create Microsoft Word document table .","code":"fit <- lm(metascore ~ log(budget), data = movies) fit_b <- lm(metascore ~ log(budget) + log(us_gross), data = movies) fit_c <- lm(metascore ~ log(budget) + log(us_gross) + runtime, data = movies) coef_names <- c(\"Budget\" = \"log(budget)\", \"US Gross\" = \"log(us_gross)\",                 \"Runtime (Hours)\" = \"runtime\", \"Constant\" = \"(Intercept)\") export_summs(fit, fit_b, fit_c, robust = \"HC3\", coefs = coef_names) #> Registered S3 methods overwritten by 'broom': #>   method            from   #>   tidy.glht         jtools #>   tidy.summary.glht jtools"},{"path":"/index.html","id":"plotting-regression-summaries-plot_coefs-and-plot_summs","dir":"","previous_headings":"Usage","what":"Plotting regression summaries (plot_coefs() and plot_summs())","title":"Analysis and Presentation of Social Scientific Data","text":"Another way get quick gist regression analysis plot values coefficients corresponding uncertainties plot_summs() (closely related plot_coefs()). Like export_summs(), can still get scaled models robust standard errors.  since get ggplot object return, can tweak theme wish. Another way visualize uncertainty coefficients via plot.distributions argument.  show 95% interval width normal distribution estimate. plot_coefs() works much way, without support summ() arguments like robust scale. enables wider range models support broom package summ().","code":"coef_names <- coef_names[1:3] # Dropping intercept for plots plot_summs(fit, fit_b, fit_c, robust = \"HC3\", coefs = coef_names) plot_summs(fit_c, robust = \"HC3\", coefs = coef_names, plot.distributions = TRUE)"},{"path":"/index.html","id":"plotting-model-predictions-effect_plot","dir":"","previous_headings":"Usage","what":"Plotting model predictions (effect_plot())","title":"Analysis and Presentation of Social Scientific Data","text":"Sometimes best way understand model look predictions generates. Rather look coefficients, effect_plot() lets plot predictions across values predictor variable alongside observed data.  new feature version 2.0.0 lets plot partial residuals instead raw observed data, allowing assess model quality accounting effects control variables.  Categorical predictors, polynomial terms, (G)LM(M)s, weighted data, much supported.","code":"effect_plot(fit_c, pred = runtime, interval = TRUE, plot.points = TRUE) #> Using data movies from global environment. This could #> cause incorrect results if movies has been altered since #> the model was fit. You can manually provide the data to #> the \"data =\" argument.  #> Warning: Removed 10 rows containing missing values #> (geom_point). effect_plot(fit_c, pred = runtime, interval = TRUE, partial.residuals = TRUE) #> Using data movies from global environment. This could #> cause incorrect results if movies has been altered since #> the model was fit. You can manually provide the data to #> the \"data =\" argument."},{"path":"/index.html","id":"other-stuff","dir":"","previous_headings":"Usage","what":"Other stuff","title":"Analysis and Presentation of Social Scientific Data","text":"several things might interest . gscale(): Scale /mean-center data, including svydesign objects scale_mod() center_mod(): Re-fit models scaled /mean-centered data wgttest() pf_sv_test(), combined weights_tests(): Test ignorability sample weights regression models svycor(): Generate correlation matrices svydesign objects theme_apa(): mostly APA-compliant ggplot2 theme theme_nice(): nice ggplot2 theme add_gridlines() drop_gridlines(): ggplot2 theme-changing convenience functions make_predictions(): easy way generate hypothetical predicted data regression model plotting purposes. Details arguments can accessed via R documentation (?functionname). now vignettes documenting just everything can well.","code":""},{"path":"/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Analysis and Presentation of Social Scientific Data","text":"’m happy receive bug reports, suggestions, questions, () contributions fix problems add features. prefer use Github issues system trying reach ways. Pull requests contributions encouraged. considering writing bug fix new feature, please check contributing guidelines. Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":"/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Analysis and Presentation of Social Scientific Data","text":"source code package licensed MIT License.","code":""},{"path":"/reference/center.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean-center vectors, data frames, and survey designs — center","title":"Mean-center vectors, data frames, and survey designs — center","text":"function wrapper around gscale() configured mean-center variables without affecting scaling variables.","code":""},{"path":"/reference/center.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean-center vectors, data frames, and survey designs — center","text":"","code":"center(   data = NULL,   vars = NULL,   binary.inputs = \"center\",   binary.factors = FALSE,   weights = NULL )"},{"path":"/reference/center.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean-center vectors, data frames, and survey designs — center","text":"data data frame survey design. needed like rescale multiple variables . x = NULL, columns rescaled. Otherwise, x vector variable names. x numeric vector, argument ignored. vars data data.frame similar, can scale select columns providing vector column names argument. binary.inputs Options binary variables. Default center; 0/1 keeps original scale; -0.5/0.5 rescales 0 -0.5 1 0.5; center subtracts mean; full subtracts mean divides 2 sd. binary.factors Coerce two-level factors numeric apply scaling functions ? Default FALSE. weights vector weights equal length x. iterating data frame, weights need equal length columns avoid errors. may need remove missing values using weights.","code":""},{"path":"/reference/center.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean-center vectors, data frames, and survey designs — center","text":"transformed version data argument.","code":""},{"path":"/reference/center.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mean-center vectors, data frames, and survey designs — center","text":"information can found documentation gscale()","code":""},{"path":[]},{"path":"/reference/center.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean-center vectors, data frames, and survey designs — center","text":"","code":"# Standardize just the \"qsec\" variable in mtcars standardize(mtcars, vars = \"qsec\") #>                      mpg cyl  disp  hp drat    wt        qsec vs am gear carb #> Mazda RX4           21.0   6 160.0 110 3.90 2.620 -0.77716515  0  1    4    4 #> Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 -0.46378082  0  1    4    4 #> Datsun 710          22.8   4 108.0  93 3.85 2.320  0.42600682  1  1    4    1 #> Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215  0.89048716  1  0    3    1 #> Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 -0.46378082  0  0    3    2 #> Valiant             18.1   6 225.0 105 2.76 3.460  1.32698675  1  0    3    1 #> Duster 360          14.3   8 360.0 245 3.21 3.570 -1.12412636  0  0    3    4 #> Merc 240D           24.4   4 146.7  62 3.69 3.190  1.20387148  1  0    4    2 #> Merc 230            22.8   4 140.8  95 3.92 3.150  2.82675459  1  0    4    2 #> Merc 280            19.2   6 167.6 123 3.92 3.440  0.25252621  1  0    4    4 #> Merc 280C           17.8   6 167.6 123 3.92 3.440  0.58829513  1  0    4    4 #> Merc 450SE          16.4   8 275.8 180 3.07 4.070 -0.25112717  0  0    3    3 #> Merc 450SL          17.3   8 275.8 180 3.07 3.730 -0.13920420  0  0    3    3 #> Merc 450SLC         15.2   8 275.8 180 3.07 3.780  0.08464175  0  0    3    3 #> Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250  0.07344945  0  0    3    4 #> Lincoln Continental 10.4   8 460.0 215 3.00 5.424 -0.01608893  0  0    3    4 #> Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 -0.23993487  0  0    3    4 #> Fiat 128            32.4   4  78.7  66 4.08 2.200  0.90727560  1  1    4    1 #> Honda Civic         30.4   4  75.7  52 4.93 1.615  0.37564148  1  1    4    2 #> Toyota Corolla      33.9   4  71.1  65 4.22 1.835  1.14790999  1  1    4    1 #> Toyota Corona       21.5   4 120.1  97 3.70 2.465  1.20946763  1  0    3    1 #> Dodge Challenger    15.5   8 318.0 150 2.76 3.520 -0.54772305  0  0    3    2 #> AMC Javelin         15.2   8 304.0 150 3.15 3.435 -0.30708866  0  0    3    2 #> Camaro Z28          13.3   8 350.0 245 3.73 3.840 -1.36476075  0  0    3    4 #> Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 -0.44699237  0  0    3    2 #> Fiat X1-9           27.3   4  79.0  66 4.08 1.935  0.58829513  1  1    4    1 #> Porsche 914-2       26.0   4 120.3  91 4.43 2.140 -0.64285758  0  1    5    2 #> Lotus Europa        30.4   4  95.1 113 3.77 1.513 -0.53093460  1  1    5    2 #> Ford Pantera L      15.8   8 351.0 264 4.22 3.170 -1.87401028  0  1    5    4 #> Ferrari Dino        19.7   6 145.0 175 3.62 2.770 -1.31439542  0  1    5    6 #> Maserati Bora       15.0   8 301.0 335 3.54 3.570 -1.81804880  0  1    5    8 #> Volvo 142E          21.4   4 121.0 109 4.11 2.780  0.42041067  1  1    4    2"},{"path":"/reference/center_mod.html","id":null,"dir":"Reference","previous_headings":"","what":"Center variables in fitted regression models — center_mod","title":"Center variables in fitted regression models — center_mod","text":"center_mod (previously known center_lm) takes fitted regression models mean-centers continuous variables model aid interpretation, especially case models interactions. wrapper scale_mod.","code":""},{"path":"/reference/center_mod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Center variables in fitted regression models — center_mod","text":"","code":"center_mod(   model,   binary.inputs = \"0/1\",   center.response = FALSE,   data = NULL,   apply.weighted.contrasts = getOption(\"jtools-weighted.contrasts\", FALSE),   ... )"},{"path":"/reference/center_mod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Center variables in fitted regression models — center_mod","text":"model regression model type lm, glm, svyglm; others may work well tested. binary.inputs Options binary variables. Default 0/1; 0/1 keeps original scale; -0.5,0.5 rescales 0 -0.5 1 0.5; center subtracts mean; full treats like continuous variables. center.response response variable also centered? Default FALSE. data provide data used fit model , data frame used re-fit model instead stats::model.frame() model. particularly useful variable transformations polynomial terms specified formula. apply.weighted.contrasts Factor variables scaled, can set contrasts intercept regression model reflect true mean (assuming variables centered). set TRUE, argument apply weighted effects coding factors. similar R default effects coding, weights according many observations level. adapted version contr.wec() wec package used . See package's documentation /Grotenhuis et al. (2016) info. ... Arguments passed gscale().","code":""},{"path":"/reference/center_mod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Center variables in fitted regression models — center_mod","text":"functions returns lm glm object, inheriting whichever class supplied.","code":""},{"path":"/reference/center_mod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Center variables in fitted regression models — center_mod","text":"function mean-center continuous variables regression model ease interpretation, especially models interaction terms. mean svyglm objects calculated using svymean, reflects survey-weighted mean. weight variables svyglm centered, lm family models. function re-estimates model, large models one expect runtime equal first run.","code":""},{"path":"/reference/center_mod.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Center variables in fitted regression models — center_mod","text":"Bauer, D. J., & Curran, P. J. (2005). Probing interactions fixed multilevel regression: Inferential graphical techniques. Multivariate Behavioral Research, 40(3), 373-400. Cohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). Applied multiple regression/correlation analyses behavioral sciences (3rd ed.). Mahwah, NJ: Lawrence Erlbaum Associates, Inc.","code":""},{"path":[]},{"path":"/reference/center_mod.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Center variables in fitted regression models — center_mod","text":"Jacob Long jacob.long@sc.edu","code":""},{"path":"/reference/center_mod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Center variables in fitted regression models — center_mod","text":"","code":"fit <- lm(formula = Murder ~ Income * Illiteracy,           data = as.data.frame(state.x77)) fit_center <- center_mod(fit)  # With weights fitw <- lm(formula = Murder ~ Income * Illiteracy,            data = as.data.frame(state.x77),            weights = Population) fitw_center <- center_mod(fitw)  # With svyglm if (requireNamespace(\"survey\")) { library(survey) data(api) dstrat <- svydesign(id = ~1, strata = ~stype, weights = ~pw,                     data = apistrat, fpc =~ fpc) regmodel <- svyglm(api00 ~ ell * meals, design = dstrat) regmodel_center <- center_mod(regmodel) } #> Loading required namespace: survey #> Loading required package: grid #> Loading required package: Matrix #> Loading required package: survival #>  #> Attaching package: ‘survey’ #> The following object is masked from ‘package:graphics’: #>  #>     dotchart"},{"path":"/reference/effect_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot simple effects in regression models — effect_plot","title":"Plot simple effects in regression models — effect_plot","text":"effect_plot() plots regression paths. plotting done ggplot2 rather base graphics, similar functions use.","code":""},{"path":"/reference/effect_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot simple effects in regression models — effect_plot","text":"","code":"effect_plot(   model,   pred,   pred.values = NULL,   centered = \"all\",   plot.points = FALSE,   interval = FALSE,   data = NULL,   at = NULL,   int.type = c(\"confidence\", \"prediction\"),   int.width = 0.95,   outcome.scale = \"response\",   robust = FALSE,   cluster = NULL,   vcov = NULL,   set.offset = 1,   x.label = NULL,   y.label = NULL,   pred.labels = NULL,   main.title = NULL,   colors = \"black\",   line.thickness = 1.1,   point.size = 1.5,   point.alpha = 0.6,   jitter = 0,   rug = FALSE,   rug.sides = \"lb\",   force.cat = FALSE,   cat.geom = c(\"point\", \"line\", \"bar\"),   cat.interval.geom = c(\"errorbar\", \"linerange\"),   cat.pred.point.size = 3.5,   partial.residuals = FALSE,   color.class = colors,   ... )"},{"path":"/reference/effect_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot simple effects in regression models — effect_plot","text":"model regression model. function tested lm, glm, svyglm, merMod, rq, brmsfit, stanreg models. Models classes may work well officially supported. model include interaction interest. pred name predictor variable involved interaction. can bare name string. Note evaluated using rlang, programmers can use !! syntax pass variables instead verbatim names. pred.values Values pred use instead equi-spaced series default (continuous variables) unique values (non-continuous variables). centered vector quoted variable names mean-centered. \"\", non-focal predictors centered. may instead pass character vector variables center. User can also use \"none\" base predictions variables set 0. response variable, pred, weights, offset variables never centered. plot.points Logical. TRUE, plots actual data points scatterplot top interaction lines. color dots based moderator value. interval Logical. TRUE, plots confidence/prediction intervals around line using geom_ribbon. data Optional, default NULL. may provide data used fit model. can better way get mean values centering can crucial models variable transformations formula (e.g., log(x)) polynomial terms (e.g., poly(x, 2)). see warning function detects problems likely solved providing data argument function attempt retrieve original data global environment. want manually set values variables model, providing named list names variables list values vectors values. can useful especially exploring interactions conditional predictions. int.type Type interval plot. Options \"confidence\" \"prediction\". Default confidence interval. int.width large interval , relative standard error? default, .95, corresponds roughly 1.96 standard errors .05 alpha level values outside range. words, confidence interval, .95 analogous 95% confidence interval. outcome.scale nonlinear models (.e., GLMs), outcome variable plotted link scale (e.g., log odds logit models) original scale (e.g., predicted probabilities logit models)? default \"response\", original scale. link scale, show straight lines rather curves, use \"link\". robust robust standard errors used find confidence intervals supported models? Default FALSE, specify type sandwich standard errors like use (.e., \"HC0\", \"HC1\", ). TRUE, defaults \"HC3\" standard errors. cluster clustered standard errors, provide column name cluster variable input data frame (string). Alternately, provide vector clusters. vcov Optional. may supply variance-covariance matrix coefficients . useful using method robust standard error calculation supported sandwich package. set.offset models offset (e.g., Poisson models), sets offset predicted values. predicted values offset. default, set 1, makes predicted values proportion. See details offset support. x.label character object specifying desired x-axis label. NULL, variable name used. y.label character object specifying desired x-axis label. NULL, variable name used. pred.labels character vector labels categorical predictors. NULL, default, factor labels used. main.title character object used overall title plot. NULL, main title used. colors See jtools_colors details types arguments accepted. Default \"black\". affects coloration line well confidence intervals points. line.thickness thick plotted lines ? Default 1.1; ggplot's default 1. point.size size used observed data plot.points TRUE? Default 1.5. point.alpha alpha aesthetic plotted points observed data ? Default 0.6, can range 0 (transparent) 1 (opaque). jitter much plot.points observed values \"jittered\" via ggplot2::position_jitter()? many points near , jittering moves small amount keep totally overlapping. cases, though, can add confusion since may make points appear outside boundaries observed values cause visual issues. Default 0, try various small values (e.g., 0.1) increase needed points overlapping much. argument vector two values, first assumed jitter width second height. rug Show rug plot margins? uses ggplot2::geom_rug() show distribution predictor (top/bottom) /response variable (left/right) original data. Default FALSE. rug.sides sides rug plots appear? Default \"lb\", meaning left bottom. \"t\" /\"b\" show distribution predictor \"l\" /\"r\" show distribution response. force.cat Force continuous pred treated categorical? default FALSE, can useful things like dummy 0/1 variables. cat.geom pred categorical (force.cat TRUE), type plot ? several options since best way visualize categorical interactions varies context. options: \"point\": default. Simply plot point estimates. may want use point.shape = TRUE also consider interval = TRUE visualize uncertainty. \"line\": connects observations across levels pred variable line. good option pred variable ordinal (ordered). may still consider point.shape = TRUE interval = TRUE still good idea. \"bar\": bar chart. call \"dynamite plot.\" Many applied researchers advise type plot represent distribution observed data uncertainty predictions well. best least use interval = TRUE argument geom. cat.interval.geom categorical categorical interactions. One \"errorbar\" \"linerange\". former, ggplot2::geom_errorbar() used. latter, ggplot2::geom_linerange() used. cat.pred.point.size (categorical pred) TRUE geom \"point\" \"line\", sets size predicted points. Default 3.5. Note distinction point.size, refers observed data points. partial.residuals Instead plotting observed data, may plot partial residuals (controlling effects variables besides pred). color.class Deprecated. Now known colors. ... extra arguments passed make_predictions()","code":""},{"path":"/reference/effect_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot simple effects in regression models — effect_plot","text":"functions returns ggplot object, can treated like user-created plot expanded upon .","code":""},{"path":"/reference/effect_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot simple effects in regression models — effect_plot","text":"function provides means plotting effects purpose exploring regression estimates. must package ggplot2 installed benefit plotting functions. default, numeric predictors one specified pred argument mean-centered, usually produces intuitive plots. affects y-axis linear models, may especially important/influential non-linear/generalized linear models. function supports nonlinear generalized linear models default plot original scale (outcome.scale = \"response\"). mixed effects models lme4 supported, fixed effects plotted. lme4 provide confidence intervals, supported function either. Note: use transformed predictors, e.g., log(x), polynomials, e.g., poly(x, 2), provide raw variable name (x) pred = argument. need input data frame used fit model data = argument.","code":""},{"path":[]},{"path":"/reference/effect_plot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot simple effects in regression models — effect_plot","text":"Jacob Long jacob.long@sc.edu","code":""},{"path":"/reference/effect_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot simple effects in regression models — effect_plot","text":"","code":"# Using a fitted lm model states <- as.data.frame(state.x77) states$HSGrad <- states$`HS Grad` fit <- lm(Income ~ HSGrad + Murder,   data = states) effect_plot(model = fit, pred = Murder)   # Using polynomial predictor, plus intervals fit <- lm(accel ~ poly(mag,3) + dist, data = attenu) effect_plot(fit, pred = mag, interval = TRUE,   int.type = \"confidence\", int.width = .8, data = attenu) # note data arg.   # With svyglm if (requireNamespace(\"survey\")) { library(survey) data(api) dstrat <- svydesign(id = ~1, strata = ~stype, weights = ~pw,                     data = apistrat, fpc = ~fpc) regmodel <- svyglm(api00 ~ ell + meals, design = dstrat) effect_plot(regmodel, pred = ell, interval = TRUE) }   # With lme4 if (FALSE) { library(lme4) data(VerbAgg) mv <- glmer(r2 ~ Anger + mode + (1 | item), data = VerbAgg,             family = binomial,             control = glmerControl(\"bobyqa\")) effect_plot(mv, pred = Anger) }"},{"path":"/reference/export_summs.html","id":null,"dir":"Reference","previous_headings":"","what":"Export regression summaries to tables — export_summs","title":"Export regression summaries to tables — export_summs","text":"function allows users use features summ() (e.g., standardization, robust standard errors) context shareable HTML, LaTeX, Microsoft Word tables. relies heavily huxtable::huxreg() table formatting. particularly useful putting results multiple models single table.","code":""},{"path":"/reference/export_summs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export regression summaries to tables — export_summs","text":"","code":"export_summs(   ...,   error_format = \"({std.error})\",   error_pos = c(\"below\", \"right\", \"same\"),   ci_level = 0.95,   statistics = NULL,   model.names = NULL,   coefs = NULL,   to.file = NULL,   file.name = NULL )"},{"path":"/reference/export_summs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export regression summaries to tables — export_summs","text":"... minimum, regression object(s). See details arguments. error_format standard error, confidence intervals, test statistics, p values used express uncertainty estimates regression coefficients? See details info. Default: \"(std.error)\" error_pos error statistic defined error_style placed relative coefficient estimate? Default: \"\" ci_level reporting confidence intervals, confidence level ? default, .95 confidence intervals requested error_format. statistics model summary statistics included? See huxreg usage. default function depends model type. See details defaults model type. model.names want give model(s) names top column, provide character vector. Otherwise, just labeled number. Default: NULL coefs want include subset coefficients table, specify character vector. want table show different names coefficients, give named vector names preferred coefficient names. See details . .file Export table Microsoft Word, PDF, HTML document? functionality relies huxtable's quick_ functions (huxtable::quick_docx(), huxtable::quick_pdf(), huxtable::quick_html(), huxtable::quick_xlsx()). Acceptable arguments \"Word\" \"docx\" (equivalent), \"pdf\", \"html\", \"xlsx\". case insensitive. Default NULL, meaning table saved. file.name File name (optionally) file path save file. Ignored .file FALSE. Default: NULL","code":""},{"path":"/reference/export_summs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Export regression summaries to tables — export_summs","text":"huxtable.","code":""},{"path":"/reference/export_summs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Export regression summaries to tables — export_summs","text":"many optional parameters documented . argument want pass summ(), instance, used. particular interest may robust scale arguments. Note summ arguments may bearing table output. default model summary statistics reporting follows logic: summ.lm = c(N = \"nobs\", R2 = \"r.squared\"), summ.glm = c(N = \"nobs\", AIC = \"AIC\", BIC = \"BIC\",                        `Pseudo R2` = \"pseudo.r.squared\"), summ.svyglm = c(N = \"nobs\", R2 = \"r.squared\"), summ.merMod = c(N = \"nobs\", AIC = \"AIC\", BIC = \"BIC\",                           `R2 (fixed)` = \"r.squared.fixed\",                           `R2 (total)` = \"r.squared\") summ.rq = c(N = \"nobs\", tau = \"tau\", R1 = \"r.1\", AIC = \"AIC\", BIC = \"BIC\") sure look summ() documentation calculation statistics, especially mixed models. set statistics = \"\", statistics argument passed huxreg NULL, reports whichever model statistics available via glance. want model summary statistics, set argument character(0). options error_format argument. can include anything returned broom::tidy() (see also tidy.summ()). part, interested std.error (standard error), statistic (test statistic, e.g. t-value z-value), p.value, conf.high conf.low, correspond upper lower bounds confidence interval estimate. Note default ci_level argument .95, can alter desired. format error statistics, simply put statistics desired curly braces wherever want character string. example, want standard error parentheses, argument \"({std.error})\", default. ideas: \"({statistic})\", gives test statistic parentheses. \"({statistic}, p = {p.value})\", gives test statistic followed \"p =\" p value parentheses. Note pay special attention rounding keep cells sufficiently narrow. \"[{conf.low}, {conf.high}]\", gives confidence interval standard bracket notation. also explicitly write confidence level, e.g., \"CI [{conf.low}, {conf.high}]\". coefs, argument slightly different default huxreg. provide named vector coefficients, table refer selected coefficients names vector rather coefficient names. instance, want include coefficients hp mpg table refer \"Horsepower\" \"Miles/gallon\", provide argument like : c(\"Horsepower\" = \"hp\", \"Miles/gallon\" = \"mpg\") can also pass argument accepted huxtable::huxreg() function. likely oft-used documented , visit huxreg's documentation info. info converting huxtable::huxtable() object HTML LaTeX, see huxtable's documentation.","code":""},{"path":[]},{"path":"/reference/export_summs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export regression summaries to tables — export_summs","text":"","code":"states <- as.data.frame(state.x77) fit1 <- lm(Income ~ Frost, data = states) fit2 <- lm(Income ~ Frost + Illiteracy, data = states) fit3 <- lm(Income ~ Frost + Illiteracy + Murder, data = states)  if (requireNamespace(\"huxtable\")) {   # Export all 3 regressions with \"Model #\" labels,   # standardized coefficients, and robust standard errors   export_summs(fit1, fit2, fit3,                model.names = c(\"Model 1\",\"Model 2\",\"Model 3\"),                coefs = c(\"Frost Days\" = \"Frost\",                          \"% Illiterate\" = \"Illiteracy\",                          \"Murder Rate\" = \"Murder\"),                scale = TRUE, robust = TRUE) } #> Loading required namespace: huxtable #> Registered S3 methods overwritten by 'broom': #>   method            from   #>   tidy.glht         jtools #>   tidy.summary.glht jtools #>  ───────────────────────────────────────────────────────────────────────────── #>                           Model 1            Model 2            Model 3        #>                     ────────────────────────────────────────────────────────── #>    Frost Days                  139.04            -75.52            -65.19      #>                                (94.89)          (138.74)          (149.01)     #>    % Illiterate                                 -319.31 *         -372.25 **   #>                                                 (124.83)          (120.00)     #>    Murder Rate                                                      85.18      #>                                                                   (136.02)     #>                     ────────────────────────────────────────────────────────── #>    N                            50                50                50         #>    R2                            0.05              0.20              0.21      #>  ───────────────────────────────────────────────────────────────────────────── #>    All continuous predictors are mean-centered and scaled by 1                 #>    standard deviation. Standard errors are heteroskedasticity                  #>    robust.  *** p < 0.001; ** p < 0.01; * p < 0.05.                            #>  #> Column names: names, Model 1, Model 2, Model 3"},{"path":"/reference/get_colors.html","id":null,"dir":"Reference","previous_headings":"","what":"Get colors for plotting functions — get_colors","title":"Get colors for plotting functions — get_colors","text":"helper function provides hex color codes jtools, interactions, perhaps packages.","code":""},{"path":"/reference/get_colors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get colors for plotting functions — get_colors","text":"","code":"get_colors(colors, num.colors = 1, reverse = FALSE, gradient = FALSE)"},{"path":"/reference/get_colors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get colors for plotting functions — get_colors","text":"colors name desired color class vector colors. See details jtools_colors. num.colors many colors returned? Default 1. reverse colors returned reverse order, compared normal? Default FALSE. gradient Return endpoints gradient? Default FALSE. TRUE, num.colors ignored.","code":""},{"path":"/reference/get_formula.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve formulas from model objects — get_formula","title":"Retrieve formulas from model objects — get_formula","text":"function primarily internal helper function jtools related packages standardize different types formula objects used different types models.","code":""},{"path":"/reference/get_formula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve formulas from model objects — get_formula","text":"","code":"get_formula(model, ...)  # S3 method for default get_formula(model, ...)  # S3 method for brmsfit get_formula(model, resp = NULL, dpar = NULL, ...)  # S3 method for panelmodel get_formula(model, ...)"},{"path":"/reference/get_formula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve formulas from model objects — get_formula","text":"model fitted model object. ... Ignored. resp brmsfit objects, response variable formula desired. brmsfit objects may multiple formulas, selects particular one. NULL, first formula chosen (unless dpar specified). dpar brmsfit objects, distributional variable formula desired. NULL, distributional parameter used. multiple responses distributional parameters, resp specified else first formula used default.","code":""},{"path":"/reference/get_formula.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve formulas from model objects — get_formula","text":"formula object.","code":""},{"path":"/reference/get_formula.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve formulas from model objects — get_formula","text":"","code":"data(mtcars) fit <- lm(mpg ~ cyl, data = mtcars) get_formula(fit) #> mpg ~ cyl #> <environment: 0x55936e695758>"},{"path":"/reference/get_robust_se.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate robust standard errors and produce coefficient tables — get_robust_se","title":"Calculate robust standard errors and produce coefficient tables — get_robust_se","text":"function wraps around several sandwich lmtest functions calculate robust standard errors returns useful format.","code":""},{"path":"/reference/get_robust_se.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate robust standard errors and produce coefficient tables — get_robust_se","text":"","code":"get_robust_se(   model,   type = \"HC3\",   cluster = NULL,   data = model.frame(model),   vcov = NULL )"},{"path":"/reference/get_robust_se.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate robust standard errors and produce coefficient tables — get_robust_se","text":"model regression model, preferably class lm glm type One \"HC3\", \"const\", \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC4\", \"HC4m\", \"HC5\". See sandwich::vcovHC() details choices. Note work clustered standard errors (see sandwich::vcovCL()]). cluster want clustered standard errors, either string naming column data represents clusters vector clusters length number rows data. data data used fit model. Default just get model.frame model. vcov may provide variance-covariance matrix function just calculate standard errors, etc. based . Default NULL.","code":""},{"path":"/reference/get_robust_se.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate robust standard errors and produce coefficient tables — get_robust_se","text":"list following: coefs: coefficient table estimates, standard errors, t-statistics, p-values lmtest. ses: standard errors coefs. ts: t-statistics coefs. ps: p-values coefs. type: argument robust. use_cluster: TRUE FALSE indicator whether clusters used. cluster: clusters name cluster variable used, . vcov: robust variance-covariance matrix.","code":""},{"path":"/reference/glance.summ.html","id":null,"dir":"Reference","previous_headings":"","what":"Broom extensions for summ objects — tidy.summ","title":"Broom extensions for summ objects — tidy.summ","text":"functions used compatibility broom's tidying functions facilitate use huxreg, thereby making export_summs works.","code":""},{"path":"/reference/glance.summ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Broom extensions for summ objects — tidy.summ","text":"","code":"# S3 method for summ tidy(x, conf.int = FALSE, conf.level = 0.95, ...)  # S3 method for summ.merMod tidy(x, conf.int = FALSE, conf.level = 0.95, ...)  # S3 method for summ.lm glance(x, ...)  # S3 method for summ.glm glance(x, ...)  # S3 method for summ.svyglm glance(x, ...)  # S3 method for summ.merMod glance(x, ...)  # S3 method for summ.rq glance(x, ...)"},{"path":"/reference/glance.summ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Broom extensions for summ objects — tidy.summ","text":"x summ object. conf.int Include confidence intervals? Default FALSE. conf.level wide confidence intervals , requested. Default .95. ... arguments (usually ignored)","code":""},{"path":"/reference/glance.summ.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Broom extensions for summ objects — tidy.summ","text":"data.frame columns matching appropriate model type per glance documentation.","code":""},{"path":[]},{"path":"/reference/gridlines.html","id":null,"dir":"Reference","previous_headings":"","what":"Add and remove gridlines — add_gridlines","title":"Add and remove gridlines — add_gridlines","text":"convenience wrappers editing ggplot2::theme()'s panel.grid.major panel.grid.minor parameters sensible defaults.","code":""},{"path":"/reference/gridlines.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add and remove gridlines — add_gridlines","text":"","code":"add_gridlines(x = TRUE, y = TRUE, minor = TRUE)  add_x_gridlines(minor = TRUE)  add_y_gridlines(minor = TRUE)  drop_gridlines(x = TRUE, y = TRUE, minor.only = FALSE)  drop_x_gridlines(minor.only = FALSE)  drop_y_gridlines(minor.only = FALSE)"},{"path":"/reference/gridlines.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add and remove gridlines — add_gridlines","text":"x Apply changes x axis? y Apply changes y axis? minor Add minor gridlines addition major? minor.Remove minor gridlines?","code":""},{"path":"/reference/gscale.html","id":null,"dir":"Reference","previous_headings":"","what":"Scale and/or center data, including survey designs — gscale","title":"Scale and/or center data, including survey designs — gscale","text":"gscale standardizes variables dividing 2 standard deviations mean-centering default. contains options handling binary variables separately. gscale() fork rescale arm package---key feature difference gscale() perform functions variables svydesign objects. gscale() also user-friendly flexible accepts input.","code":""},{"path":"/reference/gscale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scale and/or center data, including survey designs — gscale","text":"","code":"gscale(   data = NULL,   vars = NULL,   binary.inputs = \"center\",   binary.factors = FALSE,   n.sd = 2,   center.only = FALSE,   scale.only = FALSE,   weights = NULL,   apply.weighted.contrasts = getOption(\"jtools-weighted.contrasts\", FALSE),   x = NULL,   messages = FALSE )"},{"path":"/reference/gscale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scale and/or center data, including survey designs — gscale","text":"data data frame survey design. needed like rescale multiple variables . x = NULL, columns rescaled. Otherwise, x vector variable names. x numeric vector, argument ignored. vars data data.frame similar, can scale select columns providing vector column names argument. binary.inputs Options binary variables. Default center; 0/1 keeps original scale; -0.5/0.5 rescales 0 -0.5 1 0.5; center subtracts mean; full subtracts mean divides 2 sd. binary.factors Coerce two-level factors numeric apply scaling functions ? Default FALSE. n.sd many standard deviations variables divided ? Default gscale 2, like arm's rescale. 1 typical standardization scheme. center.logical value indicating whether like mean -center values, scale . scale.logical value indicating whether like scale values, mean-center . weights vector weights equal length x. iterating data frame, weights need equal length columns avoid errors. may need remove missing values using weights. apply.weighted.contrasts Factor variables scaled, can set contrasts intercept regression model reflect true mean (assuming variables centered). set TRUE, argument apply weighted effects coding factors. similar R default effects coding, weights according many observations level. adapted version contr.wec() wec package used . See package's documentation /Grotenhuis et al. (2016) info. x Deprecated. Pass numeric vectors data. Pass vectors column names vars. messages Print messages variables processed due non-numeric missing? Default FALSE.","code":""},{"path":"/reference/gscale.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Scale and/or center data, including survey designs — gscale","text":"function adapted rescale function arm package. named gscale() popularizer scaling method, Andrew Gelman. default, works just like rescale. contains many additional options can also accept multiple types input without breaking sweat. numeric variables altered data.frame survey design. Character variables, factors, etc. skipped. dealing survey data, provide survey.design object can rest assured mean-centering scaling performed help svymean() svyvar() functions, respectively. among primary motivations creating function. gscale() center scale weights variables defined survey design unless user specifically requests x = argument.","code":""},{"path":"/reference/gscale.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Scale and/or center data, including survey designs — gscale","text":"Gelman, . (2008). Scaling regression inputs dividing two standard deviations. Statistics Medicine, 27, 2865–2873. http://www.stat.columbia.edu/~gelman/research/published/standardizing7.pdf Grotenhuis, M. te, Pelzer, B., Eisinga, R., Nieuwenhuis, R., Schmidt-Catran, ., & Konig, R. (2017). size matters: Advantages weighted effect coding observational studies. International Journal Public Health, 62, 163–167. https://doi.org/10.1007/s00038-016-0901-1 ( open access)","code":""},{"path":[]},{"path":"/reference/gscale.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Scale and/or center data, including survey designs — gscale","text":"Jacob Long jacob.long@sc.edu","code":""},{"path":"/reference/gscale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scale and/or center data, including survey designs — gscale","text":"","code":"x <- rnorm(10, 2, 1) x2 <- rbinom(10, 1, .5)  # Basic use gscale(x) #>  [1]  0.12606994 -0.47555407  0.06807193  0.59717745  1.02060980 -0.30489969 #>  [7] -0.57994469 -0.31508576  0.11503738 -0.25148229 # Normal standardization gscale(x, n.sd = 1) #>  [1]  0.2521399 -0.9511081  0.1361439  1.1943549  2.0412196 -0.6097994 #>  [7] -1.1598894 -0.6301715  0.2300748 -0.5029646 # Scale only gscale(x, scale.only = TRUE) #>  [1] 1.5123192 0.9106952 1.4543212 1.9834267 2.4068591 1.0813496 0.8063046 #>  [8] 1.0711635 1.5012866 1.1347670 # Center only gscale(x, center.only = TRUE) #>  [1]  0.2166998 -0.8174230  0.1170078  1.0264796  1.7543113 -0.5240876 #>  [7] -0.9968585 -0.5415963  0.1977361 -0.4322693 # Binary inputs gscale(x2, binary.inputs = \"0/1\") #>  [1] 1 0 0 0 0 0 0 1 1 1 gscale(x2, binary.inputs = \"full\") # treats it like a continous var #>  [1]  0.5809475 -0.3872983 -0.3872983 -0.3872983 -0.3872983 -0.3872983 #>  [7] -0.3872983  0.5809475  0.5809475  0.5809475 gscale(x2, binary.inputs = \"-0.5/0.5\") # keep scale, center at zero #>  [1]  0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5  0.5  0.5  0.5 gscale(x2, binary.inputs = \"center\") # mean center it #>  [1]  0.6 -0.4 -0.4 -0.4 -0.4 -0.4 -0.4  0.6  0.6  0.6  # Data frame as input # loops through each numeric column gscale(data = mtcars, binary.inputs = \"-0.5/0.5\") #>                             mpg        cyl        disp          hp        drat #> Mazda RX4            0.07544241 -0.0524939 -0.28530991 -0.26754642  0.28375684 #> Mazda RX4 Wag        0.07544241 -0.0524939 -0.28530991 -0.26754642  0.28375684 #> Datsun 710           0.22477172 -0.6124289 -0.49509105 -0.39152023  0.23699979 #> Hornet 4 Drive       0.10862670 -0.0524939  0.11004685 -0.26754642 -0.48305877 #> Hornet Sportabout   -0.11536726  0.5074411  0.52154061  0.20647109 -0.41759890 #> Valiant             -0.16514370 -0.0524939 -0.02308349 -0.30400931 -0.78230388 #> Duster 360          -0.48039447  0.5074411  0.52154061  0.71695148 -0.36149044 #> Merc 240D            0.35750889 -0.6124289 -0.33896547 -0.61759012  0.08737724 #> Merc 230             0.22477172 -0.6124289 -0.36276756 -0.37693508  0.30245966 #> Merc 280            -0.07388690 -0.0524939 -0.25464959 -0.17274292  0.30245966 #> Merc 280C           -0.19003192 -0.0524939 -0.25464959 -0.17274292  0.30245966 #> Merc 450SE          -0.30617694  0.5074411  0.18185654  0.24293397 -0.49241018 #> Merc 450SL          -0.23151228  0.5074411  0.18185654  0.24293397 -0.49241018 #> Merc 450SLC         -0.40572981  0.5074411  0.18185654  0.24293397 -0.49241018 #> Cadillac Fleetwood  -0.80394131  0.5074411  0.97337691  0.42524840 -0.62332991 #> Lincoln Continental -0.80394131  0.5074411  0.92496588  0.49817417 -0.55787004 #> Chrysler Imperial   -0.44721018  0.5074411  0.84428082  0.60756282 -0.34278762 #> Fiat 128             1.02119472 -0.6124289 -0.61329465 -0.58841981  0.45208222 #> Honda Civic          0.85527326 -0.6124289 -0.62539740 -0.69051589  1.24695206 #> Toyota Corolla       1.14563581 -0.6124289 -0.64395497 -0.59571239  0.58300196 #> Toyota Corona        0.11692278 -0.6124289 -0.44627659 -0.36234992  0.09672865 #> Dodge Challenger    -0.38084159  0.5074411  0.35210200  0.02415666 -0.78230388 #> AMC Javelin         -0.40572981  0.5074411  0.29562247  0.02415666 -0.41759890 #> Camaro Z28          -0.56335520  0.5074411  0.48119809  0.71695148  0.12478288 #> Pontiac Firebird    -0.07388690  0.5074411  0.68291072  0.20647109 -0.48305877 #> Fiat X1-9            0.59809500 -0.6124289 -0.61208437 -0.58841981  0.45208222 #> Porsche 914-2        0.49024605 -0.6124289 -0.44546974 -0.40610538  0.77938156 #> Lotus Europa         0.85527326 -0.6124289 -0.54713290 -0.24566869  0.16218851 #> Ford Pantera L      -0.35595337  0.5074411  0.48523234  0.85551044  0.58300196 #> Ferrari Dino        -0.03240653 -0.0524939 -0.34582370  0.20647109  0.02191737 #> Maserati Bora       -0.42232196  0.5074411  0.28351971  1.37328341 -0.05289391 #> Volvo 142E           0.10862670 -0.6124289 -0.44264576 -0.27483900  0.48013645 #>                               wt         qsec   vs   am       gear        carb #> Mazda RX4           -0.305199784 -0.388582573 -0.5  0.5  0.2117771  0.36760154 #> Mazda RX4 Wag       -0.174892635 -0.231890410 -0.5  0.5  0.2117771  0.36760154 #> Datsun 710          -0.458502312  0.213003408  0.5  0.5  0.2117771 -0.56107604 #> Hornet 4 Drive      -0.001149769  0.445243578  0.5 -0.5 -0.4659096 -0.56107604 #> Hornet Sportabout    0.113827127 -0.231890410 -0.5 -0.5 -0.4659096 -0.25151684 #> Valiant              0.124047296  0.663493376  0.5 -0.5 -0.4659096 -0.56107604 #> Duster 360           0.180258223 -0.562063181 -0.5 -0.5 -0.4659096  0.36760154 #> Merc 240D           -0.013924980  0.601935740  0.5 -0.5  0.2117771 -0.25151684 #> Merc 230            -0.034365317  1.413377296  0.5 -0.5  0.2117771 -0.25151684 #> Merc 280             0.113827127  0.126263104  0.5 -0.5  0.2117771  0.36760154 #> Merc 280C            0.113827127  0.294147564  0.5 -0.5  0.2117771  0.36760154 #> Merc 450SE           0.435762437 -0.125563586 -0.5 -0.5 -0.4659096  0.05804235 #> Merc 450SL           0.262019572 -0.069602099 -0.5 -0.5 -0.4659096  0.05804235 #> Merc 450SLC          0.287569993  0.042320874 -0.5 -0.5 -0.4659096  0.05804235 #> Cadillac Fleetwood   1.038752382  0.036724726 -0.5 -0.5 -0.4659096  0.36760154 #> Lincoln Continental  1.127667849 -0.008044464 -0.5 -0.5 -0.4659096  0.36760154 #> Chrysler Imperial    1.087298183 -0.119967437 -0.5 -0.5 -0.4659096  0.36760154 #> Fiat 128            -0.519823324  0.453637801  0.5  0.5  0.2117771 -0.56107604 #> Honda Civic         -0.818763254  0.187820739  0.5  0.5  0.2117771 -0.25151684 #> Toyota Corolla      -0.706341400  0.573954997  0.5  0.5  0.2117771 -0.56107604 #> Toyota Corona       -0.384406090  0.604733815  0.5 -0.5 -0.4659096 -0.56107604 #> Dodge Challenger     0.154707802 -0.273861525 -0.5 -0.5 -0.4659096 -0.25151684 #> AMC Javelin          0.111272085 -0.153544329 -0.5 -0.5 -0.4659096 -0.25151684 #> Camaro Z28           0.318230499 -0.682380377 -0.5 -0.5 -0.4659096  0.36760154 #> Pontiac Firebird     0.320785541 -0.223496187 -0.5 -0.5 -0.4659096 -0.25151684 #> Fiat X1-9           -0.655240557  0.294147564  0.5  0.5  0.2117771 -0.56107604 #> Porsche 914-2       -0.550483829 -0.321428789 -0.5  0.5  0.8894638 -0.25151684 #> Lotus Europa        -0.870886114 -0.265467302  0.5  0.5  0.8894638 -0.25151684 #> Ford Pantera L      -0.024145148 -0.937005142 -0.5  0.5  0.8894638  0.36760154 #> Ferrari Dino        -0.228548520 -0.657197709 -0.5  0.5  0.8894638  0.98671992 #> Maserati Bora        0.180258223 -0.909024398 -0.5  0.5  0.8894638  1.60583831 #> Volvo 142E          -0.223438435  0.210205334  0.5  0.5  0.2117771 -0.25151684  # Specified vars in data frame gscale(mtcars, vars = c(\"hp\", \"wt\", \"vs\"), binary.inputs = \"center\") #>                      mpg cyl  disp          hp drat           wt  qsec      vs #> Mazda RX4           21.0   6 160.0 -0.26754642 3.90 -0.305199784 16.46 -0.4375 #> Mazda RX4 Wag       21.0   6 160.0 -0.26754642 3.90 -0.174892635 17.02 -0.4375 #> Datsun 710          22.8   4 108.0 -0.39152023 3.85 -0.458502312 18.61  0.5625 #> Hornet 4 Drive      21.4   6 258.0 -0.26754642 3.08 -0.001149769 19.44  0.5625 #> Hornet Sportabout   18.7   8 360.0  0.20647109 3.15  0.113827127 17.02 -0.4375 #> Valiant             18.1   6 225.0 -0.30400931 2.76  0.124047296 20.22  0.5625 #> Duster 360          14.3   8 360.0  0.71695148 3.21  0.180258223 15.84 -0.4375 #> Merc 240D           24.4   4 146.7 -0.61759012 3.69 -0.013924980 20.00  0.5625 #> Merc 230            22.8   4 140.8 -0.37693508 3.92 -0.034365317 22.90  0.5625 #> Merc 280            19.2   6 167.6 -0.17274292 3.92  0.113827127 18.30  0.5625 #> Merc 280C           17.8   6 167.6 -0.17274292 3.92  0.113827127 18.90  0.5625 #> Merc 450SE          16.4   8 275.8  0.24293397 3.07  0.435762437 17.40 -0.4375 #> Merc 450SL          17.3   8 275.8  0.24293397 3.07  0.262019572 17.60 -0.4375 #> Merc 450SLC         15.2   8 275.8  0.24293397 3.07  0.287569993 18.00 -0.4375 #> Cadillac Fleetwood  10.4   8 472.0  0.42524840 2.93  1.038752382 17.98 -0.4375 #> Lincoln Continental 10.4   8 460.0  0.49817417 3.00  1.127667849 17.82 -0.4375 #> Chrysler Imperial   14.7   8 440.0  0.60756282 3.23  1.087298183 17.42 -0.4375 #> Fiat 128            32.4   4  78.7 -0.58841981 4.08 -0.519823324 19.47  0.5625 #> Honda Civic         30.4   4  75.7 -0.69051589 4.93 -0.818763254 18.52  0.5625 #> Toyota Corolla      33.9   4  71.1 -0.59571239 4.22 -0.706341400 19.90  0.5625 #> Toyota Corona       21.5   4 120.1 -0.36234992 3.70 -0.384406090 20.01  0.5625 #> Dodge Challenger    15.5   8 318.0  0.02415666 2.76  0.154707802 16.87 -0.4375 #> AMC Javelin         15.2   8 304.0  0.02415666 3.15  0.111272085 17.30 -0.4375 #> Camaro Z28          13.3   8 350.0  0.71695148 3.73  0.318230499 15.41 -0.4375 #> Pontiac Firebird    19.2   8 400.0  0.20647109 3.08  0.320785541 17.05 -0.4375 #> Fiat X1-9           27.3   4  79.0 -0.58841981 4.08 -0.655240557 18.90  0.5625 #> Porsche 914-2       26.0   4 120.3 -0.40610538 4.43 -0.550483829 16.70 -0.4375 #> Lotus Europa        30.4   4  95.1 -0.24566869 3.77 -0.870886114 16.90  0.5625 #> Ford Pantera L      15.8   8 351.0  0.85551044 4.22 -0.024145148 14.50 -0.4375 #> Ferrari Dino        19.7   6 145.0  0.20647109 3.62 -0.228548520 15.50 -0.4375 #> Maserati Bora       15.0   8 301.0  1.37328341 3.54  0.180258223 14.60 -0.4375 #> Volvo 142E          21.4   4 121.0 -0.27483900 4.11 -0.223438435 18.60  0.5625 #>                     am gear carb #> Mazda RX4            1    4    4 #> Mazda RX4 Wag        1    4    4 #> Datsun 710           1    4    1 #> Hornet 4 Drive       0    3    1 #> Hornet Sportabout    0    3    2 #> Valiant              0    3    1 #> Duster 360           0    3    4 #> Merc 240D            0    4    2 #> Merc 230             0    4    2 #> Merc 280             0    4    4 #> Merc 280C            0    4    4 #> Merc 450SE           0    3    3 #> Merc 450SL           0    3    3 #> Merc 450SLC          0    3    3 #> Cadillac Fleetwood   0    3    4 #> Lincoln Continental  0    3    4 #> Chrysler Imperial    0    3    4 #> Fiat 128             1    4    1 #> Honda Civic          1    4    2 #> Toyota Corolla       1    4    1 #> Toyota Corona        0    3    1 #> Dodge Challenger     0    3    2 #> AMC Javelin          0    3    2 #> Camaro Z28           0    3    4 #> Pontiac Firebird     0    3    2 #> Fiat X1-9            1    4    1 #> Porsche 914-2        1    5    2 #> Lotus Europa         1    5    2 #> Ford Pantera L       1    5    4 #> Ferrari Dino         1    5    6 #> Maserati Bora        1    5    8 #> Volvo 142E           1    4    2  # Weighted inputs  wts <- runif(10, 0, 1) gscale(x, weights = wts) #>  [1]  0.2950283 -0.5679848  0.2118318  0.9708191  1.5782211 -0.3231857 #>  [7] -0.7177302 -0.3377974  0.2792024 -0.2465600 # If using a weights column of data frame, give its name mtcars$weights <- runif(32, 0, 1) gscale(mtcars, weights = weights) # will skip over mtcars$weights #>                             mpg         cyl        disp         hp        drat #> Mazda RX4            0.07365753 -0.04238375 -0.27279226 -0.2615001  0.24349902 #> Mazda RX4 Wag        0.07365753 -0.04238375 -0.27279226 -0.2615001  0.24349902 #> Datsun 710           0.22533990 -0.59174227 -0.47420883 -0.3851987  0.19777089 #> Hornet 4 Drive       0.10736473 -0.04238375  0.10680050 -0.2615001 -0.50644246 #> Hornet Sportabout   -0.12015883  0.50697476  0.50188685  0.2114652 -0.44242307 #> Valiant             -0.17071962 -0.04238375 -0.02102155 -0.2978820 -0.79910256 #> Duster 360          -0.49093796  0.50697476  0.50188685  0.7208124 -0.38754930 #> Merc 240D            0.36016868 -0.59174227 -0.32430842 -0.6107667  0.05144084 #> Merc 230             0.22533990 -0.59174227 -0.34716145 -0.3706459  0.26179028 #> Merc 280            -0.07802484 -0.04238375 -0.24335445 -0.1669070  0.26179028 #> Merc 280C           -0.19600002 -0.04238375 -0.24335445 -0.1669070  0.26179028 #> Merc 450SE          -0.31397519  0.50697476  0.17574694  0.2478472 -0.51558809 #> Merc 450SL          -0.23813401  0.50697476  0.17574694  0.2478472 -0.51558809 #> Merc 450SLC         -0.41509678  0.50697476  0.17574694  0.2478472 -0.51558809 #> Cadillac Fleetwood  -0.81958310  0.50697476  0.93570715  0.4297569 -0.64362688 #> Lincoln Continental -0.81958310  0.50697476  0.88922640  0.5025208 -0.57960749 #> Chrysler Imperial   -0.45723077  0.50697476  0.81175849  0.6116666 -0.36925804 #> Fiat 128             1.03431255 -0.59174227 -0.58769931 -0.5816612  0.40812033 #> Honda Civic          0.86577658 -0.59174227 -0.59931950 -0.6835306  1.18549870 #> Toyota Corolla       1.16071453 -0.59174227 -0.61713712 -0.5889376  0.53615912 #> Toyota Corona        0.11579153 -0.59174227 -0.42734074 -0.3560931  0.06058647 #> Dodge Challenger    -0.38981638  0.50697476  0.33920423  0.0295555 -0.79910256 #> AMC Javelin         -0.41509678  0.50697476  0.28497670  0.0295555 -0.44242307 #> Camaro Z28          -0.57520595  0.50697476  0.46315289  0.7208124  0.08802335 #> Pontiac Firebird    -0.07802484  0.50697476  0.65682267  0.2114652 -0.50644246 #> Fiat X1-9            0.60454583 -0.59174227 -0.58653730 -0.5816612  0.40812033 #> Porsche 914-2        0.49499745 -0.59174227 -0.42656606 -0.3997514  0.72821730 #> Lotus Europa         0.86577658 -0.59174227 -0.52417563 -0.2396709  0.12460586 #> Ford Pantera L      -0.36453598  0.50697476  0.46702629  0.8590638  0.53615912 #> Ferrari Dino        -0.03589085 -0.04238375 -0.33089319  0.2114652 -0.01257856 #> Maserati Bora       -0.43195037  0.50697476  0.27335651  1.3756875 -0.08574358 #> Volvo 142E           0.10736473 -0.59174227 -0.42385468 -0.2687764  0.43555721 #>                               wt        qsec         vs         am       gear #> Mazda RX4           -0.267693555 -0.38788689 -0.4139853  0.5637758  0.2043405 #> Mazda RX4 Wag       -0.146942626 -0.21297850 -0.4139853  0.5637758  0.2043405 #> Datsun 710          -0.409753472  0.28363640  0.5860147  0.5637758  0.2043405 #> Hornet 4 Drive       0.014058613  0.54287562  0.5860147 -0.4362242 -0.4585659 #> Hornet Sportabout    0.120603551 -0.21297850 -0.4139853 -0.4362242 -0.4585659 #> Valiant              0.130074212  0.78649802  0.5860147 -0.4362242 -0.4585659 #> Duster 360           0.182162848 -0.58153546 -0.4139853 -0.4362242 -0.4585659 #> Merc 240D            0.002220287  0.71778401  0.5860147 -0.4362242  0.2043405 #> Merc 230            -0.016721035  1.62355960  0.5860147 -0.4362242  0.2043405 #> Merc 280             0.120603551  0.18681211  0.5860147 -0.4362242  0.2043405 #> Merc 280C            0.120603551  0.37421396  0.5860147 -0.4362242  0.2043405 #> Merc 450SE           0.418929376 -0.09429066 -0.4139853 -0.4362242 -0.4585659 #> Merc 450SL           0.257928137 -0.03182338 -0.4139853 -0.4362242 -0.4585659 #> Merc 450SLC          0.281604790  0.09311119 -0.4139853 -0.4362242 -0.4585659 #> Cadillac Fleetwood   0.977698383  0.08686446 -0.4139853 -0.4362242 -0.4585659 #> Lincoln Continental  1.060093135  0.03689063 -0.4139853 -0.4362242 -0.4585659 #> Chrysler Imperial    1.022684023 -0.08804393 -0.4139853 -0.4362242 -0.4585659 #> Fiat 128            -0.466577439  0.55224571  0.5860147  0.5637758  0.2043405 #> Honda Civic         -0.743594277  0.25552612  0.5860147  0.5637758  0.2043405 #> Toyota Corolla      -0.639417005  0.68655037  0.5860147  0.5637758  0.2043405 #> Toyota Corona       -0.341091179  0.72090737  0.5860147 -0.4362242 -0.4585659 #> Dodge Challenger     0.158486195 -0.25982896 -0.4139853 -0.4362242 -0.4585659 #> AMC Javelin          0.118235886 -0.12552430 -0.4139853 -0.4362242 -0.4585659 #> Camaro Z28           0.310016773 -0.71584012 -0.4139853 -0.4362242 -0.4585659 #> Pontiac Firebird     0.312384439 -0.20360841 -0.4139853 -0.4362242 -0.4585659 #> Fiat X1-9           -0.592063699  0.37421396  0.5860147  0.5637758  0.2043405 #> Porsche 914-2       -0.494989422 -0.31292615 -0.4139853  0.5637758  0.8672470 #> Lotus Europa        -0.791894649 -0.25045887  0.5860147  0.5637758  0.8672470 #> Ford Pantera L      -0.007250374 -1.00006626 -0.4139853  0.5637758  0.8672470 #> Ferrari Dino        -0.196663597 -0.68772984 -0.4139853  0.5637758  0.8672470 #> Maserati Bora        0.182162848 -0.96883262 -0.4139853  0.5637758  0.8672470 #> Volvo 142E          -0.191928266  0.28051303  0.5860147  0.5637758  0.2043405 #>                            carb     weights #> Mazda RX4            0.39707227  0.05419298 #> Mazda RX4 Wag        0.39707227  0.77322739 #> Datsun 710          -0.57396981  0.60741509 #> Hornet 4 Drive      -0.57396981 -0.51917371 #> Hornet Sportabout   -0.25028911 -0.32156257 #> Valiant             -0.57396981 -0.48235136 #> Duster 360           0.39707227 -0.85784756 #> Merc 240D           -0.25028911 -0.90001223 #> Merc 230            -0.25028911 -0.90195207 #> Merc 280             0.39707227  0.21298497 #> Merc 280C            0.39707227 -0.55008145 #> Merc 450SE           0.07339158 -0.69501184 #> Merc 450SL           0.07339158  0.02933380 #> Merc 450SLC          0.07339158 -0.11192057 #> Cadillac Fleetwood   0.39707227 -0.05533965 #> Lincoln Continental  0.39707227 -0.38793850 #> Chrysler Imperial    0.39707227  0.23936809 #> Fiat 128            -0.57396981 -0.79324348 #> Honda Civic         -0.25028911 -0.10420974 #> Toyota Corolla      -0.57396981 -0.75631383 #> Toyota Corona       -0.57396981  0.43361896 #> Dodge Challenger    -0.25028911 -0.23314472 #> AMC Javelin         -0.25028911 -0.97474056 #> Camaro Z28           0.39707227  0.42102532 #> Pontiac Firebird    -0.25028911  0.10996939 #> Fiat X1-9           -0.57396981  0.16485305 #> Porsche 914-2       -0.25028911  0.71236376 #> Lotus Europa        -0.25028911  0.25466693 #> Ford Pantera L       0.39707227 -0.26082251 #> Ferrari Dino         1.04443366 -1.31239543 #> Maserati Bora        1.69179505 -0.33551853 #> Volvo 142E          -0.25028911 -0.80812922 # If using a weights column of data frame, can still select variables gscale(mtcars, vars = c(\"hp\", \"wt\", \"vs\"), weights = weights) #>                      mpg cyl  disp         hp drat           wt  qsec #> Mazda RX4           21.0   6 160.0 -0.2615001 3.90 -0.267693555 16.46 #> Mazda RX4 Wag       21.0   6 160.0 -0.2615001 3.90 -0.146942626 17.02 #> Datsun 710          22.8   4 108.0 -0.3851987 3.85 -0.409753472 18.61 #> Hornet 4 Drive      21.4   6 258.0 -0.2615001 3.08  0.014058613 19.44 #> Hornet Sportabout   18.7   8 360.0  0.2114652 3.15  0.120603551 17.02 #> Valiant             18.1   6 225.0 -0.2978820 2.76  0.130074212 20.22 #> Duster 360          14.3   8 360.0  0.7208124 3.21  0.182162848 15.84 #> Merc 240D           24.4   4 146.7 -0.6107667 3.69  0.002220287 20.00 #> Merc 230            22.8   4 140.8 -0.3706459 3.92 -0.016721035 22.90 #> Merc 280            19.2   6 167.6 -0.1669070 3.92  0.120603551 18.30 #> Merc 280C           17.8   6 167.6 -0.1669070 3.92  0.120603551 18.90 #> Merc 450SE          16.4   8 275.8  0.2478472 3.07  0.418929376 17.40 #> Merc 450SL          17.3   8 275.8  0.2478472 3.07  0.257928137 17.60 #> Merc 450SLC         15.2   8 275.8  0.2478472 3.07  0.281604790 18.00 #> Cadillac Fleetwood  10.4   8 472.0  0.4297569 2.93  0.977698383 17.98 #> Lincoln Continental 10.4   8 460.0  0.5025208 3.00  1.060093135 17.82 #> Chrysler Imperial   14.7   8 440.0  0.6116666 3.23  1.022684023 17.42 #> Fiat 128            32.4   4  78.7 -0.5816612 4.08 -0.466577439 19.47 #> Honda Civic         30.4   4  75.7 -0.6835306 4.93 -0.743594277 18.52 #> Toyota Corolla      33.9   4  71.1 -0.5889376 4.22 -0.639417005 19.90 #> Toyota Corona       21.5   4 120.1 -0.3560931 3.70 -0.341091179 20.01 #> Dodge Challenger    15.5   8 318.0  0.0295555 2.76  0.158486195 16.87 #> AMC Javelin         15.2   8 304.0  0.0295555 3.15  0.118235886 17.30 #> Camaro Z28          13.3   8 350.0  0.7208124 3.73  0.310016773 15.41 #> Pontiac Firebird    19.2   8 400.0  0.2114652 3.08  0.312384439 17.05 #> Fiat X1-9           27.3   4  79.0 -0.5816612 4.08 -0.592063699 18.90 #> Porsche 914-2       26.0   4 120.3 -0.3997514 4.43 -0.494989422 16.70 #> Lotus Europa        30.4   4  95.1 -0.2396709 3.77 -0.791894649 16.90 #> Ford Pantera L      15.8   8 351.0  0.8590638 4.22 -0.007250374 14.50 #> Ferrari Dino        19.7   6 145.0  0.2114652 3.62 -0.196663597 15.50 #> Maserati Bora       15.0   8 301.0  1.3756875 3.54  0.182162848 14.60 #> Volvo 142E          21.4   4 121.0 -0.2687764 4.11 -0.191928266 18.60 #>                             vs am gear carb    weights #> Mazda RX4           -0.4139853  1    4    4 0.66918363 #> Mazda RX4 Wag       -0.4139853  1    4    4 0.98665526 #> Datsun 710           0.5860147  1    4    1 0.91344499 #> Hornet 4 Drive       0.5860147  0    3    1 0.41602794 #> Hornet Sportabout   -0.4139853  0    3    2 0.50327818 #> Valiant              0.5860147  0    3    1 0.43228592 #> Duster 360          -0.4139853  0    3    4 0.26649498 #> Merc 240D            0.5860147  0    4    2 0.24787823 #> Merc 230             0.5860147  0    4    2 0.24702174 #> Merc 280             0.5860147  0    4    4 0.73929425 #> Merc 280C            0.5860147  0    4    4 0.40238140 #> Merc 450SE          -0.4139853  0    3    3 0.33839101 #> Merc 450SL          -0.4139853  0    3    3 0.65820768 #> Merc 450SLC         -0.4139853  0    3    3 0.59584035 #> Cadillac Fleetwood  -0.4139853  0    3    4 0.62082224 #> Lincoln Continental -0.4139853  0    3    4 0.47397155 #> Chrysler Imperial   -0.4139853  0    3    4 0.75094306 #> Fiat 128             0.5860147  1    4    1 0.29501930 #> Honda Civic          0.5860147  1    4    2 0.59924488 #> Toyota Corolla       0.5860147  1    4    1 0.31132466 #> Toyota Corona        0.5860147  0    3    1 0.83670967 #> Dodge Challenger    -0.4139853  0    3    2 0.54231687 #> AMC Javelin         -0.4139853  0    3    2 0.21488380 #> Camaro Z28          -0.4139853  0    3    4 0.83114926 #> Pontiac Firebird    -0.4139853  0    3    2 0.69381031 #> Fiat X1-9            0.5860147  1    4    1 0.71804281 #> Porsche 914-2       -0.4139853  1    5    2 0.95978245 #> Lotus Europa         0.5860147  1    5    2 0.75769788 #> Ford Pantera L      -0.4139853  1    5    4 0.53009643 #> Ferrari Dino        -0.4139853  1    5    6 0.06580076 #> Maserati Bora       -0.4139853  1    5    8 0.49711628 #> Volvo 142E           0.5860147  1    4    2 0.28844687  # Survey designs if (requireNamespace(\"survey\")) {   library(survey)   data(api)   ## Create survey design object   dstrat <- svydesign(id = ~1, strata = ~stype, weights = ~pw,                        data = apistrat, fpc=~fpc)   # Creating test binary variable   dstrat$variables$binary <- rbinom(200, 1, 0.5)    gscale(data = dstrat, binary.inputs = \"-0.5/0.5\")   gscale(data = dstrat, vars = c(\"api00\",\"meals\",\"binary\"),          binary.inputs = \"-0.5/0.5\") } #> Stratified Independent Sampling design #> dstrat <- svydesign(id = ~1, strata = ~stype, weights = ~pw, #>                        data = apistrat, fpc=~fpc)"},{"path":"/reference/interactions_deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Deprecated interaction functions — interact_plot","title":"Deprecated interaction functions — interact_plot","text":"functions now part interactions package.","code":""},{"path":"/reference/interactions_deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deprecated interaction functions — interact_plot","text":"","code":"interact_plot(...)  cat_plot(...)  sim_slopes(...)  johnson_neyman(...)  probe_interaction(...)"},{"path":"/reference/interactions_deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deprecated interaction functions — interact_plot","text":"... arguments ignored","code":""},{"path":"/reference/jtools_colors.html","id":null,"dir":"Reference","previous_headings":"","what":"Color palettes in jtools functions — jtools_colors","title":"Color palettes in jtools functions — jtools_colors","text":"jtools combines several options colors argument plotting functions.","code":""},{"path":"/reference/jtools_colors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Color palettes in jtools functions — jtools_colors","text":"argument colors functions like effect_plot, plot_coefs, others flexible may also cause confusion. provide argument length 1, assumed naming palette. jtools provides 6 color palettes design qualitative data. 4 6 based Paul Tol's suggestions (see references) meant optimize ability quickly differentiate colors distinguishable colorblind people. called \"Qual1\", \"Qual2\", \"Qual3\", \"CUD\", \"CUD Bright\", \"Rainbow\". \"Qual\" schemes comes Paul Tol. \"Rainbow\" Paul Tol's compromise rainbow color scheme fairly differentiable colorblind people rendered grayscale. \"CUD Bright\" brightened reordered version Okabe Ito's suggestions 'Color Universal Design' \"CUD\" exact scheme (see references). \"CUD Bright\" default qualitative scales jtools functions. may also provide color palette supported RColorBrewer. See options RColorBrewer::brewer.pal()'s documentation. provide one RColorBrewer's sequential palettes, like \"Blues\", jtools automatically requests one color needed brewer.pal drops lightest color. experience scales tend give one color light easily differentiate white background. gradients, can use RColorBrewer sequential palette names get comparable results continuous scale. also jtools-specific gradient schemes: \"blue\", \"blue2\", \"green\", \"red\", \"purple\", \"seagreen\". want something little non-standard, suggest taking look \"blue2\" \"seagreen\". Lastly, may provide colors name. must vector length whatever colors correspond . format must one understood ggplot2's manual scale functions. basically means needs hex format (e.g., \"#000000\") one many names R understands (e.g., \"red\"; use colors() see options).","code":""},{"path":"/reference/jtools_colors.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Color palettes in jtools functions — jtools_colors","text":"Paul Tol's site used derive 4 6 jtools-specific qualitative palettes: https://personal.sron.nl/~pault/ Okabe Ito's palette inspired \"CUD Bright\", though \"CUD Bright\" exactly . \"CUD\" . See https://web.archive.org/web/20190216090108/jfly.iam.u-tokyo.ac.jp/color/ .","code":""},{"path":"/reference/knit_print.summ.html","id":null,"dir":"Reference","previous_headings":"","what":"knitr methods for summ — knit_print.summ.lm","title":"knitr methods for summ — knit_print.summ.lm","text":"reason end users utilize functions, CRAN requires documented.","code":""},{"path":"/reference/knit_print.summ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"knitr methods for summ — knit_print.summ.lm","text":"","code":"knit_print.summ.lm(x, options = NULL, ...)  knit_print.summ.glm(x, options = NULL, ...)  knit_print.summ.svyglm(x, options = NULL, ...)  knit_print.summ.merMod(x, options = NULL, ...)  knit_print.summ.rq(x, options = NULL, ...)"},{"path":"/reference/knit_print.summ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"knitr methods for summ — knit_print.summ.lm","text":"x summ object options Chunk options. ... Ignored.","code":""},{"path":"/reference/make_new_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Make new data for generating predicted data from regression models. — make_new_data","title":"Make new data for generating predicted data from regression models. — make_new_data","text":"convenience function helps automate process generating predicted data regression model predictor(s). designed give data frame predict method's newdata argument.","code":""},{"path":"/reference/make_new_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make new data for generating predicted data from regression models. — make_new_data","text":"","code":"make_new_data(   model,   pred,   pred.values = NULL,   at = NULL,   data = NULL,   center = TRUE,   set.offset = NULL,   num.preds = 100,   ... )"},{"path":"/reference/make_new_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make new data for generating predicted data from regression models. — make_new_data","text":"model model (e.g., lm, glm, merMod, svyglm) pred name focal predictor string. variable , plotting, likely along x-axis (dependent variable y-axis). pred.values values pred want include. Default NULL, means sequence equi-spaced values range numeric predictor level non-numeric predictor. want manually set values variables model, providing named list names variables list values vectors values. can useful especially exploring interactions conditional predictions. data data frame used fitting model. Default NULL, case data retrieved via model.frame , variable transformations formula, looking environment data. center Set numeric covariates mean? Default TRUE. may also just provide vector names (strings) covariates center. Note svyglm models, survey-weighted means used. models weights, weighted means. set.offset model offset, value use offset variable. Default NULL, case median offset variable used. num.preds number predictions generate. Default 100. Ignored pred.values NULL. ... Extra arguments passed get_formula()","code":""},{"path":"/reference/make_new_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make new data for generating predicted data from regression models. — make_new_data","text":"data frame.","code":""},{"path":"/reference/make_new_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make new data for generating predicted data from regression models. — make_new_data","text":"Please bear mind generate predictions. need predict function model another interface, prediction package's titular function.","code":""},{"path":"/reference/make_new_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make new data for generating predicted data from regression models. — make_new_data","text":"","code":"fit <- lm(Income ~ Frost + Illiteracy + Murder, data = as.data.frame(state.x77)) # Basic use new_data <- make_new_data(fit, pred = \"Frost\") # Set covariate to specific value new_data <- make_new_data(fit, pred = \"Frost\", at = list(Murder = 5)) # Set covariate to several specific values new_data <- make_new_data(fit, pred = \"Frost\", at = list(Murder = c(5, 10, 15)))"},{"path":"/reference/make_predictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate predicted data for plotting results of regression models — make_predictions","title":"Generate predicted data for plotting results of regression models — make_predictions","text":"alternate interface underlying tools make effect_plot() well interactions::interact_plot() interactions::cat_plot() interactions package. make_predictions() creates data plotted adds information original data make amenable plotting predicted data.","code":""},{"path":"/reference/make_predictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate predicted data for plotting results of regression models — make_predictions","text":"","code":"make_predictions(model, ...)  # S3 method for default make_predictions(   model,   pred,   pred.values = NULL,   at = NULL,   data = NULL,   center = TRUE,   interval = TRUE,   int.type = c(\"confidence\", \"prediction\"),   int.width = 0.95,   outcome.scale = \"response\",   robust = FALSE,   cluster = NULL,   vcov = NULL,   set.offset = NULL,   new_data = NULL,   return.orig.data = FALSE,   partial.residuals = FALSE,   ... )"},{"path":"/reference/make_predictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate predicted data for plotting results of regression models — make_predictions","text":"model model (e.g., lm, glm, merMod, svyglm) ... Ignored. pred name focal predictor string. variable , plotting, likely along x-axis (dependent variable y-axis). pred.values values pred want include. Default NULL, means sequence equi-spaced values range numeric predictor level non-numeric predictor. want manually set values variables model, providing named list names variables list values vectors values. can useful especially exploring interactions conditional predictions. data Optional, default NULL. may provide data used fit model. can better way get mean values centering can crucial models variable transformations formula (e.g., log(x)) polynomial terms (e.g., poly(x, 2)). see warning function detects problems likely solved providing data argument function attempt retrieve original data global environment. center Set numeric covariates mean? Default TRUE. may also just provide vector names (strings) covariates center. Note svyglm models, survey-weighted means used. models weights, weighted means. interval Logical. TRUE, plots confidence/prediction intervals around line using geom_ribbon. int.type Type interval plot. Options \"confidence\" \"prediction\". Default confidence interval. int.width large interval , relative standard error? default, .95, corresponds roughly 1.96 standard errors .05 alpha level values outside range. words, confidence interval, .95 analogous 95% confidence interval. outcome.scale nonlinear models (.e., GLMs), outcome variable plotted link scale (e.g., log odds logit models) original scale (e.g., predicted probabilities logit models)? default \"response\", original scale. link scale, show straight lines rather curves, use \"link\". robust robust standard errors used find confidence intervals supported models? Default FALSE, specify type sandwich standard errors like use (.e., \"HC0\", \"HC1\", ). TRUE, defaults \"HC3\" standard errors. cluster clustered standard errors, provide column name cluster variable input data frame (string). Alternately, provide vector clusters. vcov Optional. may supply variance-covariance matrix coefficients . useful using method robust standard error calculation supported sandwich package. set.offset models offset (e.g., Poisson models), sets offset predicted values. predicted values offset. default, set 1, makes predicted values proportion. See details offset support. new_data prefer generate hypothetical (hypothetical) data rather function make call make_new_data(), can provide . return.orig.data Instead returning just predicted data frame, original data returned well? , list return predicted data (first element) original data (second element). Default FALSE. partial.residuals return.orig.data TRUE, observed dependent variable replaced partial residual? makes call partialize(), can find details.","code":""},{"path":"/reference/md_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Print attractive data frames in the console — md_table","title":"Print attractive data frames in the console — md_table","text":"function takes data frame input prints console ASCII/markdown table better readability.","code":""},{"path":"/reference/md_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print attractive data frames in the console — md_table","text":"","code":"md_table(   x,   format = getOption(\"md_table_format\", \"grid\"),   digits = getOption(\"jtools-digits\", 2),   sig.digits = TRUE,   row.names = rownames(x),   col.names = colnames(x),   align = NULL )"},{"path":"/reference/md_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print attractive data frames in the console — md_table","text":"x data frame matrix. format style, can one following: \"multiline\", \"grid\", \"simple\" (also \"pandoc\"), \"rmarkdown\" (also \"markdown\"). Default: \"markdown\" digits many digits print numbers. Default: 2 sig.digits number printed digits number digits least many significant digits? Default TRUE, meaning print digits number significant digits. row.names FALSE, row names suppressed. character vector row names can also specified . default, row names included rownames(t) neither NULL identical 1:nrow(x). col.names character vector column names used table align Column alignment: character vector consisting ‘'l'’ (left), ‘'c'’ (center) /‘'r'’ (right). default ‘align = NULL’, numeric columns right-aligned, columns left-aligned.","code":""},{"path":"/reference/model_utils.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility functions for generating model predictions — get_offset_name","title":"Utility functions for generating model predictions — get_offset_name","text":"functions get information data regression models.","code":""},{"path":"/reference/model_utils.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility functions for generating model predictions — get_offset_name","text":"","code":"get_offset_name(model)  get_weights(model, data)  get_data(model, formula = NULL, warn = TRUE, ...)  get_response_name(model, ...)"},{"path":"/reference/model_utils.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility functions for generating model predictions — get_offset_name","text":"model model (e.g., lm, glm, merMod, svyglm) data get_weights(), data used fit model. formula formula model, desired. Otherwise get_formula() called. warn get_data(), warning model.frame() work variable transformations? Default TRUE may desired get_data() used inside another function used multiple times. ... Arguments passed get_formula()","code":""},{"path":"/reference/model_utils.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility functions for generating model predictions — get_offset_name","text":"get_data(): data used fit model. get_response_name(): name response variable. get_offset_name(): name offset variable. get_weights(): list weights_name, name weighting variable, weights, weights (1 weights).","code":""},{"path":"/reference/movies.html","id":null,"dir":"Reference","previous_headings":"","what":"Data about movies — movies","title":"Data about movies — movies","text":"dataset containing information films, popular , extent feature women.","code":""},{"path":"/reference/movies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data about movies — movies","text":"","code":"movies"},{"path":"/reference/movies.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data about movies — movies","text":"data frame 841 rows 24 variables: title movie's title year year movie's US theatrical release release_date exact date movie's US theatrical release runtime length movie hours genre5 movie's primary genre per IMDB, fit one 5 broad categories genre_detailed verbatim genre description per IMDB rated movie's MPA rating (G, PG, PG-13, R, NC-17) ordered factor director name movie's director(s) writer name movie's screenwriter(s) actors comma-separated string leading actors film language movie's language(s), per IMDB country country(ies) movie produced metascore movie's score MetaCritic, ranging 0 100 imdb_rating movie's rating IMDB, ranging 0 10 imdb_votes number users submitted rating IMDB imdb_id unique identifier movie IMDB studio studio(s) produced movie bechdel_binary logical indicating whether movie passed Bechdel test bechdel_ordinal granular measure bechdel test, indicating just whether movie passed failed close got passing fail us_gross movie's US gross 2013 US dollars int_gross movie's international gross 2013 US dollars budget movie's budget 2013 US dollars men_lines proportion spoken lines spoken male characters lines_data raw data used calculate men_lines; see Source information","code":""},{"path":"/reference/movies.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data about movies — movies","text":"data aggregated several sources. Metadata gathered IMDB. information, particularly lines, collected Pudding. data regarding Bechdel Test, well finances, comes FiveThirtyEight associated R package (fivethirtyeight dataset, bechdel).","code":""},{"path":"/reference/nin.html","id":null,"dir":"Reference","previous_headings":"","what":"Not %in% — %nin%","title":"Not %in% — %nin%","text":"function opposite %%","code":""},{"path":"/reference/nin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Not %in% — %nin%","text":"","code":"x %nin% table"},{"path":"/reference/nin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Not %in% — %nin%","text":"x object table object want see x ","code":""},{"path":"/reference/nin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Not %in% — %nin%","text":"logical vector","code":""},{"path":[]},{"path":"/reference/num_print.html","id":null,"dir":"Reference","previous_headings":"","what":"Numbering printing with signed zeroes and trailing zeroes — num_print","title":"Numbering printing with signed zeroes and trailing zeroes — num_print","text":"function print exactly amount digits requested well signed zeroes appropriate (e.g, -0.00).","code":""},{"path":"/reference/num_print.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Numbering printing with signed zeroes and trailing zeroes — num_print","text":"","code":"num_print(x, digits = getOption(\"jtools-digits\", 2), format = \"f\")"},{"path":"/reference/num_print.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Numbering printing with signed zeroes and trailing zeroes — num_print","text":"x number(s) print digits Number digits past decimal print format equal \"d\" (integers), \"f\", \"e\", \"E\", \"g\", \"G\", \"fg\" (reals). Default \"f\"","code":""},{"path":"/reference/partialize.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjust observed data for partial residuals plots — partialize","title":"Adjust observed data for partial residuals plots — partialize","text":"function designed facilitate creation partial residual plots, can plot observed data alongside model predictions. difference instead actual observed data, outcome variable adjusted effects covariates.","code":""},{"path":"/reference/partialize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adjust observed data for partial residuals plots — partialize","text":"","code":"partialize(model, ...)  # S3 method for default partialize(   model,   vars = NULL,   data = NULL,   at = NULL,   center = TRUE,   scale = c(\"response\", \"link\"),   set.offset = 1,   ... )"},{"path":"/reference/partialize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjust observed data for partial residuals plots — partialize","text":"model regression model. ... Ignored. vars variable(s) adjust , string (vector strings). want show effect x adjusting effect z, make \"x\" vars argument. data Optionally, provide data used fit model (data frame variables). Otherwise, retrieved model global environment. want manually set values variables model, providing named list names variables list values vectors values. can useful especially exploring interactions conditional predictions. center Set numeric covariates mean? Default TRUE. may also just provide vector names (strings) covariates center. Note svyglm models, survey-weighted means used. models weights, weighted means. scale GLMs, outcome variable returned link scale response scale? Default \"response\". set.offset models offset (e.g., Poisson models), sets offset predicted values. predicted values offset. default, set 1, makes predicted values proportion. See details offset support.","code":""},{"path":"/reference/partialize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjust observed data for partial residuals plots — partialize","text":"data plus residualized outcome variable.","code":""},{"path":"/reference/partialize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Adjust observed data for partial residuals plots — partialize","text":"main use working partial residuals rather observed values explore patterns model fit respect one variables \"controlling \" effects others. Plotting predicted line along observed data may make well-fitting model look poor fit lot variation accounted variables one x-axis. advise consulting Fox Weisberg (available free) details partial residuals . function designed produce data similar format effects::Effect() function residuals set TRUE plotted. wanted modular function produce data separately. clear, developers effects package nothing function; `partialize`` merely designed replicate functionality.","code":""},{"path":"/reference/partialize.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Adjust observed data for partial residuals plots — partialize","text":"Fox, J., & Weisberg, S. (2018). Visualizing fit lack fit complex regression models predictor effect plots partial residuals. Journal Statistical Software, 87(9), 1–27. https://doi.org/10.18637/jss.v087.i09","code":""},{"path":"/reference/pf_sv_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Test whether sampling weights are needed — pf_sv_test","title":"Test whether sampling weights are needed — pf_sv_test","text":"Use test proposed Pfeffermann Sverchkov (1999) check whether regression model specified correctly without weights.","code":""},{"path":"/reference/pf_sv_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test whether sampling weights are needed — pf_sv_test","text":"","code":"pf_sv_test(   model,   data = NULL,   weights,   sims = 1000,   digits = getOption(\"jtools-digits\", default = 3) )"},{"path":"/reference/pf_sv_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test whether sampling weights are needed — pf_sv_test","text":"model fitted model, without weights data data frame data fed fitted model weights weights name weights column model's data frame vector weights equal length number observations included model. sims number bootstrap simulations use estimating variance residual correlation. Default 1000, publications computing power/time sufficient, higher number better. digits integer specifying number digits past decimal report output. Default 3. can change default number digits jtools functions options(\"jtools-digits\" = digits) digits desired number.","code":""},{"path":"/reference/pf_sv_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test whether sampling weights are needed — pf_sv_test","text":"test described Pfeffermann Sverchkov (1999) designed help analysts decide whether need use sample weights regressions avoid biased parameter estimation. first checks correlation residuals model weights. uses bootstrapping estimate variance correlation, ending t-test whether correlation differs zero. done squared residuals cubed residuals well. anyone statistically significant (whatever level feel appropriate), best weighted regression. Note large samples, small correlation may low p-value without large bias unweighted regression.","code":""},{"path":"/reference/pf_sv_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Test whether sampling weights are needed — pf_sv_test","text":"Pfeffermann, D., & Sverchkov, M. (1999). Parametric semi-parametric estimation regression models fitted survey data. Sankhya: Indian Journal Statistics, 61. 166-186.","code":""},{"path":[]},{"path":"/reference/pf_sv_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test whether sampling weights are needed — pf_sv_test","text":"","code":"# Note: This is a contrived example to show how the function works, # not a case with actual sammpling weights from a survey vendor if (requireNamespace(\"boot\")) {   states <- as.data.frame(state.x77)   set.seed(100)   states$wts <- runif(50, 0, 3)   fit <- lm(Murder ~ Illiteracy + Frost, data = states)   pf_sv_test(model = fit, data = states, weights = wts, sims = 100) } #>  #> Pfeffermann-Sverchkov test of sample weight ignorability  #>  #> Residual correlation = -0.157, p = 0.328 #> Squared residual correlation = 0.250, p = 0.108 #> Cubed residual correlation = -0.000, p = 0.998 #>  #> A significant correlation may indicate biased estimates #> in the unweighted model."},{"path":"/reference/plot_summs.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Regression Summaries — plot_summs","title":"Plot Regression Summaries — plot_summs","text":"plot_summs plot_coefs create regression coefficient plots ggplot2.","code":""},{"path":"/reference/plot_summs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Regression Summaries — plot_summs","text":"","code":"plot_summs(   ...,   ci_level = 0.95,   model.names = NULL,   coefs = NULL,   omit.coefs = \"(Intercept)\",   inner_ci_level = NULL,   colors = \"CUD Bright\",   plot.distributions = FALSE,   rescale.distributions = FALSE,   exp = FALSE,   point.shape = TRUE,   point.size = 3,   legend.title = \"Model\",   groups = NULL,   facet.rows = NULL,   facet.cols = NULL,   facet.label.pos = \"top\",   color.class = colors,   resp = NULL,   dpar = NULL )  plot_coefs(   ...,   ci_level = 0.95,   inner_ci_level = NULL,   model.names = NULL,   coefs = NULL,   omit.coefs = c(\"(Intercept)\", \"Intercept\"),   colors = \"CUD Bright\",   plot.distributions = FALSE,   rescale.distributions = FALSE,   exp = FALSE,   point.shape = TRUE,   point.size = 3,   legend.title = \"Model\",   groups = NULL,   facet.rows = NULL,   facet.cols = NULL,   facet.label.pos = \"top\",   color.class = colors,   resp = NULL,   dpar = NULL )"},{"path":"/reference/plot_summs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Regression Summaries — plot_summs","text":"... regression model(s). may also include arguments passed tidy(). ci_level desired width confidence intervals coefficients. Default: 0.95 model.names plotting multiple models simultaneously, can provide vector names . NULL, named sequentially \"Model 1\", \"Model 2\", . Default: NULL coefs like include certain coefficients, provide vector. named vector, names used place variable names. See details examples. Default: NULL omit.coefs like specify coefficients include plot, provide vector. argument overridden coefs provided. default, intercept term omitted. include intercept term, just set omit.coefs NULL. inner_ci_level Plot thicker line representing narrower span ci_level. Default NULL, good options .9, .8, .5. colors See jtools_colors color options. Default: 'CUD Bright' plot.distributions Instead just plotting ranges, may plot normal distributions representing width estimate. Note completely theoretical based bootstrapping MCMC procedure, even source model fit way. Default FALSE. rescale.distributions plot.distributions TRUE, default behavior plot normal density curve scale. uncertainty intervals much wider/narrower others, means wide ones low height able see curve. set parameter TRUE, curve maximum height regardless width. exp TRUE, coefficients exponentiated (e.g., transforms logit coefficents log odds scale odds). reference line also moved 1 instead 0. point.shape using multiple models, model's point estimates use different point shape visually differentiate model others? Default TRUE. may also pass vector shapes specify shapes . point.size Change size points. Default 3. legend.title title legend ? Default \"Model\", can specify since rather difficult change later via ggplot2's typical methods. groups like facets (.e., separate panes) different groups coefficients, can specify groups list . See details . facet.rows number rows facet grid (nrow argument ggplot2::facet_wrap()). facet.cols number columns facet grid (nrow argument ggplot2::facet_wrap()). facet.label.pos put facet labels. One \"top\" (default), \"bottom\", \"left\", \"right\". color.class Deprecated. Now known colors. resp models brmsfit multiple response variables, specify vector . model list includes types models, need enter resp models. instance, want plot lm object two brmsfit objects, need provide vector length 2 resp. dpar models brmsfit distributional dependent variable, can specified . NULL, assumed want coefficients location/mean parameter, distributional parameter(s).","code":""},{"path":"/reference/plot_summs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Regression Summaries — plot_summs","text":"ggplot object.","code":""},{"path":"/reference/plot_summs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Regression Summaries — plot_summs","text":"note distinction plot_summs plot_coefs: plot_summs accepts models supported summ() allows users take advantage standardization robust standard error features (among others may relevant). plot_coefs supports models broom::tidy() method defined broom package, course lacks additional features like robust standard errors. get mix two, can pass summ objects plot_coefs . coefs, provide named vector coefficients, plot refer selected coefficients names vector rather coefficient names. instance, want include coefficients hp mpg plot refer \"Horsepower\" \"Miles/gallon\", provide argument like : c(\"Horsepower\" = \"hp\", \"Miles/gallon\" = \"mpg\") use groups argument, provide (preferably named) list character vectors. want separate panes \"Frost\" \"Illiteracy\" one \"Population\" \"Area\" , make list like : list(pane_1 = c(\"Frost\", \"Illiteracy\"), pane_2 = c(\"Population\", \"Area\"))","code":""},{"path":"/reference/plot_summs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Regression Summaries — plot_summs","text":"","code":"states <- as.data.frame(state.x77) fit1 <- lm(Income ~ Frost + Illiteracy + Murder +            Population + Area + `Life Exp` + `HS Grad`,            data = states, weights = runif(50, 0.1, 3)) fit2 <- lm(Income ~ Frost + Illiteracy + Murder +            Population + Area + `Life Exp` + `HS Grad`,            data = states, weights = runif(50, 0.1, 3)) fit3 <- lm(Income ~ Frost + Illiteracy + Murder +            Population + Area + `Life Exp` + `HS Grad`,            data = states, weights = runif(50, 0.1, 3))  # Plot all 3 regressions with custom predictor labels, # standardized coefficients, and robust standard errors plot_summs(fit1, fit2, fit3,            coefs = c(\"Frost Days\" = \"Frost\", \"% Illiterate\" = \"Illiteracy\",                      \"Murder Rate\" = \"Murder\"),            scale = TRUE, robust = TRUE)"},{"path":"/reference/predict_merMod.html","id":null,"dir":"Reference","previous_headings":"","what":"Alternative interface for merMod predictions — predict_merMod","title":"Alternative interface for merMod predictions — predict_merMod","text":"function generates predictions merMod models, ability get standard errors well.","code":""},{"path":"/reference/predict_merMod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Alternative interface for merMod predictions — predict_merMod","text":"","code":"predict_merMod(   object,   newdata = NULL,   se.fit = FALSE,   use.re.var = FALSE,   allow.new.levels = FALSE,   type = c(\"link\", \"response\", \"terms\"),   na.action = na.pass,   re.form = NULL,   boot = FALSE,   sims = 100,   prog.arg = \"none\",   ... )"},{"path":"/reference/predict_merMod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Alternative interface for merMod predictions — predict_merMod","text":"object fitted model object newdata data frame evaluate     predictions. se.fit Include standard errors predictions? Note standard errors default include fixed effects variance. See details info. Default FALSE. use.re.var se.fit TRUE, include random effects variance standard errors? Default FALSE. allow.new.levels logical new levels (NA values)     newdata allowed. FALSE (default), new values     newdata trigger error; TRUE, prediction     use unconditional (population-level) values data     previously unobserved levels (NAs). type character string - either \"link\", default,     \"response\" indicating type prediction object returned. na.action function determining done     missing values fixed effects newdata.     default predict NA: see na.pass. re.form (formula, NULL, NA) specify random effects condition predicting.  NULL,     include random effects; NA ~0,     include random effects. boot Use bootstrapping (via lme4::bootMer()) estimate variance se.fit? Default FALSE sims boot TRUE, many simulations run? Default 100. prog.arg boot se.fit TRUE, character string - type progress bar display. Default \"none\"; function look relevant *ProgressBar function, \"txt\" work general; \"tk\" available tcltk package loaded; \"win\" Windows systems. Progress bars disabled (message) parallel operation. ... boot se.fit TRUE, additional arguments passed lme4::bootMer().","code":""},{"path":"/reference/predict_merMod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Alternative interface for merMod predictions — predict_merMod","text":"developers lme4 omit se.fit argument reason, perfectly clear best estimate variance models. solution logical one, perhaps perfect. Bayesian models one way better. method used based one described : http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#predictions-andor-confidence--prediction-intervals--predictions","code":""},{"path":"/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. generics glance, tidy tibble as_tibble","code":""},{"path":"/reference/scale_mod.html","id":null,"dir":"Reference","previous_headings":"","what":"Scale variables in fitted regression models — scale_mod","title":"Scale variables in fitted regression models — scale_mod","text":"scale_mod (previously known scale_lm) takes fitted regression models scales predictors dividing 1 2 standard deviations (chosen user).","code":""},{"path":"/reference/scale_mod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scale variables in fitted regression models — scale_mod","text":"","code":"scale_mod(model, ...)  # S3 method for default scale_mod(   model,   binary.inputs = \"0/1\",   n.sd = 1,   center = TRUE,   scale.response = FALSE,   center.only = FALSE,   scale.only = FALSE,   data = NULL,   vars = NULL,   apply.weighted.contrasts = getOption(\"jtools-weighted.contrasts\", FALSE),   ... )"},{"path":"/reference/scale_mod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scale variables in fitted regression models — scale_mod","text":"model regression model type lm, glm, svyglm, lme4::merMod. model types may work well tested. ... Arguments passed gscale(). binary.inputs Options binary variables. Default \"0/1\"; \"0/1\" keeps original scale; \"-0.5,0.5\" rescales 0 -0.5 1 0.5; center subtracts mean; full treats like continuous variables. n.sd many standard deviations divide standardization? Default 1, though prefer 2. center Default TRUE. TRUE, predictors also mean-centered. binary predictors, binary.inputs argument supersedes one. scale.response response variable also rescaled? Default FALSE. center.Rather actually scale predictors, just mean-center . scale.logical value indicating whether like scale values, mean-center . data provide data used fit model , data frame used re-fit model instead stats::model.frame() model. particularly useful variable transformations polynomial terms specified formula. vars character vector variable names want scaled. NULL, default, predictors. apply.weighted.contrasts Factor variables scaled, can set contrasts intercept regression model reflect true mean (assuming variables centered). set TRUE, argument apply weighted effects coding factors. similar R default effects coding, weights according many observations level. adapted version contr.wec() wec package used . See package's documentation /Grotenhuis et al. (2016) info.","code":""},{"path":"/reference/scale_mod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scale variables in fitted regression models — scale_mod","text":"functions returns re-fitted model object, inheriting whichever class supplied.","code":""},{"path":"/reference/scale_mod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Scale variables in fitted regression models — scale_mod","text":"function scale continuous variables regression model ease interpretation, especially models interaction terms. can also mean-center well, requested. scaling happens input data, terms . means interaction terms still properly calculated product standardized predictors, standardized product predictors. function re-estimates model, large models one expect runtime equal first run.","code":""},{"path":"/reference/scale_mod.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Scale variables in fitted regression models — scale_mod","text":"Bauer, D. J., & Curran, P. J. (2005). Probing interactions fixed multilevel regression: Inferential graphical techniques. Multivariate Behavioral Research, 40(3), 373-400. Cohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). Applied multiple regression/correlation analyses behavioral sciences (3rd ed.). Mahwah, NJ: Lawrence Erlbaum Associates, Inc.","code":""},{"path":[]},{"path":"/reference/scale_mod.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Scale variables in fitted regression models — scale_mod","text":"Jacob Long jacob.long@sc.edu","code":""},{"path":"/reference/scale_mod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scale variables in fitted regression models — scale_mod","text":"","code":"fit <- lm(formula = Murder ~ Income * Illiteracy,           data = as.data.frame(state.x77)) fit_scale <- scale_mod(fit) fit_scale <- scale_mod(fit, center = TRUE)  # With weights fitw <- lm(formula = Murder ~ Income * Illiteracy,            data = as.data.frame(state.x77),            weights = Population) fitw_scale <- scale_mod(fitw) fitw_scale <- scale_mod(fitw, center = TRUE, binary.input = \"0/1\")  # With svyglm if (requireNamespace(\"survey\")) { library(survey) data(api) dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat, fpc=~fpc) regmodel <- svyglm(api00~ell*meals,design=dstrat) regmodel_scale <- scale_mod(regmodel) regmodel_scale <- scale_mod(regmodel, binary.input = \"0/1\") }"},{"path":"/reference/set_summ_defaults.html","id":null,"dir":"Reference","previous_headings":"","what":"Set defaults for summ() functions — set_summ_defaults","title":"Set defaults for summ() functions — set_summ_defaults","text":"function convenience wrapper manually setting options using options(). gives handy way , instance, set arguments used every call summ() script/session. make settings persist across sessions, can run .Rprofile file. Note arguments apply (e.g., robust merMod models) silently ignored types models used.","code":""},{"path":"/reference/set_summ_defaults.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set defaults for summ() functions — set_summ_defaults","text":"","code":"set_summ_defaults(   digits = NULL,   model.info = NULL,   model.fit = NULL,   pvals = NULL,   robust = NULL,   confint = NULL,   ci.width = NULL,   vifs = NULL,   conf.method = NULL,   table.format = NULL )"},{"path":"/reference/set_summ_defaults.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set defaults for summ() functions — set_summ_defaults","text":"digits integer specifying number digits past decimal report output. Default 2. can change default number digits jtools functions options(\"jtools-digits\" = digits) digits desired number. model.info Toggles printing basic information sample size, name DV, number predictors. model.fit Toggles printing model fit statistics. pvals Show p values? FALSE, printed. Default TRUE. robust FALSE, reports heteroskedasticity-robust standard errors instead conventional SEs. also known Huber-White standard errors. several options provided sandwich::vcovHC(): \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". Default FALSE. requires sandwich package compute standard errors. confint Show confidence intervals instead standard errors? Default FALSE. ci.width number 0 1 signifies width desired confidence interval. Default .95, corresponds 95% confidence interval. Ignored confint = FALSE. vifs TRUE, adds column output variance inflation factors (VIF). Default FALSE. conf.method Argument passed lme4::confint.merMod(). Default \"Wald\", \"profile\" \"boot\" better accuracy priority. aware alternate methods sometimes time-consuming. table.format format understood md_table()","code":""},{"path":"/reference/standardize.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardize vectors, data frames, and survey designs — standardize","title":"Standardize vectors, data frames, and survey designs — standardize","text":"function wrapper around gscale() configured conventional standardization continuous variables, mean-centering dividing one standard deviation.","code":""},{"path":"/reference/standardize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardize vectors, data frames, and survey designs — standardize","text":"","code":"standardize(   data = NULL,   vars = NULL,   binary.inputs = \"center\",   binary.factors = FALSE,   weights = NULL )"},{"path":"/reference/standardize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardize vectors, data frames, and survey designs — standardize","text":"data data frame survey design. needed like rescale multiple variables . x = NULL, columns rescaled. Otherwise, x vector variable names. x numeric vector, argument ignored. vars data data.frame similar, can scale select columns providing vector column names argument. binary.inputs Options binary variables. Default center; 0/1 keeps original scale; -0.5/0.5 rescales 0 -0.5 1 0.5; center subtracts mean; full subtracts mean divides 2 sd. binary.factors Coerce two-level factors numeric apply scaling functions ? Default FALSE. weights vector weights equal length x. iterating data frame, weights need equal length columns avoid errors. may need remove missing values using weights.","code":""},{"path":"/reference/standardize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardize vectors, data frames, and survey designs — standardize","text":"transformed version data argument.","code":""},{"path":"/reference/standardize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Standardize vectors, data frames, and survey designs — standardize","text":"information can found documentation gscale()","code":""},{"path":[]},{"path":"/reference/standardize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardize vectors, data frames, and survey designs — standardize","text":"","code":"# Standardize just the \"qsec\" variable in mtcars standardize(mtcars, vars = \"qsec\") #>                      mpg cyl  disp  hp drat    wt        qsec vs am gear carb #> Mazda RX4           21.0   6 160.0 110 3.90 2.620 -0.77716515  0  1    4    4 #> Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 -0.46378082  0  1    4    4 #> Datsun 710          22.8   4 108.0  93 3.85 2.320  0.42600682  1  1    4    1 #> Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215  0.89048716  1  0    3    1 #> Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 -0.46378082  0  0    3    2 #> Valiant             18.1   6 225.0 105 2.76 3.460  1.32698675  1  0    3    1 #> Duster 360          14.3   8 360.0 245 3.21 3.570 -1.12412636  0  0    3    4 #> Merc 240D           24.4   4 146.7  62 3.69 3.190  1.20387148  1  0    4    2 #> Merc 230            22.8   4 140.8  95 3.92 3.150  2.82675459  1  0    4    2 #> Merc 280            19.2   6 167.6 123 3.92 3.440  0.25252621  1  0    4    4 #> Merc 280C           17.8   6 167.6 123 3.92 3.440  0.58829513  1  0    4    4 #> Merc 450SE          16.4   8 275.8 180 3.07 4.070 -0.25112717  0  0    3    3 #> Merc 450SL          17.3   8 275.8 180 3.07 3.730 -0.13920420  0  0    3    3 #> Merc 450SLC         15.2   8 275.8 180 3.07 3.780  0.08464175  0  0    3    3 #> Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250  0.07344945  0  0    3    4 #> Lincoln Continental 10.4   8 460.0 215 3.00 5.424 -0.01608893  0  0    3    4 #> Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 -0.23993487  0  0    3    4 #> Fiat 128            32.4   4  78.7  66 4.08 2.200  0.90727560  1  1    4    1 #> Honda Civic         30.4   4  75.7  52 4.93 1.615  0.37564148  1  1    4    2 #> Toyota Corolla      33.9   4  71.1  65 4.22 1.835  1.14790999  1  1    4    1 #> Toyota Corona       21.5   4 120.1  97 3.70 2.465  1.20946763  1  0    3    1 #> Dodge Challenger    15.5   8 318.0 150 2.76 3.520 -0.54772305  0  0    3    2 #> AMC Javelin         15.2   8 304.0 150 3.15 3.435 -0.30708866  0  0    3    2 #> Camaro Z28          13.3   8 350.0 245 3.73 3.840 -1.36476075  0  0    3    4 #> Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 -0.44699237  0  0    3    2 #> Fiat X1-9           27.3   4  79.0  66 4.08 1.935  0.58829513  1  1    4    1 #> Porsche 914-2       26.0   4 120.3  91 4.43 2.140 -0.64285758  0  1    5    2 #> Lotus Europa        30.4   4  95.1 113 3.77 1.513 -0.53093460  1  1    5    2 #> Ford Pantera L      15.8   8 351.0 264 4.22 3.170 -1.87401028  0  1    5    4 #> Ferrari Dino        19.7   6 145.0 175 3.62 2.770 -1.31439542  0  1    5    6 #> Maserati Bora       15.0   8 301.0 335 3.54 3.570 -1.81804880  0  1    5    8 #> Volvo 142E          21.4   4 121.0 109 4.11 2.780  0.42041067  1  1    4    2"},{"path":"/reference/subsetters.html","id":null,"dir":"Reference","previous_headings":"","what":"Subsetting operators — %not%","title":"Subsetting operators — %not%","text":"%just% %% subsetting convenience functions situations x[x %% y] x[x %nin% y]. See details behavior x data frame matrix.","code":""},{"path":"/reference/subsetters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subsetting operators — %not%","text":"","code":"x %not% y  x %not% y <- value  x %just% y  x %just% y <- value  # S3 method for default %not%(x, y)  # S3 method for default %not%(x, y) <- value  # S3 method for data.frame %not%(x, y)  # S3 method for data.frame %not%(x, y) <- value  # S3 method for matrix %not%(x, y)  # S3 method for matrix %not%(x, y) <- value  # S3 method for list %not%(x, y)  # S3 method for list %not%(x, y) <- value  # S3 method for default %just%(x, y)  # S3 method for default %just%(x, y) <- value  # S3 method for data.frame %just%(x, y)  # S3 method for data.frame %just%(x, y) <- value  # S3 method for matrix %just%(x, y)  # S3 method for matrix %just%(x, y) <- value  # S3 method for list %just%(x, y)  # S3 method for list %just%(x, y) <- value"},{"path":"/reference/subsetters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subsetting operators — %not%","text":"x Object subset y List items include /x value object(s) assign subsetted x","code":""},{"path":"/reference/subsetters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subsetting operators — %not%","text":"x y (%just%) x y (%%).","code":""},{"path":"/reference/subsetters.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Subsetting operators — %not%","text":"behavior %% %just% different subsetting data frames matrices. subset y case interpreted column names indices. can also make assignments subset way subsetting brackets.","code":""},{"path":[]},{"path":"/reference/subsetters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Subsetting operators — %not%","text":"","code":"x <- 1:5  y <- 3:8    x %just% y # 3 4 5 #> [1] 3 4 5  x %not% y # 1 2 #> [1] 1 2   # Assignment works too  x %just% y <- NA # 1 2 NA NA NA  x %not% y <- NA # NA NA 3 4 5    mtcars %just% c(\"mpg\", \"qsec\", \"cyl\") # keeps only columns with those names #>                      mpg cyl  qsec #> Mazda RX4           21.0   6 16.46 #> Mazda RX4 Wag       21.0   6 17.02 #> Datsun 710          22.8   4 18.61 #> Hornet 4 Drive      21.4   6 19.44 #> Hornet Sportabout   18.7   8 17.02 #> Valiant             18.1   6 20.22 #> Duster 360          14.3   8 15.84 #> Merc 240D           24.4   4 20.00 #> Merc 230            22.8   4 22.90 #> Merc 280            19.2   6 18.30 #> Merc 280C           17.8   6 18.90 #> Merc 450SE          16.4   8 17.40 #> Merc 450SL          17.3   8 17.60 #> Merc 450SLC         15.2   8 18.00 #> Cadillac Fleetwood  10.4   8 17.98 #> Lincoln Continental 10.4   8 17.82 #> Chrysler Imperial   14.7   8 17.42 #> Fiat 128            32.4   4 19.47 #> Honda Civic         30.4   4 18.52 #> Toyota Corolla      33.9   4 19.90 #> Toyota Corona       21.5   4 20.01 #> Dodge Challenger    15.5   8 16.87 #> AMC Javelin         15.2   8 17.30 #> Camaro Z28          13.3   8 15.41 #> Pontiac Firebird    19.2   8 17.05 #> Fiat X1-9           27.3   4 18.90 #> Porsche 914-2       26.0   4 16.70 #> Lotus Europa        30.4   4 16.90 #> Ford Pantera L      15.8   8 14.50 #> Ferrari Dino        19.7   6 15.50 #> Maserati Bora       15.0   8 14.60 #> Volvo 142E          21.4   4 18.60  mtcars %not% 1:5 # drops columns 1 through 5 #>                        wt  qsec vs am gear carb #> Mazda RX4           2.620 16.46  0  1    4    4 #> Mazda RX4 Wag       2.875 17.02  0  1    4    4 #> Datsun 710          2.320 18.61  1  1    4    1 #> Hornet 4 Drive      3.215 19.44  1  0    3    1 #> Hornet Sportabout   3.440 17.02  0  0    3    2 #> Valiant             3.460 20.22  1  0    3    1 #> Duster 360          3.570 15.84  0  0    3    4 #> Merc 240D           3.190 20.00  1  0    4    2 #> Merc 230            3.150 22.90  1  0    4    2 #> Merc 280            3.440 18.30  1  0    4    4 #> Merc 280C           3.440 18.90  1  0    4    4 #> Merc 450SE          4.070 17.40  0  0    3    3 #> Merc 450SL          3.730 17.60  0  0    3    3 #> Merc 450SLC         3.780 18.00  0  0    3    3 #> Cadillac Fleetwood  5.250 17.98  0  0    3    4 #> Lincoln Continental 5.424 17.82  0  0    3    4 #> Chrysler Imperial   5.345 17.42  0  0    3    4 #> Fiat 128            2.200 19.47  1  1    4    1 #> Honda Civic         1.615 18.52  1  1    4    2 #> Toyota Corolla      1.835 19.90  1  1    4    1 #> Toyota Corona       2.465 20.01  1  0    3    1 #> Dodge Challenger    3.520 16.87  0  0    3    2 #> AMC Javelin         3.435 17.30  0  0    3    2 #> Camaro Z28          3.840 15.41  0  0    3    4 #> Pontiac Firebird    3.845 17.05  0  0    3    2 #> Fiat X1-9           1.935 18.90  1  1    4    1 #> Porsche 914-2       2.140 16.70  0  1    5    2 #> Lotus Europa        1.513 16.90  1  1    5    2 #> Ford Pantera L      3.170 14.50  0  1    5    4 #> Ferrari Dino        2.770 15.50  0  1    5    6 #> Maserati Bora       3.570 14.60  0  1    5    8 #> Volvo 142E          2.780 18.60  1  1    4    2   # Assignment works for data frames as well  mtcars %just% c(\"mpg\", \"qsec\") <- gscale(mtcars, c(\"mpg\", \"qsec\")) #> Warning: provided 11 variables to replace 2 variables  mtcars %not% c(\"mpg\", \"qsec\") <- gscale(mtcars %not% c(\"mpg\", \"qsec\"))"},{"path":"/reference/summ.glm.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized linear regression summaries with options — summ.glm","title":"Generalized linear regression summaries with options — summ.glm","text":"summ() prints output regression model fashion similar summary(), formatted differently options.","code":""},{"path":"/reference/summ.glm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized linear regression summaries with options — summ.glm","text":"","code":"# S3 method for glm summ(   model,   scale = FALSE,   confint = getOption(\"summ-confint\", FALSE),   ci.width = getOption(\"summ-ci.width\", 0.95),   robust = getOption(\"summ-robust\", FALSE),   cluster = NULL,   vifs = getOption(\"summ-vifs\", FALSE),   digits = getOption(\"jtools-digits\", default = 2),   exp = FALSE,   pvals = getOption(\"summ-pvals\", TRUE),   n.sd = 1,   center = FALSE,   transform.response = FALSE,   scale.only = FALSE,   data = NULL,   model.info = getOption(\"summ-model.info\", TRUE),   model.fit = getOption(\"summ-model.fit\", TRUE),   which.cols = NULL,   vcov = NULL,   ... )"},{"path":"/reference/summ.glm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized linear regression summaries with options — summ.glm","text":"model glm object. scale TRUE, reports standardized regression coefficients scaling mean-centering input data (latter can changed via scale.argument). Default FALSE. confint Show confidence intervals instead standard errors? Default FALSE. ci.width number 0 1 signifies width desired confidence interval. Default .95, corresponds 95% confidence interval. Ignored confint = FALSE. robust FALSE, reports heteroskedasticity-robust standard errors instead conventional SEs. also known Huber-White standard errors. several options provided sandwich::vcovHC(): \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". Default FALSE. requires sandwich package compute standard errors. cluster clustered standard errors, provide column name cluster variable input data frame (string). Alternately, provide vector clusters. Note must set robust either \"HC1\", \"HC2\", \"HC3\" order clustered standard errors (\"HC4\" \"HC5\" supported. vifs TRUE, adds column output variance inflation factors (VIF). Default FALSE. digits integer specifying number digits past decimal report output. Default 2. can change default number digits jtools functions options(\"jtools-digits\" = digits) digits desired number. exp TRUE, reports exponentiated coefficients confidence intervals exponential models like logit Poisson models. quantity known odds ratio binary outcomes incidence rate ratio count models. pvals Show p values? FALSE, printed. Default TRUE. n.sd scale = TRUE, many standard deviations predictors divided ? Default 1, though suggest 2. center want coefficients mean-centered variables want standardize, set TRUE. Note setting false affect whether scale mean-centers variables. Use scale.. transform.response scaling/centering apply response variable? Default FALSE. scale.want scale center, set TRUE. Note legacy reasons, setting scale = TRUE center = FALSE achieve effect. Default FALSE. data provide data used fit model , data frame used re-fit model (scale TRUE) instead stats::model.frame() model. particularly useful variable transformations polynomial terms specified formula. model.info Toggles printing basic information sample size, name DV, number predictors. model.fit Toggles printing model fit statistics. .cols Developmental feature. providing columns name, can add/remove/reorder requested columns output. fully supported, now. vcov may provide variance-covariance matrix regression coefficients want calculate standard errors way accommodated robust cluster options. ... Among things, arguments passed scale_mod() center_mod() center scale TRUE.","code":""},{"path":"/reference/summ.glm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized linear regression summaries with options — summ.glm","text":"saved, users can access items returned output (without rounding). coeftable outputted table variables coefficients model model statistics displayed. useful cases scale = TRUE. Much information can accessed attributes.","code":""},{"path":"/reference/summ.glm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized linear regression summaries with options — summ.glm","text":"default, function print following items console: sample size name outcome variable chi-squared test, (Pseudo-)R-squared value AIC/BIC. table regression coefficients, standard errors, z values, p values. several options available robust. heavy lifting done sandwich::vcovHC(), better described. Put simply, may choose \"HC0\" \"HC5\". Based recommendation developers sandwich, default set \"HC3\". Stata's default \"HC1\", choice may better goal replicate Stata's output. option understood vcovHC() accepted. Cluster-robust standard errors computed cluster set name input data's cluster variable vector clusters. scale center options performed via refitting model scale_mod() center_mod(), respectively. turn uses gscale() mean-centering scaling.","code":""},{"path":"/reference/summ.glm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized linear regression summaries with options — summ.glm","text":"King, G., & Roberts, M. E. (2015). robust standard errors expose methodological problems fix, . Political Analysis, 23(2), 159–179. doi: 10.1093/pan/mpu015 Lumley, T., Diehr, P., Emerson, S., & Chen, L. (2002). Importance Normality Assumption Large Public Health Data Sets. Annual Review Public Health, 23, 151–169. doi: 10.1146/annurev.publhealth.23.100901.140546","code":""},{"path":[]},{"path":"/reference/summ.glm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generalized linear regression summaries with options — summ.glm","text":"Jacob Long jacob.long@sc.edu","code":""},{"path":"/reference/summ.glm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized linear regression summaries with options — summ.glm","text":"","code":"## Dobson (1990) Page 93: Randomized Controlled Trial :  counts <- c(18,17,15,20,10,20,25,13,12)  outcome <- gl(3,1,9)  treatment <- gl(3,3)  print(d.AD <- data.frame(treatment, outcome, counts)) #>   treatment outcome counts #> 1         1       1     18 #> 2         1       2     17 #> 3         1       3     15 #> 4         2       1     20 #> 5         2       2     10 #> 6         2       3     20 #> 7         3       1     25 #> 8         3       2     13 #> 9         3       3     12  glm.D93 <- glm(counts ~ outcome + treatment, family = poisson)   # Summarize with standardized coefficients  summ(glm.D93, scale = TRUE) #> MODEL INFO: #> Observations: 9 #> Dependent Variable: counts #> Type: Generalized linear model #>   Family: poisson  #>   Link function: log  #>  #> MODEL FIT: #> χ²(4) = 5.45, p = 0.24 #> Pseudo-R² (Cragg-Uhler) = 0.46 #> Pseudo-R² (McFadden) = 0.10 #> AIC = 56.76, BIC = 57.75  #>  #> Standard errors: MLE #> ------------------------------------------------ #>                      Est.   S.E.   z val.      p #> ----------------- ------- ------ -------- ------ #> (Intercept)          3.04   0.17    17.81   0.00 #> outcome2            -0.45   0.20    -2.25   0.02 #> outcome3            -0.29   0.19    -1.52   0.13 #> treatment2           0.00   0.20     0.00   1.00 #> treatment3           0.00   0.20     0.00   1.00 #> ------------------------------------------------ #>  #> Continuous predictors are mean-centered and scaled by 1 s.d."},{"path":"/reference/summ.html","id":null,"dir":"Reference","previous_headings":"","what":"Regression summaries with options — summ","title":"Regression summaries with options — summ","text":"get specific documentation, choose appropriate link type model want summarize details section.","code":""},{"path":"/reference/summ.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regression summaries with options — summ","text":"","code":"summ(model, ...)  j_summ(model, ...)"},{"path":"/reference/summ.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regression summaries with options — summ","text":"model lm, glm, svyglm, merMod, rq object. ... arguments passed model-specific function.","code":""},{"path":"/reference/summ.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Regression summaries with options — summ","text":"summ.lm summ.glm summ.svyglm summ.merMod summ.rq","code":""},{"path":"/reference/summ.lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear regression summaries with options — summ.lm","title":"Linear regression summaries with options — summ.lm","text":"summ() prints output regression model fashion similar summary(), formatted differently options.","code":""},{"path":"/reference/summ.lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear regression summaries with options — summ.lm","text":"","code":"# S3 method for lm summ(   model,   scale = FALSE,   confint = getOption(\"summ-confint\", FALSE),   ci.width = getOption(\"summ-ci.width\", 0.95),   robust = getOption(\"summ-robust\", FALSE),   cluster = NULL,   vifs = getOption(\"summ-vifs\", FALSE),   digits = getOption(\"jtools-digits\", 2),   pvals = getOption(\"summ-pvals\", TRUE),   n.sd = 1,   center = FALSE,   transform.response = FALSE,   scale.only = FALSE,   data = NULL,   part.corr = FALSE,   model.info = getOption(\"summ-model.info\", TRUE),   model.fit = getOption(\"summ-model.fit\", TRUE),   which.cols = NULL,   vcov = NULL,   ... )"},{"path":"/reference/summ.lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear regression summaries with options — summ.lm","text":"model lm object. scale TRUE, reports standardized regression coefficients scaling mean-centering input data (latter can changed via scale.argument). Default FALSE. confint Show confidence intervals instead standard errors? Default FALSE. ci.width number 0 1 signifies width desired confidence interval. Default .95, corresponds 95% confidence interval. Ignored confint = FALSE. robust FALSE, reports heteroskedasticity-robust standard errors instead conventional SEs. also known Huber-White standard errors. several options provided sandwich::vcovHC(): \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". Default FALSE. requires sandwich package compute standard errors. cluster clustered standard errors, provide column name cluster variable input data frame (string). Alternately, provide vector clusters. Note must set robust either \"HC1\", \"HC2\", \"HC3\" order clustered standard errors (\"HC4\" \"HC5\" supported. vifs TRUE, adds column output variance inflation factors (VIF). Default FALSE. digits integer specifying number digits past decimal report output. Default 2. can change default number digits jtools functions options(\"jtools-digits\" = digits) digits desired number. pvals Show p values? FALSE, printed. Default TRUE. n.sd scale = TRUE, many standard deviations predictors divided ? Default 1, though suggest 2. center want coefficients mean-centered variables want standardize, set TRUE. Note setting false affect whether scale mean-centers variables. Use scale.. transform.response scaling/centering apply response variable? Default FALSE. scale.want scale center, set TRUE. Note legacy reasons, setting scale = TRUE center = FALSE achieve effect. Default FALSE. data provide data used fit model , data frame used re-fit model (scale TRUE) instead stats::model.frame() model. particularly useful variable transformations polynomial terms specified formula. part.corr Print partial (labeled \"partial.r\") semipartial (labeled \"part.r\") correlations table? Default FALSE. See details quantities robust standard errors used. model.info Toggles printing basic information sample size, name DV, number predictors. model.fit Toggles printing model fit statistics. .cols Developmental feature. providing columns name, can add/remove/reorder requested columns output. fully supported, now. vcov may provide variance-covariance matrix regression coefficients want calculate standard errors way accommodated robust cluster options. ... Among things, arguments passed scale_mod() center_mod() center scale TRUE.","code":""},{"path":"/reference/summ.lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linear regression summaries with options — summ.lm","text":"saved, users can access items returned output (without rounding). coeftable outputted table variables coefficients model model statistics displayed. useful cases scale = TRUE. Much information can accessed attributes.","code":""},{"path":"/reference/summ.lm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear regression summaries with options — summ.lm","text":"default, function print following items console: sample size name outcome variable R-squared value plus adjusted R-squared table regression coefficients, standard errors, t-values, p values. several options available robust. heavy lifting done sandwich::vcovHC(), better described. Put simply, may choose \"HC0\" \"HC5\". Based recommendation developers sandwich, default set \"HC3\". Stata's default \"HC1\", choice may better goal replicate Stata's output. option understood vcovHC() accepted. Cluster-robust standard errors computed cluster set name input data's cluster variable vector clusters. scale center options performed via refitting model scale_mod() center_mod(), respectively. turn uses gscale() mean-centering scaling. using part.corr = TRUE, get two common effect size metrics far right two columns output table. However, noted go hand hand robust standard error estimators. standard error coefficient change point estimate, just uncertainty. However, function uses t-statistics calculation partial semipartial correlation. provides amounts heteroskedasticity-adjusted set estimates, unaware statistical publication validates type use. Please use heuristic used alongside robust standard errors; report \"robust\" partial semipartial correlations publications.","code":""},{"path":"/reference/summ.lm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Linear regression summaries with options — summ.lm","text":"King, G., & Roberts, M. E. (2015). robust standard errors expose methodological problems fix, . Political Analysis, 23(2), 159–179. doi: 10.1093/pan/mpu015 Lumley, T., Diehr, P., Emerson, S., & Chen, L. (2002). Importance Normality Assumption Large Public Health Data Sets. Annual Review Public Health, 23, 151–169. doi: 10.1146/annurev.publhealth.23.100901.140546","code":""},{"path":[]},{"path":"/reference/summ.lm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Linear regression summaries with options — summ.lm","text":"Jacob Long jacob.long@sc.edu","code":""},{"path":"/reference/summ.lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linear regression summaries with options — summ.lm","text":"","code":"# Create lm object fit <- lm(Income ~ Frost + Illiteracy + Murder,           data = as.data.frame(state.x77))  # Print the output with standardized coefficients and 3 digits summ(fit, scale = TRUE, digits = 3) #> MODEL INFO: #> Observations: 50 #> Dependent Variable: Income #> Type: OLS linear regression  #>  #> MODEL FIT: #> F(3,46) = 4.049, p = 0.012 #> R² = 0.209 #> Adj. R² = 0.157  #>  #> Standard errors: OLS #> ------------------------------------------------------- #>                         Est.      S.E.   t val.       p #> ----------------- ---------- --------- -------- ------- #> (Intercept)         4435.800    79.773   55.605   0.000 #> Frost                -65.188   109.686   -0.594   0.555 #> Illiteracy          -372.251   129.914   -2.865   0.006 #> Murder                85.179   114.217    0.746   0.460 #> ------------------------------------------------------- #>  #> Continuous predictors are mean-centered and scaled by 1 s.d."},{"path":"/reference/summ.merMod.html","id":null,"dir":"Reference","previous_headings":"","what":"Mixed effects regression summaries with options — summ.merMod","title":"Mixed effects regression summaries with options — summ.merMod","text":"summ() prints output regression model fashion similar summary(), formatted differently options.","code":""},{"path":"/reference/summ.merMod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mixed effects regression summaries with options — summ.merMod","text":"","code":"# S3 method for merMod summ(   model,   scale = FALSE,   confint = getOption(\"summ-confint\", FALSE),   ci.width = getOption(\"summ-ci.width\", 0.95),   conf.method = getOption(\"summ-conf.method\", c(\"Wald\", \"profile\", \"boot\")),   digits = getOption(\"jtools-digits\", default = 2),   r.squared = TRUE,   pvals = getOption(\"summ-pvals\", NULL),   n.sd = 1,   center = FALSE,   transform.response = FALSE,   scale.only = FALSE,   data = NULL,   exp = FALSE,   t.df = NULL,   model.info = getOption(\"summ-model.info\", TRUE),   model.fit = getOption(\"summ-model.fit\", TRUE),   re.variance = getOption(\"summ-re.variance\", c(\"sd\", \"var\")),   which.cols = NULL,   re.table = getOption(\"summ-re.table\", TRUE),   groups.table = getOption(\"summ-groups.table\", TRUE),   ... )"},{"path":"/reference/summ.merMod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mixed effects regression summaries with options — summ.merMod","text":"model merMod object. scale TRUE, reports standardized regression coefficients scaling mean-centering input data (latter can changed via scale.argument). Default FALSE. confint Show confidence intervals instead standard errors? Default FALSE. ci.width number 0 1 signifies width desired confidence interval. Default .95, corresponds 95% confidence interval. Ignored confint = FALSE. conf.method Argument passed lme4::confint.merMod(). Default \"Wald\", \"profile\" \"boot\" better accuracy priority. aware alternate methods sometimes time-consuming. digits integer specifying number digits past decimal report output. Default 2. can change default number digits jtools functions options(\"jtools-digits\" = digits) digits desired number. r.squared Calculate r-squared model fit statistic? Default TRUE, errors takes long time calculate may want consider setting FALSE. pvals Show p values? FALSE, printed. Default TRUE, except merMod objects (see details). n.sd scale = TRUE, many standard deviations predictors divided ? Default 1, though suggest 2. center want coefficients mean-centered variables want standardize, set TRUE. Note setting false affect whether scale mean-centers variables. Use scale.. transform.response scaling/centering apply response variable? Default FALSE. scale.want scale center, set TRUE. Note legacy reasons, setting scale = TRUE center = FALSE achieve effect. Default FALSE. data provide data used fit model , data frame used re-fit model (scale TRUE) instead stats::model.frame() model. particularly useful variable transformations polynomial terms specified formula. exp TRUE, reports exponentiated coefficients confidence intervals exponential models like logit Poisson models. quantity known odds ratio binary outcomes incidence rate ratio count models. t.df lmerMod models . User may set degrees freedom used conducting t-tests. See details options. model.info Toggles printing basic information sample size, name DV, number predictors. model.fit Toggles printing model fit statistics. re.variance random effects variances expressed standard deviations variances? Default, consistent previous versions jtools, \"sd\". Use \"var\" get variance instead. .cols Developmental feature. providing columns name, can add/remove/reorder requested columns output. fully supported, now. re.table Show table summarizing variance random effects? Default TRUE. groups.table Show table summarizing grouping variables? Default TRUE. ... Among things, arguments passed scale_mod() center_mod() center scale TRUE.","code":""},{"path":"/reference/summ.merMod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mixed effects regression summaries with options — summ.merMod","text":"saved, users can access items returned output (without rounding). coeftable outputted table variables coefficients rcoeftable secondary table grouping variables random coefficients. gvars tertiary table grouping variables, numbers groups, ICCs. model model statistics displayed. useful cases scale = TRUE. Much information can accessed attributes.","code":""},{"path":"/reference/summ.merMod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mixed effects regression summaries with options — summ.merMod","text":"default, function print following items console: sample size name outcome variable (Pseudo-)R-squared value AIC/BIC. table regression coefficients, standard errors, t-values. scale center options performed via refitting model scale_mod() center_mod(), respectively. turn uses gscale() mean-centering scaling. merMod models bit different others. lme4 package developers , instance, made decision report compute p values lmer() models. good reasons , notably t-values produced \"accurate\" sense Type error rate. certain large, balanced samples many groups, big deal. \"big\" \"small\" sample? much balance necessary? type random effects structure okay? Good luck getting statistician give clear guidelines . simulation studies done fewer 100 observations, sure sample around 100 fewer interpret t-values. large number groups also crucial avoiding bias using t-values. groups nested crossed linear model, best just get pbkrtest package. default, function follows lme4's lead report p values lmer() models. user pbkrtest installed, however, p values reported using Kenward-Roger d.f. approximation unless pvals = FALSE t.df set something NULL. publications, cite Kenward & Roger (1997) piece well either package pbkrtest package explain p values calculated. See pvalues lme4 details. looking simple test extra packages installed, better use confidence intervals check see exclude zero use t-test. users glmer(), see advice well. lme4 association summ() well, still imperfect. options customize output regard t.df argument. NULL, default, degrees freedom used depends whether user lmerTest pbkrtest installed. lmerTest installed, degrees freedom coefficient calculated using Satterthwaite method p values calculated accordingly. pbkrtest installed t.df \"k-r\", Kenward-Roger approximation standard errors degrees freedom coefficient used. Note Kenward-Roger standard errors can take longer calculate may cause R crash models fit large (roughly greater 5000 rows) datasets. neither installed user sets pvals = TRUE, residual degrees freedom used. t.df = \"residual\", residual d.f. used without message. user prefers use method determine d.f., number provided argument used. pseudo-R^2 one way calculate R^2 mixed models nonlinear models. Many caution interpreting even using approximations outside OLS regression. said, package reports one version benefit, though course understand unambiguous measure model fit. package calculates R^2 mixed models using adapted version rsquared() piecewiseSEM package. implementation Nakagawa & Schielzeth (2013) procedure refinements Johnson (2014). choose report pseudo-R^2 publication, cite Nakagawa & Schielzeth explain calculation done.","code":""},{"path":"/reference/summ.merMod.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mixed effects regression summaries with options — summ.merMod","text":"Johnson, P. C. D. (2014). Extension Nakagawa & Schielzeth's $R^2_GLMM$ random slopes models. Methods Ecology Evolution, 5, 944–946. doi: 10.1111/2041-210X.12225 Kenward, M. G., & Roger, J. H. (1997). Small sample inference fixed effects restricted maximum likelihood. Biometrics, 53, 983. doi: 10.2307/2533558 Kuznetsova, ., Brockhoff, P. B., & Christensen, R. H. B. (2017). lmerTest package: Tests linear mixed effects models. Journal Statistical Software, 82. doi: 10.18637/jss.v082.i13 Luke, S. G. (2017). Evaluating significance linear mixed-effects models R. Behavior Research Methods, 49, 1494–1502. doi: 10.3758/s13428-016-0809-y Nakagawa, S., & Schielzeth, H. (2013). general simple method obtaining $R^2$ generalized linear mixed-effects models. Methods Ecology Evolution, 4, 133–142. doi: 10.1111/j.2041-210x.2012.00261.x","code":""},{"path":[]},{"path":"/reference/summ.merMod.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mixed effects regression summaries with options — summ.merMod","text":"Jacob Long jacob.long@sc.edu","code":""},{"path":"/reference/summ.merMod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mixed effects regression summaries with options — summ.merMod","text":"","code":"if (requireNamespace(\"lme4\")) {   library(lme4, quietly = TRUE)   data(sleepstudy)   mv <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)    summ(mv) # Note lack of p values if you don't have lmerTest/pbkrtest    # Without lmerTest/pbkrtest, you'll get message about Type 1 errors   summ(mv, pvals = TRUE)    # To suppress message, manually specify t.df argument   summ(mv, t.df = \"residual\")    # Confidence intervals may be better alternative to p values   summ(mv, confint = TRUE)   # Use conf.method to get profile intervals (may be slow to run)   # summ(mv, confint = TRUE, conf.method = \"profile\")  } #> MODEL INFO: #> Observations: 180 #> Dependent Variable: Reaction #> Type: Mixed effects linear regression  #>  #> MODEL FIT: #> AIC = 1755.63, BIC = 1774.79 #> Pseudo-R² (fixed effects) = 0.28 #> Pseudo-R² (total) = 0.80  #>  #> FIXED EFFECTS: #> -------------------------------------------------------------------- #>                       Est.     2.5%    97.5%   t val.    d.f.      p #> ----------------- -------- -------- -------- -------- ------- ------ #> (Intercept)         251.41   238.03   264.78    36.84   17.00   0.00 #> Days                 10.47     7.44    13.50     6.77   17.00   0.00 #> -------------------------------------------------------------------- #>  #> p values calculated using Satterthwaite d.f. #>  #> RANDOM EFFECTS: #> ------------------------------------ #>   Group      Parameter    Std. Dev.  #> ---------- ------------- ----------- #>  Subject    (Intercept)     24.74    #>  Subject       Days         5.92     #>  Residual                   25.59    #> ------------------------------------ #>  #> Grouping variables: #> --------------------------- #>   Group    # groups   ICC   #> --------- ---------- ------ #>  Subject      18      0.48  #> ---------------------------"},{"path":"/reference/summ.rq.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile regression summaries with options — summ.rq","title":"Quantile regression summaries with options — summ.rq","text":"summ() prints output regression model fashion similar summary(), formatted differently options.","code":""},{"path":"/reference/summ.rq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile regression summaries with options — summ.rq","text":"","code":"# S3 method for rq summ(   model,   scale = FALSE,   confint = getOption(\"summ-confint\", FALSE),   ci.width = getOption(\"summ-ci.width\", 0.95),   se = c(\"nid\", \"rank\", \"iid\", \"ker\", \"boot\"),   boot.sims = 1000,   boot.method = \"xy\",   vifs = getOption(\"summ-vifs\", FALSE),   digits = getOption(\"jtools-digits\", 2),   pvals = getOption(\"summ-pvals\", TRUE),   n.sd = 1,   center = FALSE,   transform.response = FALSE,   data = NULL,   model.info = getOption(\"summ-model.info\", TRUE),   model.fit = getOption(\"summ-model.fit\", TRUE),   which.cols = NULL,   ... )"},{"path":"/reference/summ.rq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile regression summaries with options — summ.rq","text":"model rq model. time, rqs models (multiple tau parameters) supported. scale TRUE, reports standardized regression coefficients scaling mean-centering input data (latter can changed via scale.argument). Default FALSE. confint Show confidence intervals instead standard errors? Default FALSE. ci.width number 0 1 signifies width desired confidence interval. Default .95, corresponds 95% confidence interval. Ignored confint = FALSE. se One \"nid\", \"rank\", \"iid\", \"ker\", \"boot\". \"nid\" default. See quantreg::summary.rq() documentation options. boot.sims se = \"boot\", number bootstrap replications perform. passed R argument boot.rq boot.method se = \"boot\", type bootstrapping method use. Default \"xy\", see quantreg::boot.rq() options. vifs TRUE, adds column output variance inflation factors (VIF). Default FALSE. digits integer specifying number digits past decimal report output. Default 2. can change default number digits jtools functions options(\"jtools-digits\" = digits) digits desired number. pvals Show p values? FALSE, printed. Default TRUE. n.sd scale = TRUE, many standard deviations predictors divided ? Default 1, though suggest 2. center want coefficients mean-centered variables want standardize, set TRUE. Note setting false affect whether scale mean-centers variables. Use scale.. transform.response scaling/centering apply response variable? Default FALSE. data provide data used fit model , data frame used re-fit model (scale TRUE) instead stats::model.frame() model. particularly useful variable transformations polynomial terms specified formula. model.info Toggles printing basic information sample size, name DV, number predictors. model.fit Toggles printing model fit statistics. .cols Developmental feature. providing columns name, can add/remove/reorder requested columns output. fully supported, now. ... Among things, arguments passed scale_mod() center_mod() center scale TRUE.","code":""},{"path":"/reference/summ.rq.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantile regression summaries with options — summ.rq","text":"method implements things think users asking summary.rq . hs, U, gamma ignored. Note using se = \"rank\", standard errors, test statistics, p values calculated. R1 fit statistic: Described Koenker \\& Machado (1999), offers interpretation similar R-squared OLS regression. calculate R-squared models, goes underlying theoretical rationale . Koenker big fan R1 either, something. See Koenker \\& Machado (1999) info.","code":""},{"path":"/reference/summ.rq.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Quantile regression summaries with options — summ.rq","text":"Koenker, R., & Machado, J. . F. (1999). Goodness fit related inference processes quantile regression. Journal American Statistical Association, 94, 1296–1310. https://doi.org/10.1080/01621459.1999.10473882","code":""},{"path":[]},{"path":"/reference/summ.rq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile regression summaries with options — summ.rq","text":"","code":"if (requireNamespace(\"quantreg\")) {  library(quantreg)  data(engel)  fitrq <- rq(income ~ foodexp, data = engel, tau = 0.5)  summ(fitrq) } #> Loading required namespace: quantreg #> Loading required package: SparseM #>  #> Attaching package: ‘SparseM’ #> The following object is masked from ‘package:base’: #>  #>     backsolve #>  #> Attaching package: ‘quantreg’ #> The following object is masked from ‘package:survival’: #>  #>     untangle.specials #> MODEL INFO: #> Observations: 235 #> Dependent Variable: income #> Type: Quantile regression #>   Quantile (tau): 0.5 #>   Method: Barrodale-Roberts  #>  #> MODEL FIT: #> R¹(0.5) = 0.64  #>  #> Standard errors: Sandwich (Huber) #> -------------------------------------------------- #>                       Est.    S.E.   t val.      p #> ----------------- -------- ------- -------- ------ #> (Intercept)         -14.96   28.69    -0.52   0.60 #> foodexp               1.55    0.06    26.66   0.00 #> --------------------------------------------------"},{"path":"/reference/summ.svyglm.html","id":null,"dir":"Reference","previous_headings":"","what":"Complex survey regression summaries with options — summ.svyglm","title":"Complex survey regression summaries with options — summ.svyglm","text":"summ() prints output regression model fashion similar summary(), formatted differently options.","code":""},{"path":"/reference/summ.svyglm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Complex survey regression summaries with options — summ.svyglm","text":"","code":"# S3 method for svyglm summ(   model,   scale = FALSE,   confint = getOption(\"summ-confint\", FALSE),   ci.width = getOption(\"summ-ci.width\", 0.95),   digits = getOption(\"jtools-digits\", default = 2),   pvals = getOption(\"summ-pvals\", TRUE),   n.sd = 1,   center = FALSE,   transform.response = FALSE,   scale.only = FALSE,   exp = FALSE,   vifs = getOption(\"summ-vifs\", FALSE),   model.info = getOption(\"summ-model.info\", TRUE),   model.fit = getOption(\"summ-model.fit\", TRUE),   which.cols = NULL,   ... )"},{"path":"/reference/summ.svyglm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Complex survey regression summaries with options — summ.svyglm","text":"model svyglm object. scale TRUE, reports standardized regression coefficients scaling mean-centering input data (latter can changed via scale.argument). Default FALSE. confint Show confidence intervals instead standard errors? Default FALSE. ci.width number 0 1 signifies width desired confidence interval. Default .95, corresponds 95% confidence interval. Ignored confint = FALSE. digits integer specifying number digits past decimal report output. Default 2. can change default number digits jtools functions options(\"jtools-digits\" = digits) digits desired number. pvals Show p values? FALSE, printed. Default TRUE. n.sd scale = TRUE, many standard deviations predictors divided ? Default 1, though suggest 2. center want coefficients mean-centered variables want standardize, set TRUE. Note setting false affect whether scale mean-centers variables. Use scale.. transform.response scaling/centering apply response variable? Default FALSE. scale.want scale center, set TRUE. Note legacy reasons, setting scale = TRUE center = FALSE achieve effect. Default FALSE. exp TRUE, reports exponentiated coefficients confidence intervals exponential models like logit Poisson models. quantity known odds ratio binary outcomes incidence rate ratio count models. vifs TRUE, adds column output variance inflation factors (VIF). Default FALSE. model.info Toggles printing basic information sample size, name DV, number predictors. model.fit Toggles printing model fit statistics. .cols Developmental feature. providing columns name, can add/remove/reorder requested columns output. fully supported, now. ... Among things, arguments passed scale_mod() center_mod() center scale TRUE.","code":""},{"path":"/reference/summ.svyglm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Complex survey regression summaries with options — summ.svyglm","text":"saved, users can access items returned output (without rounding). coeftable outputted table variables coefficients model model statistics displayed. useful cases scale = TRUE. Much information can accessed attributes.","code":""},{"path":"/reference/summ.svyglm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Complex survey regression summaries with options — summ.svyglm","text":"default, function print following items console: sample size name outcome variable (Pseudo-)R-squared value AIC. table regression coefficients, standard errors, t values, p values. scale center options performed via refitting model scale_mod() center_mod(), respectively. turn uses gscale() mean-centering scaling. functions can handle svyglm objects correctly calling svymean() svyvar() compute means standard deviations. Weights altered. fact model refit means runtime similar original time took fit model.","code":""},{"path":[]},{"path":"/reference/summ.svyglm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Complex survey regression summaries with options — summ.svyglm","text":"Jacob Long jacob.long@sc.edu","code":""},{"path":"/reference/summ.svyglm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Complex survey regression summaries with options — summ.svyglm","text":"","code":"if (requireNamespace(\"survey\")) {   library(survey)   data(api)   dstrat <- svydesign(id = ~1, strata =~ stype, weights =~ pw,                       data = apistrat, fpc =~ fpc)   regmodel <- svyglm(api00 ~ ell * meals, design = dstrat)    summ(regmodel) } #> MODEL INFO: #> Observations: 200 #> Dependent Variable: api00 #> Type: Survey-weighted linear regression  #>  #> MODEL FIT: #> R² = 0.66 #> Adj. R² = 0.66  #>  #> Standard errors: Robust #> -------------------------------------------------- #>                       Est.    S.E.   t val.      p #> ----------------- -------- ------- -------- ------ #> (Intercept)         836.62   10.99    76.10   0.00 #> ell                  -1.69    1.01    -1.67   0.10 #> meals                -3.32    0.28   -11.99   0.00 #> ell:meals             0.02    0.01     1.42   0.16 #> -------------------------------------------------- #>  #> Estimated dispersion parameter = 5118.85"},{"path":"/reference/svycor.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Pearson correlations with complex survey data — svycor","title":"Calculate Pearson correlations with complex survey data — svycor","text":"svycor extends survey package calculating correlations syntax similar original package, reasons unknown lacks function.","code":""},{"path":"/reference/svycor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Pearson correlations with complex survey data — svycor","text":"","code":"svycor(   formula,   design,   na.rm = FALSE,   digits = getOption(\"jtools-digits\", default = 2),   sig.stats = FALSE,   bootn = 1000,   mean1 = TRUE,   ... )"},{"path":"/reference/svycor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Pearson correlations with complex survey data — svycor","text":"formula formula (e.g., ~var1+var2) specifying terms correlate. design survey.design svyrep.design object. na.rm Logical. cases missing values dropped? digits integer specifying number digits past decimal report output. Default 2. can change default number digits jtools functions options(\"jtools-digits\" = digits) digits desired number. sig.stats Logical. Perform non-parametric bootstrapping (using wtd.cor) generate standard errors associated t- p-values. See details considerations null hypothesis testing complex survey correlations. bootn sig.stats TRUE, defines number bootstraps run generate standard errors p-values. large values large datasets, can contribute considerably processing time. mean1 sig.stats TRUE, important know whether sampling weights mean 1. , standard errors calculated number rows dataset total number observations (TRUE) sum weights dataset total number observations (FALSE)? ... Additional arguments passed svyvar().","code":""},{"path":"/reference/svycor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Pearson correlations with complex survey data — svycor","text":"significance tests requested, one returned value: cors correlation matrix (without rounding) significance tests requested, following also returned: p.values matrix p values t.values matrix t values std.err matrix standard errors","code":""},{"path":"/reference/svycor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Pearson correlations with complex survey data — svycor","text":"function extends survey package calculating correlations user-specified variables survey design returning correlation matrix. Using wtd.cor function, function also returns standard errors p-values correlation terms using sample-weighted bootstrapping procedure. correlations require distributional assumptions, hypothesis testing (.e., \\(r > 0\\)) . appropriate way calculate standard errors use define probability straightforward scenario since weighting causes heteroskedasticity, thereby violating assumption inherent commonly used methods converting Pearson's correlations t-values. method provided defensible, reporting scientific publications method spelled .","code":""},{"path":"/reference/svycor.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate Pearson correlations with complex survey data — svycor","text":"function designed part procedure recommended Thomas Lumley, author survey package, Stack Overflow. However, reviewed endorsed implementation. defects attributed author.","code":""},{"path":[]},{"path":"/reference/svycor.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate Pearson correlations with complex survey data — svycor","text":"Jacob Long jacob.long@sc.edu","code":""},{"path":"/reference/svycor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Pearson correlations with complex survey data — svycor","text":"","code":"if (requireNamespace(\"survey\")) {  library(survey)  data(api)  # Create survey design object  dstrat <- svydesign(id = ~1, strata = ~stype, weights = ~pw,                      data = apistrat, fpc = ~fpc)   # Print correlation matrix  svycor(~api00 + api99 + dnum, design = dstrat)   # Save the results, extract correlation matrix  out <- svycor(~api00 + api99 + dnum, design = dstrat)  out$cors  } #>           api00     api99      dnum #> api00 1.0000000 0.9759047 0.2543484 #> api99 0.9759047 1.0000000 0.2441910 #> dnum  0.2543484 0.2441910 1.0000000"},{"path":"/reference/svysd.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate standard deviations with complex survey data — svysd","title":"Calculate standard deviations with complex survey data — svysd","text":"svysd extends survey package calculating standard deviations syntax similar original package, provides svyvar() function.","code":""},{"path":"/reference/svysd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate standard deviations with complex survey data — svysd","text":"","code":"svysd(   formula,   design,   na.rm = FALSE,   digits = getOption(\"jtools-digits\", default = 3),   ... )"},{"path":"/reference/svysd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate standard deviations with complex survey data — svysd","text":"formula formula (e.g., ~var1+var2) specifying term(s) interest. design survey.design svyrep.design object. na.rm Logical. cases missing values dropped? digits integer specifying number digits past decimal report output. Default 3. can change default number digits jtools functions options(\"jtools-digits\" = digits) digits desired number. ... Additional arguments passed svyvar().","code":""},{"path":"/reference/svysd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate standard deviations with complex survey data — svysd","text":"alternative simply sqrt(svyvar(~term, design = design)). However, printing sharing output, may misleading since output say \"variance.\"","code":""},{"path":"/reference/svysd.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate standard deviations with complex survey data — svysd","text":"function designed independent survey package neither endorsed known authors.","code":""},{"path":[]},{"path":"/reference/svysd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate standard deviations with complex survey data — svysd","text":"","code":"if (requireNamespace(\"survey\")) {  library(survey)  data(api)  # Create survey design object  dstrat <- svydesign(id = ~1,strata = ~stype, weights = ~pw, data = apistrat,                      fpc=~fpc)   # Print the standard deviation of some variables  svysd(~api00+ell+meals, design = dstrat) } #>       std. dev. #> api00   123.250 #> ell      21.267 #> meals    29.503"},{"path":"/reference/theme_apa.html","id":null,"dir":"Reference","previous_headings":"","what":"Format ggplot2 figures in APA style — theme_apa","title":"Format ggplot2 figures in APA style — theme_apa","text":"theme_apa() designed work like complete theme ggplot. extent possible, aligns (vague) APA figure guidelines.","code":""},{"path":"/reference/theme_apa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format ggplot2 figures in APA style — theme_apa","text":"","code":"theme_apa(   legend.pos = \"right\",   legend.use.title = FALSE,   legend.font.size = 12,   x.font.size = 12,   y.font.size = 12,   facet.title.size = 12,   remove.y.gridlines = TRUE,   remove.x.gridlines = TRUE )"},{"path":"/reference/theme_apa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format ggplot2 figures in APA style — theme_apa","text":"legend.pos One \"right\", \"left\", \"top\", \"bottom\", \"topleft\", \"topright\", \"topmiddle\", \"bottomleft\", \"bottomright\", \"bottommiddle\". Positions legend, layer top geoms, plane. legend.use.title Logical. Specify whether include legend title. Defaults FALSE. legend.font.size Integer indicating font size labels legend. Default APA-recommended 12, many labels may necessary choose smaller size. x.font.size Font size x-axis label. y.font.size Font size x-axis label. facet.title.size Font size facet labels. remove.y.gridlines coordinate grid y-axis (horizontal lines) removed? Default TRUE. remove.x.gridlines coordinate grid x-axis (vertical lines) removed? Default TRUE.","code":""},{"path":"/reference/theme_apa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Format ggplot2 figures in APA style — theme_apa","text":"function applies theme ggplot2 figures style roughly line APA guidelines. Users may need perform operations specific use cases. things keep mind APA style figures: Main titles written word processor typesetter rather plot image . cases, users can forgo legend favor describing figure caption (also written word processor/typesetter). Legends typically embedded coordinate plane figure rather next , default ggplot2. Use color generally discouraged since applications APA figures needed involve eventual publication non-color print media. hard fast rules font size, though APA recommends choosing 8 14-point. Fonts figures sans serif. APA style calls positioning legends plane , function includes options choosing position--top left, top right, bottom left, bottom right--place legend. ggplot2 provides obvious way automatically choose position overlaps least geoms (plotted data), users need choose one. Facetting supported, APA guidelines considerably less clear situations. theme created inspiration Rudolf Cardinal's code, required updating newer versions ggplot2 adaptations APA style.","code":""},{"path":"/reference/theme_apa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Format ggplot2 figures in APA style — theme_apa","text":"American Psychological Association. (2010). Publication manual American Psychological Association, Sixth Edition. Washington, DC: American Psychological Association. Nicol, ..M. & Pexman, P.M. (2010). Displaying findings: practical guide creating figures, posters, presentations, Sixth Edition. Washington, D.C.: American Psychological Association.","code":""},{"path":[]},{"path":"/reference/theme_apa.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Format ggplot2 figures in APA style — theme_apa","text":"Jacob Long jacob.long@sc.edu","code":""},{"path":"/reference/theme_apa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format ggplot2 figures in APA style — theme_apa","text":"","code":"# Create plot with ggplot2 library(ggplot2) plot <- ggplot(mpg, aes(cty, hwy)) +   geom_jitter()  # Add APA theme with defaults plot + theme_apa()"},{"path":"/reference/theme_nice.html","id":null,"dir":"Reference","previous_headings":"","what":"A nice, flexible ggplot2 theme — theme_nice","title":"A nice, flexible ggplot2 theme — theme_nice","text":"theme_nice designed work like complete theme ggplot. nice appearance.","code":""},{"path":"/reference/theme_nice.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A nice, flexible ggplot2 theme — theme_nice","text":"","code":"theme_nice(   legend.pos = \"right\",   style = c(\"white\", \"light\", \"dark_blue\", \"dark_gray\"),   base_size = 11,   base_family = \"\",   base_line_size = base_size/22,   base_rect_size = base_size/22 )"},{"path":"/reference/theme_nice.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A nice, flexible ggplot2 theme — theme_nice","text":"legend.pos One \"right\", \"left\", \"top\", \"bottom\" (outside plotting area), \"topleft\", \"topright\", \"topmiddle\", \"bottomleft\", \"bottomright\", \"bottommiddle\" (inside plotting area). style One \"white\", \"light\", \"dark_blue\", \"dark_gray\". \"white\" sets background white, \"light\" light gray, \"dark_gray\" dark gray, \"dark_blue\" dark blue. base_size base font size, given pts. base_family base font family base_line_size base size line elements base_rect_size base size rect elements","code":""},{"path":"/reference/theme_nice.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A nice, flexible ggplot2 theme — theme_nice","text":"Jacob Long jacob.long@sc.edu","code":""},{"path":"/reference/theme_nice.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A nice, flexible ggplot2 theme — theme_nice","text":"","code":"# Create plot with ggplot2 library(ggplot2) plot <- ggplot(mpg, aes(cty, hwy)) +   geom_jitter() + theme_nice()"},{"path":"/reference/weights_tests.html","id":null,"dir":"Reference","previous_headings":"","what":"Test whether sampling weights are needed — weights_tests","title":"Test whether sampling weights are needed — weights_tests","text":"Use tests proposed Pfeffermann Sverchkov (1999) DuMouchel Duncan (1983) check whether regression model specified correctly without weights.","code":""},{"path":"/reference/weights_tests.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test whether sampling weights are needed — weights_tests","text":"","code":"weights_tests(   model,   weights,   data,   model_output = TRUE,   test = NULL,   sims = 1000,   digits = getOption(\"jtools-digits\", default = 2) )"},{"path":"/reference/weights_tests.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test whether sampling weights are needed — weights_tests","text":"model fitted model, without weights weights name weights column model's data frame vector weights equal length number observations included model. data data frame data fed fitted model weights model_output summary model weights predictor printed? Default TRUE, may want trying declutter document. test type test used ANOVA? default, NULL, chooses based model type (\"F\" linear models). argument passed anova. sims number bootstrap simulations use estimating variance residual correlation. Default 1000, publications computing power/time sufficient, higher number better. digits integer specifying number digits past decimal report output. Default 3. can change default number digits jtools functions options(\"jtools-digits\" = digits) digits desired number.","code":""},{"path":"/reference/weights_tests.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test whether sampling weights are needed — weights_tests","text":"function wrapper two tests implemented package test whether regression model correctly specified. first wgttest, R adaptation Stata macro name. test can otherwise referred DuMouchel-Duncan test. test Pfeffermann-Sverchkov test, can accessed directly pf_sv_test. details , visit documentation respective functions. function just runs .","code":""},{"path":"/reference/weights_tests.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Test whether sampling weights are needed — weights_tests","text":"DuMouchel, W. H. & Duncan, D.J. (1983). Using sample survey weights multiple regression analyses stratified samples. Journal American Statistical Association, 78. 535-543. Nordberg, L. (1989). Generalized linear modeling sample survey data. Journal Official Statistics; Stockholm, 5, 223-239. Pfeffermann, D., & Sverchkov, M. (1999). Parametric semi-parametric estimation regression models fitted survey data. Sankhya: Indian Journal Statistics, 61. 166-186.","code":""},{"path":[]},{"path":"/reference/weights_tests.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test whether sampling weights are needed — weights_tests","text":"","code":"# Note: This is a contrived example to show how the function works, # not a case with actual sammpling weights from a survey vendor if (requireNamespace(\"boot\")) {   states <- as.data.frame(state.x77)   set.seed(100)   states$wts <- runif(50, 0, 3)   fit <- lm(Murder ~ Illiteracy + Frost, data = states)   weights_tests(model = fit, data = states, weights = wts, sims = 100) } #> DuMouchel-Duncan test of model change with weights #>  #> F(3,44) = 0.674 #> p = 0.572 #>  #> Lower p values indicate greater influence of the weights. #>  #> Standard errors: OLS #> --------------------------------------------------- #>                         Est.   S.E.   t val.      p #> -------------------- ------- ------ -------- ------ #> (Intercept)             2.68   4.80     0.56   0.58 #> Illiteracy              5.01   1.93     2.60   0.01 #> wts                     1.01   2.78     0.36   0.72 #> Frost                  -0.00   0.03    -0.15   0.88 #> Illiteracy:wts         -0.96   1.17    -0.83   0.41 #> wts:Frost              -0.00   0.01    -0.24   0.81 #> --------------------------------------------------- #>  #> --- #> Pfeffermann-Sverchkov test of sample weight ignorability  #>  #> Residual correlation = -0.16, p = 0.33 #> Squared residual correlation = 0.25, p = 0.11 #> Cubed residual correlation = -0.00, p = 1.00 #>  #> A significant correlation may indicate biased estimates #> in the unweighted model."},{"path":"/reference/wgttest.html","id":null,"dir":"Reference","previous_headings":"","what":"Test whether sampling weights are needed — wgttest","title":"Test whether sampling weights are needed — wgttest","text":"Use DuMouchel-Duncan (1983) test assess need sampling weights linear regression analysis.","code":""},{"path":"/reference/wgttest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test whether sampling weights are needed — wgttest","text":"","code":"wgttest(   model,   weights,   data = NULL,   model_output = FALSE,   test = NULL,   digits = getOption(\"jtools-digits\", default = 3) )"},{"path":"/reference/wgttest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test whether sampling weights are needed — wgttest","text":"model unweighted linear model (must lm, glm, see details types) want check. weights name weights column model's data frame vector weights equal length number observations included model. data data frame data fed fitted model weights model_output summary model weights predictor printed? Default FALSE since output can long complex models. test type test used ANOVA? default, NULL, chooses based model type (\"F\" linear models). argument passed anova. digits integer specifying number digits past decimal report output. Default 3. can change default number digits jtools functions options(\"jtools-digits\" = digits) digits desired number.","code":""},{"path":"/reference/wgttest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test whether sampling weights are needed — wgttest","text":"designed similar wgttest macro Stata (http://fmwww.bc.edu/repec/bocode/w/wgttest.html). method, advocated DuMouchel Duncan (1983), fairly straightforward. decide whether weights needed, weights added linear model predictor interaction predictor. , omnibus test significance performed compare weights-added model original; insignificant, weights significantly related result can use efficient estimation unweighted OLS. can helpful look created model using model_output = TRUE see variables might ones affected inclusion weights. test can support GLMs addition LMs, use validated Nordberg (1989). , knowledge, different Stata macro. work mixed models (e.g., lmer lme) though plausibly implemented. However, scholarly consensus properly incorporate weights mixed models. types models may work, tested. function designed compatible many model types possible, user careful make sure s/understands whether type test appropriate model considered. DuMouchel Duncan (1983) thinking linear regression test conceived. Nordberg (1989) validated use generalized linear models, author's knowledge tested model types.","code":""},{"path":"/reference/wgttest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Test whether sampling weights are needed — wgttest","text":"DuMouchel, W. H. & Duncan, D.J. (1983). Using sample survey weights multiple regression analyses stratified samples. Journal American Statistical Association, 78. 535-543. Nordberg, L. (1989). Generalized linear modeling sample survey data. Journal Official Statistics; Stockholm, 5, 223–239. Winship, C. & Radbill, L. (1994). Sampling weights regression analysis. Sociological Methods Research, 23, 230-257.","code":""},{"path":[]},{"path":"/reference/wgttest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test whether sampling weights are needed — wgttest","text":"","code":"# First, let's create some fake sampling weights wts <- runif(50, 0, 5) # Create model fit <- lm(Income ~ Frost + Illiteracy + Murder,           data = as.data.frame(state.x77)) # See if the weights change the model wgttest(fit, weights = wts) #> DuMouchel-Duncan test of model change with weights #>  #> F(4,42) = 0.908 #> p = 0.468 #>  #> Lower p values indicate greater influence of the weights. #>   # With a GLM wts <- runif(100, 0, 2) x <- rnorm(100) y <- rbinom(100, 1, .5) fit <- glm(y ~ x, family = binomial) wgttest(fit, wts) #> DuMouchel-Duncan test of model change with weights #>  #> Deviance (2) = 0.625 #> p = 0.732 #>  #> Lower p values indicate greater influence of the weights. #>  ## Can specify test manually wgttest(fit, weights = wts, test = \"Rao\") #> DuMouchel-Duncan test of model change with weights #>  #> Rao (2,96) = 0.624 #> p = 0.732 #>  #> Lower p values indicate greater influence of the weights. #>   # Quasi family is treated differently than likelihood-based ## Dobson (1990) Page 93: Randomized Controlled Trial (plus some extra values): counts <- c(18,17,15,20,10,20,25,13,12,18,17,15,20,10,20,25,13,12) outcome <- gl(3,1,18) treatment <- gl(3,6) glm.D93 <- glm(counts ~ outcome + treatment, family = quasipoisson) wts <- runif(18, 0, 3) wgttest(glm.D93, weights = wts) #> DuMouchel-Duncan test of model change with weights #>  #> F(5,8) = 0.167 #> p = 0.968 #>  #> Lower p values indicate greater influence of the weights. #>"},{"path":"/reference/wrap_str.html","id":null,"dir":"Reference","previous_headings":"","what":"cat, message, warning, and stop wrapped to fit the console's\nwidth. — wrap_str","title":"cat, message, warning, and stop wrapped to fit the console's\nwidth. — wrap_str","text":"convenience functions format printed output fit width user's console.","code":""},{"path":"/reference/wrap_str.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cat, message, warning, and stop wrapped to fit the console's\nwidth. — wrap_str","text":"","code":"wrap_str(..., sep = \"\")  cat_wrap(..., brk = \"\")  warn_wrap(..., brk = \"\\n\", class = NULL, call. = FALSE)  stop_wrap(   ...,   brk = \"\\n\",   trace = rlang::trace_back(bottom = rlang::caller_env()),   class = NULL,   call. = NULL )  msg_wrap(..., class = NULL, brk = \"\\n\")"},{"path":"/reference/wrap_str.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"cat, message, warning, and stop wrapped to fit the console's\nwidth. — wrap_str","text":"... Objects print. stop_wrap(), warn_wrap(), msg_wrap(), named objects instead diverted ... argument rlang::abort(), rlang::warn(), rlang::inform(), respectively. sep Separator ..., Default: '' brk last character message/warning/error ? Default \"\\n\", meaning console output ends new line. class Subclass condition. call. legacy reasons. ignored. trace trace object created trace_back().","code":""},{"path":"/reference/wrap_str.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"cat, message, warning, and stop wrapped to fit the console's\nwidth. — wrap_str","text":"point functions allow print output/messages/warnings/errors console without figure place newline characters. functions get width console \"width\" option, editors adjusts dynamically resize. instead writing warning like : can like : function automatically insert line breaks fit console. note, also ignore newlines insert. means can make fit editor's screen indent middle string without formatting carried output.","code":"warning(\"I have to give you this very important message that may be too\\n\",         \"wide for your screen\") warn_wrap(\"I have to give you this very important message that may be           too wide for your screen\")"},{"path":"/reference/wtd.sd.html","id":null,"dir":"Reference","previous_headings":"","what":"Weighted standard deviation calculation — wtd.sd","title":"Weighted standard deviation calculation — wtd.sd","text":"function calculates standard deviations weights counterpart built-weighted.mean function.","code":""},{"path":"/reference/wtd.sd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weighted standard deviation calculation — wtd.sd","text":"","code":"wtd.sd(x, weights)"},{"path":"/reference/wtd.sd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weighted standard deviation calculation — wtd.sd","text":"x vector values want standard deviation weights vector weights equal length x","code":""},{"path":"/news/index.html","id":"jtools-220","dir":"Changelog","previous_headings":"","what":"jtools 2.2.0","title":"jtools 2.2.0","text":"Accuracy bug fixes: pf_sv_test() calculating standard errors incorrectly previous versions jtools. corrected. Thanks Rebecca Andridge noticing . (#89) wtd.sd() now gives correct results data missing x weights. Thanks Klaus Langohr reporting issue. bug fixes: make_predictions() longer ignores int.type. (#116) scale_mod()/center_mod(), well summ()’s scale feature, longer error left-hand side model formula contains transformation. (#101) Pseudo-R^2 calculations now work family given string glm() function. (#92) Facetting now works plot_summs() always plot_coefs(). (#88) effect_plot() now recognizes color palettes provided colors argument (although get first color palette). Thanks Jed Brodie report. effect_plot() now applies color specified color points intervals. deprecates point.color argument now ignored warning. previously means users change color intervals. Thanks Jed Brodie report. %just%.list() now returns output. scale_mod() now works svyglm models offsets. Enhancements: plot_coefs() plot_summs() now allow change size points using point.size argument. (#61, #120) summ() now scale.argument supported models, allowing scale continuous variables without mean-centering . (#104) effect_plot() make_predictions() now handle binomial GLMs two-column response variable. (#100) Users may now choose points plot_coefs() plot_summs() passing vector shapes point.shape argument. (#71) Miscellaneous changes: gscale() (therefore scale_mod() center_mod()) longer convert binary factor variables numeric variables default. behavior can requested setting binary.factor = TRUE. (#114) summ() longer silently ignores cluster argument robust set FALSE. (#93)","code":""},{"path":"/news/index.html","id":"jtools-214","dir":"Changelog","previous_headings":"","what":"jtools 2.1.4","title":"jtools 2.1.4","text":"CRAN release: 2021-09-03 Fixed test error.","code":""},{"path":"/news/index.html","id":"jtools-213","dir":"Changelog","previous_headings":"","what":"jtools 2.1.3","title":"jtools 2.1.3","text":"CRAN release: 2021-03-12 Fixed encoding error movies dataset.","code":""},{"path":"/news/index.html","id":"jtools-212","dir":"Changelog","previous_headings":"","what":"jtools 2.1.2","title":"jtools 2.1.2","text":"CRAN release: 2021-01-07 Fixed minor error upcoming version R.","code":""},{"path":"/news/index.html","id":"jtools-211","dir":"Changelog","previous_headings":"","what":"jtools 2.1.1","title":"jtools 2.1.1","text":"CRAN release: 2020-11-16 Bugfixes: Fixed error writing file export_summs(). (#85) Fixed CRAN check issues changes quantreg package.","code":""},{"path":"/news/index.html","id":"jtools-210","dir":"Changelog","previous_headings":"","what":"jtools 2.1.0","title":"jtools 2.1.0","text":"CRAN release: 2020-06-23 New: new dataset, movies, added. gradually updating examples use movies rather R’s much-used, built-data. Bugfixes: effect_plot() longer ignores int.width argument. Thanks Marco Giesselmann reporting. (#82) Fixed failing CRAN test due brms deprecating bf_parse() function. Addressed breaking changes upcoming broom 0.7.0 release. (#83) make_predictions() associated dependencies packages now handles scale()’d variables correctly. (Issue #33 interactions package) Several functions now sensibly handle survey data replicate weights, also stops errors survey data classes srvyr package. Thanks Mark White reporting. (#84)","code":""},{"path":"/news/index.html","id":"jtools-205","dir":"Changelog","previous_headings":"","what":"jtools 2.0.5","title":"jtools 2.0.5","text":"CRAN release: 2020-04-21 Hotfix: Fixing failing tests CRAN.","code":""},{"path":"/news/index.html","id":"jtools-204","dir":"Changelog","previous_headings":"","what":"jtools 2.0.4","title":"jtools 2.0.4","text":"Hotfix release: latest version ggplot2 (3.3.0) broke theme_apa(). ’s fixed. theme_nice() now takes advantage new ggplot2 feature aligns captions better way. effect_plot() longer ignores colors argument. effect_plot() make_predictions() now work properly multivariate distributional brms models different set predictors different parts model.","code":""},{"path":"/news/index.html","id":"jtools-203","dir":"Changelog","previous_headings":"","what":"jtools 2.0.3","title":"jtools 2.0.3","text":"CRAN release: 2020-03-21 New features: effect_plot() plot_coefs() enhanced support brms models. may now use resp dpar arguments select dependent variables multivariate models well distributional parameters distributional models. new function, get_formula(). mostly internal helper function designed extract formulas objects like brmsfit class formula break internal functions.","code":""},{"path":"/news/index.html","id":"jtools-202","dir":"Changelog","previous_headings":"","what":"jtools 2.0.2","title":"jtools 2.0.2","text":"CRAN release: 2020-01-24 Minor release. Fixes: Pseudo-R^2 calculations now handle GLMs start values specified. (#63) effect_plot() longer silently ignores = argument. make_new_data() longer tries calculate control values variables included data model. documentation issue causing errors CRAN. changes: plot_coefs() plot_summs() can now accept list models input. (#64) make_predictions() functions depend (e.g., effect_plot()) now use fitted() get predicted values brmsfit objects, provide smoother predicted line expected.","code":""},{"path":"/news/index.html","id":"jtools-201","dir":"Changelog","previous_headings":"","what":"jtools 2.0.1","title":"jtools 2.0.1","text":"CRAN release: 2019-04-08 Minor release. Fixes: Satterthwaite Kenward-Roger degrees freedom used calculate p values linear merMod (.e., lmerMod) models summ, p values reported one-tailed — half actual value. t statistics standard errors correct. deprecated odds.ratio argument given summ(), users correctly warned deprecated argument exponentiated coefficients returned . Fixed error make_new_data()/make_predictions()/effect_plot() offsets specified formula variable included formula. make_predictions() partialize() handle missing data gracefully, especially original data tibble. changes: Added %just.list% %.list% S3 methods. %just% now sorts matches left-hand side order occur right-hand side. summ() (md_table()) now rely pander produce plain-text tables use pander’s \"multiline\" format default. Check \"grid\" another option. can change default using table.format set_summ_defaults(). stars (.e., significance stars) longer available summ(). partially due change printing tables via pander also keeping statistical best practices. predict_merMod(), used generating confidence intervals merMod model predictions make_predictions() effect_plot(), now user-accessible function. stop_wrap(), warn_wrap(), msg_wrap() now interface rlang package equivalents rather base stop() . End users may also take advantage rlang sub-classing abilities functions. summ() now passes extra arguments center_mod()/scale_mod(), allowing use functions’ advanced options.","code":""},{"path":"/news/index.html","id":"jtools-200","dir":"Changelog","previous_headings":"","what":"jtools 2.0.0","title":"jtools 2.0.0","text":"CRAN release: 2019-02-08 Big changes.","code":""},{"path":"/news/index.html","id":"new-spinoff-package-interactions-2-0-0","dir":"Changelog","previous_headings":"","what":"New spinoff package: interactions","title":"jtools 2.0.0","text":"reduce complexity package help people understand getting, removed functions directly analyze interaction/moderation effects put new package, interactions. still functions jtools support interactions, users may find everything ever used jtools now moved interactions. following functions moved interactions: interact_plot() cat_plot() sim_slopes() johnson_neyman() probe_interaction() Hopefully moving items separate package called interactions help people discover functions reduce confusion packages .","code":""},{"path":"/news/index.html","id":"important-changes-to-make_predictions-and-removal-of-plot_predictions-2-0-0","dir":"Changelog","previous_headings":"","what":"Important changes to make_predictions() and removal of plot_predictions()","title":"jtools 2.0.0","text":"jtools 1.0.0 release, introduced make_predictions() lower-level way emulate functionality effect_plot(), interact_plot(), cat_plot(). return list object predicted data, original data, bunch attributes containing information plot . One take object, class predictions, use main argument plot_predictions(), another new function creates plots see effect_plot() et al. simplified make_predictions() less specific plotting functions eliminated plot_predictions(), ultimately complex maintain caused problems separating interaction tools separate package. make_predictions() default simply creates new data frame predicted values along pred variable. longer accepts modx mod2 arguments. Instead, accepts argument called user can specify number variables values generate predictions . syntax designed similar predictions/margins packages. See documentation info revised syntax. make_new_data() new function supports make_predictions() creating data frame hypothetical values predictions added.","code":""},{"path":"/news/index.html","id":"generate-partial-residuals-for-plotting-2-0-0","dir":"Changelog","previous_headings":"","what":"Generate partial residuals for plotting","title":"jtools 2.0.0","text":"added new function, partialize(), creates partial residuals purposes plotting (e.g., effect_plot()). One negative visualizing predictions alongside original data effect_plot() similar tools observed data may spread pick patterns. However, sometimes model controlling causes scattering, especially multilevel models random intercepts. Partial residuals include effects controlled-variables let see well model performs things accounted . can plot partial residuals instead observed data effect_plot() via argument partial.residuals = TRUE get data using partialize(). also integrated make_predictions().","code":""},{"path":"/news/index.html","id":"new-programming-helpers-2-0-0","dir":"Changelog","previous_headings":"","what":"New programming helpers","title":"jtools 2.0.0","text":"keeping “tools” focus package, making available programming tools previously used internally inside jtools package.","code":""},{"path":"/news/index.html","id":"nin-not-and-just-2-0-0","dir":"Changelog","previous_headings":"New programming helpers","what":"%nin%, %not%, and %just%","title":"jtools 2.0.0","text":"Many familiar handy %% operator , sometimes want everything except values object. words, might want !(x %% y) instead x %% y. %nin% (“”) acts useful shortcut. Now, instead !(x %% y), can just use x %nin% y. Note actual implementation %nin% slightly different produce results quickly large data. may run packages also %nin% function , knowledge, functionally . One common uses %% %nin% want subset object. instance, assume x 1 5, y 3 7, want instances x y. Using %nin%, write x[x %nin% y], leaves 1 2. really don’t like write object’s name twice row like , created something simplify : %%. can now subset x parts y like : x %% y. Conversely, can equivalent x[x %% y] using %just% operator: x %just% y. special cases %% %just%, left-hand side matrix data frame, assumed right hand side column indices (numeric) column names (character). example, mtcars %just% c(\"mpg\", \"qsec\"), get data frame just “mpg” “qsec” columns mtcars. S3 method support can added additional object types developers.","code":""},{"path":"/news/index.html","id":"wrap_str-msg_wrap-warn_wrap-and-stop_wrap-2-0-0","dir":"Changelog","previous_headings":"New programming helpers","what":"wrap_str(), msg_wrap(), warn_wrap(), and stop_wrap()","title":"jtools 2.0.0","text":"irritation writing messages/warnings/errors users breaking long strings without unwanted line breaks output. One problem knowing wide user’s console . wrap_str() takes string inserts line breaks whatever “width” option set , automatically changes according actual width RStudio setups. means can write error message single string across multiple, perhaps indented, lines without line breaks indentations part console output. msg_wrap(), warn_wrap(), stop_wrap() wrap_str() wrappers (pun intended) around message(), warning(), stop(), respectively.","code":""},{"path":"/news/index.html","id":"other-changes-2-0-0","dir":"Changelog","previous_headings":"New programming helpers","what":"Other changes","title":"jtools 2.0.0","text":"summ() longer prints coefficient tables data frames caused RStudio notebook users issues output printed console notebook format less--ideal ways. tables now markdown format might remind Stata’s coefficient tables. function prints tables mentioned called md_table() can used others want. based knitr’s kable function. summ() longer prints significance stars default. can enabled stars = TRUE argument setting \"summ-stars\" option TRUE (also available via set_summ_defaults) model.check argument summ() removed. function called get_colors now available users. retrieves color palettes used jtools functions. Plots made jtools now new theme, can use , called theme_nice(). previous default, theme_apa(), still available don’t like default since don’t think APA defined nicest-looking design guidelines general use. effect_plot() now can plot categorical predictors, picking functionality previously provided cat_plot(). effect_plot() now uses tidy evaluation pred argument (#37). means can pass variable contains name pred, useful creating function, loop, etc. using variable, put !! rlang package (e.g., pred = !! variable). users, changes affect usage.","code":""},{"path":"/news/index.html","id":"bugfixes-2-0-0","dir":"Changelog","previous_headings":"New programming helpers","what":"Bugfixes","title":"jtools 2.0.0","text":"make_predictions() (extension effect_plot() plotting functions interactions package) now understands dependent variable transformations better. instance, shouldn’t issues response variable log(y) instead y. returning original data frame, functions append transformed (e.g., log(y)) column needed. lme4 bug generating predictions models offsets — ignores offset specified via offset = argument. created workaround .","code":""},{"path":"/news/index.html","id":"jtools-111","dir":"Changelog","previous_headings":"","what":"jtools 1.1.1","title":"jtools 1.1.1","text":"CRAN release: 2018-09-23 minor release.","code":""},{"path":"/news/index.html","id":"bug-fixes-1-1-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"jtools 1.1.1","text":"plot_predictions() incorrect default value interval, causing error used default arguments make_predictions(). default now FALSE. (#39) interact_plot(), cat_plot(), effect_plot() errors models included covariates (involved interaction, ) non-numeric. corrected. (#41) Logical variables (values TRUE FALSE) handled plotting functions appropriately, causing treated numeric. now preserved logical. (#40). sim_slopes() gave inaccurate results factor moderators treatment coding (\"contr.treatment\") now recoded treatment coding.","code":""},{"path":"/news/index.html","id":"other-changes-1-1-1","dir":"Changelog","previous_headings":"","what":"Other changes","title":"jtools 1.1.1","text":"summ() output RMarkdown documents now powered kableExtra, (opinion) offers attractive HTML output seems better luck float placement PDF documents. mileage may vary. 2 vignettes now made rmdformats rather base rmarkdown template. S3 methods S3 generics aren’t imported package (tidy glance broom, knit_print knitr, as_huxtable huxtable) now conditional namespace registration users R 3.6. shouldn’t much effect end users.","code":""},{"path":"/news/index.html","id":"jtools-110","dir":"Changelog","previous_headings":"","what":"jtools 1.1.0","title":"jtools 1.1.0","text":"CRAN release: 2018-08-16 release initially intended bugfix release, enough things came make minor release.","code":""},{"path":"/news/index.html","id":"bug-fixes-1-1-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"jtools 1.1.0","text":"Suppressed number warning messages caused broom update using export_summs() plot_coefs(). Fixed error plot_coefs() arising latest update ggplot2. Fixed new bug introduced 1.0.0 wherein points weighted data sized according weight. Fixed issue pseudo-R^2 calculation non-interactive use. [#34] Pseudo-R^2 now included export_summs() output glm models. [#36] interact_plot() longer errors missing observations original data quantiles requested.","code":""},{"path":"/news/index.html","id":"new-features-1-1-0","dir":"Changelog","previous_headings":"","what":"New features","title":"jtools 1.1.0","text":"summ.merMod, default p-value calculation now via Satterthwaite method lmerTest installed. old default, Kenward-Roger, used request pbkrtest installed lmerTest. now calculates different degrees freedom predictor also calculates variance-covariance matrix model, meaning standard errors adjusted well. default largely computation takes long many models. johnson_neyman() now allows specify critical t value using alternate method calculate . johnson_neyman() now allows specify range moderator values want plot well setting title. Users may now label values sim_slopes() way similar interact_plot(). [#35] Users may provide labels preset moderator values interact_plot() (e.g., modx.values = \"plus-minus\"). [#31] plot_coefs()/plot_summs() now supports facetting coefficients based user-specified groupings. See ?plot_summs details. summ() variants now pretty output RMarkdown documents huxtable package installed. can disabled chunk option render = 'normal_print'.","code":""},{"path":"/news/index.html","id":"interface-changes-1-1-0","dir":"Changelog","previous_headings":"","what":"Interface changes","title":"jtools 1.1.0","text":"interaction functions now use modx.values, mod2.values, pred.values place modxvals, mod2vals, predvals. Don’t go running change code, though; old argument names still work, new ones clearer preferred new code.","code":""},{"path":"/news/index.html","id":"new-functions-1-1-0","dir":"Changelog","previous_headings":"","what":"New functions","title":"jtools 1.1.0","text":"now plot() method sim_slopes objects. Just save sim_slopes() call object call plot() function object see happens. Basically, ’s plot_coefs() sim_slopes(). huxtable installed, can now call as_huxtable sim_slopes() object get publication-style table. interface comparable export_summs().","code":""},{"path":"/news/index.html","id":"jtools-100","dir":"Changelog","previous_headings":"","what":"jtools 1.0.0","title":"jtools 1.0.0","text":"CRAN release: 2018-05-08","code":""},{"path":"/news/index.html","id":"major-release-1-0-0","dir":"Changelog","previous_headings":"","what":"Major release","title":"jtools 1.0.0","text":"release several big changes embedded within, side projects needed lot work implement required user-facing changes. Overall improvements, edge cases break old code. following sections divided affected functions. functions discussed one section.","code":""},{"path":"/news/index.html","id":"interact_plot-cat_plot-and-effect_plot-1-0-0","dir":"Changelog","previous_headings":"Major release","what":"interact_plot(), cat_plot(), and effect_plot()","title":"jtools 1.0.0","text":"functions longer re-fit inputted model center covariates, impose labels factors, . generally several key positives, including Major speed gains (15% faster small lm models, 60% svyglm, 80% merMod testing). speed gains increase models become complicated source data become larger. model types supported. past, models failed update method defined correctly information needed refit model can provided functions. complicated formula input supported, caveat. , instance, log-transformed predictor (log) formula, function previously lot trouble usually errors. Now supported, provided input data used fit model via data argument. ’ll receive warning function thinks needed work right. noted, new data argument functions. normally need use model fit y ~ x + z type formula. start things like y ~ factor(x) + z, need provide source data frame. Another benefit allows fitting polynomials effect_plot() even interactions polynomials interact_plot(). instance, model fit using kind formula — y ~ poly(x, 2) + z — plot predicted curve effect_plot(fit, pred = x, data = data) substituting fit whatever model called data whatever data frame used called. possible drawbacks changes. One longer factor predictors supported interact_plot() effect_plot(), even two-level ones. worked coercing 0/1 continuous variables re-fitting model. Since model longer re-fit, can’t done. work around , either transform predictor numeric fitting model use cat_plot(). Relatedly, two-level factor covariates longer centered simply set reference value. Robust confidence intervals: Plotting robust standard errors compatible models (tested lm, glm). Just use robust argument like sim_slopes() summ(). Preliminary support confidence intervals merMod models: may now get confidence intervals using merMod objects input plotting functions. importance, though, uncertainty fixed effects. now, warning printed. See next section another option merMod confidence intervals. Rug plots margins: -called “rug” plots can included margins plots functions. show tick marks observed data points, giving non-obtrusive impression distribution pred variable (optionally) dependent variable. See documentation interact_plot() effect_plot() rug/rug.sides arguments. Facet modx variable: prefer visualize predicted lines separate panes, now option available via facet.modx argument. can also use plot.points , though division groups straightforward moderator isn’t factor. See documentation done.","code":""},{"path":"/news/index.html","id":"make_predictions-and-plot_predictions-new-tools-for-advanced-plotting-1-0-0","dir":"Changelog","previous_headings":"Major release","what":"make_predictions() and plot_predictions(): New tools for advanced plotting","title":"jtools 1.0.0","text":"let users flexibility, jtools now lets users directly access (previously internal) functions make effect_plot(), cat_plot(), interact_plot() work. make easier tailor outputs specific needs. features may implemented functions keep _plot functions getting complicated already . simplest use two functions use make_predictions() just like effect_plot()/interact_plot()/cat_plot(). difference , course, make_predictions() makes data used plotting. resulting predictions object predicted original data well attributes describing arguments used. pass object plot_predictions() arguments, exactly corresponding _plot function . However, might want something entirely different using predicted data part reason functions separate. One feature specific make_predictions() bootstrap confidence intervals merMod models.","code":""},{"path":"/news/index.html","id":"all-interaction-tools-1-0-0","dir":"Changelog","previous_headings":"Major release","what":"All interaction tools","title":"jtools 1.0.0","text":"may longer use tools scale models. Use scale_mod(), save resulting object, use input functions want scaling. tools new default centered argument. now set centered = \"\", \"\" longer means used . Now refers variables included interaction, including dependent variable. means effect, default option thing previous versions . instead occur centered = NULL, ’s centered = \"\" means. NULL option longer. Note sim_slopes(), focal predictor (pred) now centered — affects conditional intercept.","code":""},{"path":"/news/index.html","id":"sim_slopes-1-0-0","dir":"Changelog","previous_headings":"Major release","what":"sim_slopes()","title":"jtools 1.0.0","text":"function now supports categorical (factor) moderators, though option Johnson-Neyman intervals cases. can use significance interaction term(s) inference whether slopes differ level factor moderator factor. may now also pass arguments summ(), used internally calculate standard errors, p values, etc. particularly useful using merMod model pbkrtest-based p value calculation time-consuming.","code":""},{"path":"/news/index.html","id":"gscale-1-0-0","dir":"Changelog","previous_headings":"Major release","what":"gscale()","title":"jtools 1.0.0","text":"interface changed slightly, actual numbers always provided data argument. x argument instead vars argument can provide variable names. upshot now fits much better piping workflow. entire function gotten extensive reworking, cases result significant speed gains. ’s enough, just know code absolute monstrosity now ’s . two new functions wrappers around gscale(): standardize() center(), call gscale() n.sd = 1 first case center.= TRUE latter case.","code":""},{"path":"/news/index.html","id":"summ-1-0-0","dir":"Changelog","previous_headings":"Major release","what":"summ()","title":"jtools 1.0.0","text":"Tired specifying preferred configuration every time use summ()? Now, many arguments default check options can set defaults. See ?set_summ_defaults info. Rather separate scale.response center.response arguments, summ() function now uses transform.response collectively cover bases. Whether response centered scaled depends scale center arguments. robust.type argument deprecated. Now, provide type robust estimator directly robust. now, robust = TRUE, defaults \"HC3\" warning. Better provide argument directly, e.g., robust = \"HC3\". robust = FALSE still fine using OLS/MLE standard errors. Whereas summ.glm, summ.svyglm, summ.merMod previously offered odds.ratio argument, renamed exp (short exponentiate) better express quantity. vifs now works factor variables model. One first bugs summ() ever occurred function given rank-deficient model. straightforward detect, especially since need make space almost empty row outputted table. long last, release can handle models gracefully. Like rest R, summ() rounded output, items rounded exactly zero treated , well, zero. can misleading original value actually negative. instance, digits = 2 coefficient -0.003, value printed console 0.00, suggesting zero slightly positive value fact opposite. limitation round (trunc) function. ’ve now changed zero-rounded value retains sign. summ.merMod now calculates pseudo-R^2 much, much faster. modestly complex models, speed-roughly 50x faster. much faster now much less frequently throws errors prints cryptic messages, now calculated default. confidence interval calculation now “Wald” models (see confint.merMod details) rather “profile”, many models can take long time sometimes work . can toggled conf.method argument. summ.glm/summ.svyglm now calculate pseudo-R^2 quasibinomial quasipoisson families using value obtained refitting binomial/poisson. now, ’m touching AIC/BIC models underlying theory bit different implementation challenging. summ.lm now uses t-distribution finding critical values confidence intervals. Previously, normal approximation used. summ.default method removed. becoming absolute terror maintain doubted anyone found useful. ’s hard provide value added models type know (robust errors don’t always apply, scaling doesn’t always work, model fit statistics may make sense, etc.). Bug really upset things . One new model type supported: rq models quantreg package. Please feel free provide feedback output support models.","code":""},{"path":"/news/index.html","id":"scale_lm-and-center_lm-are-now-scale_modcenter_mod-1-0-0","dir":"Changelog","previous_headings":"Major release","what":"scale_lm() and center_lm() are now scale_mod()/center_mod()","title":"jtools 1.0.0","text":"better reflect capabilities functions (restricted lm objects), renamed. old names continue work preserve old code. However, scale.response center.response now default FALSE reflect fact OLS models can support transformations dependent variable way. new vars = argument scale_mod() allows apply scaling whichever variables included character vector. ’ve also implemented neat technical fix allows updated model updated also including actual raw data model call.","code":""},{"path":"/news/index.html","id":"plot_coefs-and-plot_summs-1-0-0","dir":"Changelog","previous_headings":"Major release","what":"plot_coefs() and plot_summs()","title":"jtools 1.0.0","text":"variety fixes optimizations added functions. Now, default, two confidence intervals plotted, thick line representing (default settings) 90% interval thinner line 95% intervals. can set inner_ci_level NULL get rid thicker line. plot_summs(), can also set per-model summ() arguments providing argument vector (e.g., robust = c(TRUE, FALSE)). Length 1 arguments applied models. plot_summs() now also support models accepted summ() just passing models plot_coefs() without using summ() . Another new option point.shape, similar model plotting functions. useful planning distribute output grayscale colorblind audiences (although new default color scheme meant colorblind friendly, always best use another visual cue). coolest new plot.distributions argument, TRUE plot normal distributions even better convey uncertainty. course, use judiciously modeling estimation approach doesn’t produce coefficient estimates asymptotically normally distributed. Inspiration comes https://twitter.com/BenJamesEdwards/status/979751070254747650. Minor fixes: broom’s interface Bayesian methods inconsistent, ’ve hacked together tweaks make brmsfit stanreg models work plot_coefs(). ’ll also notice vertical gridlines plots, think/hope useful. easily removable (see drop_x_gridlines()) ggplot2’s built-theming options.","code":""},{"path":"/news/index.html","id":"export_summs-1-0-0","dir":"Changelog","previous_headings":"Major release","what":"export_summs()","title":"jtools 1.0.0","text":"Changes major. Like plot_summs(), can now provide unsupported model types export_summs() just passed huxreg. can also provide different arguments summ() per-model basis way described plot_summs() heading . tweaks model info (provided glance). prominent merMod models, now separate N grouping factor.","code":""},{"path":"/news/index.html","id":"theme_apa-plus-new-functions-add_gridlines-drop_gridlines-1-0-0","dir":"Changelog","previous_headings":"Major release","what":"theme_apa() plus new functions add_gridlines(), drop_gridlines()","title":"jtools 1.0.0","text":"New arguments added theme_apa(): remove.x.gridlines remove.y.gridlines, TRUE default. APA hates giving hard fast rules, norm gridlines omitted unless crucial interpretation. theme_apa() also now “complete” theme, means specifying options via theme revert theme_apa()’s changes base theme. Behind scenes helper functions add_gridlines() drop_gridlines() used, sound like . avoid using arguments functions, can also use add_x_gridlines()/add_y_gridlines() drop_x_gridlines()/drop_y_gridlines() wrappers around general functions.","code":""},{"path":"/news/index.html","id":"survey-tools-1-0-0","dir":"Changelog","previous_headings":"Major release","what":"Survey tools","title":"jtools 1.0.0","text":"weights_tests() — wgttest() pf_sv_test() — now handle missing data sensible consistent way.","code":""},{"path":"/news/index.html","id":"colors-1-0-0","dir":"Changelog","previous_headings":"Major release","what":"Colors","title":"jtools 1.0.0","text":"new default qualitative palette, based Color Universal Design (designed readable colorblind) looks great . several new palette choices well. documented ?jtools_colors","code":""},{"path":"/news/index.html","id":"other-stuff-1-0-0","dir":"Changelog","previous_headings":"Major release","what":"Other stuff","title":"jtools 1.0.0","text":"Using crayon package backend, console output now formatted jtools functions better readability supported systems. Feedback welcome since might look better worse certain editors/setups.","code":""},{"path":"/news/index.html","id":"jtools-094-cran-release","dir":"Changelog","previous_headings":"","what":"jtools 0.9.4 (CRAN release)","title":"jtools 0.9.4 (CRAN release)","text":"CRAN release: 2018-02-13 release limited dealing huxtable package’s temporary removal CRAN, turn makes package compliance CRAN policies regarding dependencies non-CRAN packages. Look jtools 1.0.0 coming soon!","code":""},{"path":"/news/index.html","id":"jtools-093-cran-release","dir":"Changelog","previous_headings":"","what":"jtools 0.9.3 (CRAN release)","title":"jtools 0.9.3 (CRAN release)","text":"CRAN release: 2018-01-28 Bugfixes: johnson_neyman() sim_slopes() encountering errors merMod input. Thanks Seongho Bae reporting issues testing development versions. upcoming version R change common warning error, causing need change internals gscale. default model names export_summs() extra space (e.g., ( 1)) due changes huxtable. defaults now just single numbers.","code":""},{"path":"/news/index.html","id":"jtools-092","dir":"Changelog","previous_headings":"","what":"jtools 0.9.2","title":"jtools 0.9.2","text":"Bugfix: Johnson-Neyman plots misreported alpha level control.fdr TRUE. reporting alpha * 2 legend, now accurate . Feature update: johnson_neyman() now handles multilevel models lme4.","code":""},{"path":"/news/index.html","id":"jtools-091-cran-release","dir":"Changelog","previous_headings":"","what":"jtools 0.9.1 (CRAN release)","title":"jtools 0.9.1 (CRAN release)","text":"CRAN release: 2018-01-05 Bugfix update: Jonas Kunst helpfully pointed odd behavior interact_plot() factor moderators. longer occasions two different legends appear. linetype colors also now consistent whether second moderator . continuous moderators, darkest line also solid line default highest value moderator. fixes: update huxtable broke export_summs(), fixed. Feature updates: can now manually provide colors interact_plot() cat_plot() providing vector colors (format ggplot2 accepts) color.class argument. Noah Greifer wrote tweak summ() formats output way lines decimal points. looks great.","code":""},{"path":"/news/index.html","id":"jtools-090-cran-release","dir":"Changelog","previous_headings":"","what":"jtools 0.9.0 (CRAN release)","title":"jtools 0.9.0 (CRAN release)","text":"CRAN release: 2017-11-12 may single biggest update yet. downloaded CRAN, sure check 0.8.1 update well. New features organized function. johnson_neyman(): new control.fdr option added control false discovery rate, building new research. makes test conservative less likely Type 1 error. line.thickness argument added Heidi Jacobs pointed changed fact. construction multiple plots using sim_slopes() 3-way interactions much-improved. critical test statistic used default slightly altered. previously used normal approximation; .e., alpha = .05 critical test statistic always 1.96. Now, residual degrees freedom used t distribution. can old way setting df = \"normal\" arbitrary number. interact_plot(): improvements plot.points (see 0.8.1 ). can now plot observed data 3-way interactions. Another pre-set modxvals mod2vals specification added: \"terciles\". splits observed data 3 equally sized groups chooses values mean groups. especially good skewed data second moderators. new linearity.check option two-way interactions. facets level moderator lets compare fitted line loess smoothed line ensure interaction effect roughly linear level (continuous) moderator. model used weights, like survey sampling weights, observed data points resized according observation’s weight plot.points = TRUE. New jitter argument added using plot.points. don’t want points jittered, can set jitter = 0. want less, can play value looks right. applies effect_plot() well. summ(): Users now informed function taking long r.squared pbkrtest slowing things . r.squared now set FALSE default. New functions! plot_summs(): graphic counterpart export_summs(), introduced 0.8.0 release. plots regression coefficients help visualizing uncertainty estimate facilitates plotting nested models alongside comparison. allows use summ() features like robust standard errors scaling type plot otherwise create packages. plot_coefs(): Just like plot_summs(), special summ() features. allows use models unsupported summ(), however, can provide summ() objects plot model different summ() argument alongside . cat_plot(): long time coming. complementary function interact_plot(), designed deal interactions categorical variables. can use bar plots, line plots, dot plots, box whisker plots . can also use function plot effect single categorical predictor without interaction.","code":""},{"path":"/news/index.html","id":"jtools-081","dir":"Changelog","previous_headings":"","what":"jtools 0.8.1","title":"jtools 0.8.1","text":"Thanks Kim Henry reported bug johnson_neyman() case interval, entire interval outside plotted area: happened, legend wrongly stated plotted line non-significant. Besides bugfix, new features: johnson_neyman() fails find interval (doesn’t exist), longer quits error. output just state interval found plot still created. Much better support plotting observed data interact_plot() added. Previously, moderator factor, get nicely colored plotted points using plot.points = TRUE. moderator continuous, points just black wasn’t informative beyond examining main effect focal predictor. update, plotted points continuous moderators shaded along gradient matches colors used predicted lines confidence intervals.","code":""},{"path":"/news/index.html","id":"jtools-080-cran-release","dir":"Changelog","previous_headings":"","what":"jtools 0.8.0 (CRAN release)","title":"jtools 0.8.0 (CRAN release)","text":"CRAN release: 2017-10-10 many user-facing changes since 0.7.4, major refactoring internally speed things make future development smoother.","code":""},{"path":"/news/index.html","id":"jtools-074","dir":"Changelog","previous_headings":"","what":"jtools 0.7.4","title":"jtools 0.7.4","text":"Bugfixes: interact_plot() effect_plot() trip one focal predictors name subset covariate (e.g., pred = “var” covariate called “var_2”). ’s fixed. Confidence intervals merMod objects respecting user-requested confidence level fixed. Confidence intervals merMod objects throwing spurious warning R 3.4.2. interact_plot() mis-ordering secondary moderators. fixed. export_summs() major performance problem providing extra arguments may also caused wrongly ignore arguments. fixed much faster. Enhancements: * interact_plot() now gives informative labels secondary moderators user defined values labels. * confidence intervals now properly supported export_summs() * changes made export_summs() compatibility huxtable 1.0.0 changes","code":""},{"path":"/news/index.html","id":"jtools-073-cran-release","dir":"Changelog","previous_headings":"","what":"jtools 0.7.3 (CRAN release)","title":"jtools 0.7.3 (CRAN release)","text":"CRAN release: 2017-10-02 Important bugfix: standardize set TRUE using summ(), model mean-centered output stated. fixed. truly regret error—double-check analyses may run feature. New function: export_summs(). function outputs regression models supported summ() table formats useful RMarkdown output well specific options exporting Microsoft Word files. particularly helpful wanting efficient way export regressions standardized /use robust standard errors.","code":""},{"path":"/news/index.html","id":"jtools-072","dir":"Changelog","previous_headings":"","what":"jtools 0.7.2","title":"jtools 0.7.2","text":"documentation j_summ() reorganized supported model type , separate documentation. ?j_summ now just give links supported model type. importantly, j_summ() now referred , simply, summ(). old code fine; j_summ() now alias summ() run underlying code. Documentation refer summ() function, though. includes updated vignette. One new feature summ.lm: part.corr = TRUE argument linear model, partial semipartial correlations variable reported. tweaks summ.merMod: Default behavior regard p values depends model type (lmer() vs. glmer()/nlmer()) , case linear models, whether pbkrtest package installed. , p values calculated based Kenward-Roger degrees freedom calculation printed. Otherwise, p values shown default lmer() models. p values shown glmer() models, since also default behavior lme4. r.squared option, now FALSE default. adds runtime since must fit null model comparison sometimes also causes convergence issues.","code":""},{"path":"/news/index.html","id":"jtools-071","dir":"Changelog","previous_headings":"","what":"jtools 0.7.1","title":"jtools 0.7.1","text":"CRAN release: 2017-09-15 Returning CRAN! strange bug CRAN’s servers causing jtools updates silently fail submitted updates; ’d get confirmation passed tests, LaTeX error related Indian journal cited torpedoing reached CRAN servers. change 0.7.0 fixing problem, ’re CRAN user want flip past several releases well see ’ve missed.","code":""},{"path":"/news/index.html","id":"jtools-070","dir":"Changelog","previous_headings":"","what":"jtools 0.7.0","title":"jtools 0.7.0","text":"New features: j_summ() can now provide cluster-robust standard errors lm models. j_summ() output now gives info missing observations supported models. long last, j_summ()/scale_lm()/center_lm() can standardize/center models logged terms functions applied. interact_plot() effect_plot() now also support predictors functions applied . j_summ() now supports confidence intervals user-specified widths. j_summ() now allows users display p-values requested. ’ve added warning j_summ() output merMod objects, since provides p-values calculated basis estimated t-values. interpreted way OLS GLM p-values , since smaller samples mixed model t-values give inflated Type error rates. default, j_summ() show p-values merMod objects. Bug fix: scale_lm() center argument implemented explain option well documentation. johnson_neyman() got confused factor variable given predictor","code":""},{"path":"/news/index.html","id":"jtools-061","dir":"Changelog","previous_headings":"","what":"jtools 0.6.1","title":"jtools 0.6.1","text":"Bug fix release: wgttest() acted way might unexpected providing weights variable name data argument. Now work expected getting data frame model call. gscale() situations choked missing data, especially weights used. turn affected j_summ(), scale_lm(), center_lm(), rely gscale() standardization mean-centering. ’s fixed now. gscale() wasn’t playing nicely binary factors survey designs, rendering scaling incorrect. saw warning, re-check outputs update.","code":""},{"path":"/news/index.html","id":"jtools-060","dir":"Changelog","previous_headings":"","what":"jtools 0.6.0","title":"jtools 0.6.0","text":"lot changes! New functions: effect_plot(): like visualization moderation effects interact_plot(), enjoy effect_plot(). clone interact_plot(), shows single regression line rather several. supports GLMs lme4 models can plot original, observed data points. pf_sv_test(): Another tool survey researchers test whether ’s okay run unweighted regressions. Named Pfeffermann Sverchkov, devised test. weights_tests(): Like probe_interaction() interaction functions, weights_tests() run new pf_sv_test() well wgttest() simultaneously common set arguments. Enhancements: Set default number digits print jtools functions option \"jtools-digits\". wgttest() now accepts tests GLMs may work regression models. Bug fixes: j_summ() print significance stars based rounded p value, sometimes resulting misleading output. Now significance stars based non-rounded p values. probe_interaction() pass “alpha” argument sim_slopes(), possibly confusing users johnson_neyman(). argument sim_slopes() looking called \"jnalpha\". Now probe_interaction pass \"alpha\" arguments \"jn_alpha\". interact_plot() stop error model included two-level factor involved interaction centered. Now factors situation treated like factors. interact_plot() sometimes gave misleading output users manually defined moderator labels. now consistent ordering labels values wrongly label values provided odd order. wgttest() now functions properly vector weights provided weights argument rather column name. gscale() now works properly tibbles, requires different style column indexing data frames. Related prior point, j_summ()/standardize_lm()/center_lm() now work properly models originally fit tibbles data argument. sim_slopes() fail certain weighted lm objects depending way weights specified function call. now work weighted lm objects.","code":""},{"path":"/news/index.html","id":"jtools-050","dir":"Changelog","previous_headings":"","what":"jtools 0.5.0","title":"jtools 0.5.0","text":"CRAN release: 2017-08-08 goodies users interact_plot(): Added support models weights parameter interact_plot(). work previously, didn’t use weighted mean SD calculating values moderator(s) mean-centering predictors. Now . Added support two-level factor predictors interact_plot(). Previously, factor variables moderator. predictor interact_plot() two unique values (e.g., dummy variables numeric class), default two values tick marks x-axis. Users may use pred.labels argument specify labels ticks. Offsets now supported (especially useful Poisson GLMs), specified via offset argument rather included model formula. can () specify offset used plot using set.offset argument. default 1 y-axis represents proportion. feature changes: sim_slopes() now supports weights (weights argument rather svyglm model). Previously used unweighted mean standard deviation non-survey models weights. Improved printing features wgttest(). Bug fixes: R 3.4 introduced change caused warning messages return objects created certain way. first addressed jtools 0.4.5, instances slipped cracks. Thanks Kim Henry pointing one instance. sim_slopes() called johnson_neyman() robust argument set TRUE, robust.type argument passed (causing default “HC3” used). Now passing argument correctly.","code":""},{"path":"/news/index.html","id":"jtools-045","dir":"Changelog","previous_headings":"","what":"jtools 0.4.5","title":"jtools 0.4.5","text":"CRAN release: 2017-05-24 Added better support plotting nonlinear interactions interact_plot(), providing option plot original (nonlinear) scale. interact_plot() can now plot fixed effects interactions merMod objects Fixed warning messages using j_summ() R 3.4.x Added preliminary merMod support j_summ(). Still needs convergence warnings, items.","code":""},{"path":"/news/index.html","id":"jtools-044","dir":"Changelog","previous_headings":"","what":"jtools 0.4.4","title":"jtools 0.4.4","text":"CRAN release: 2017-03-26 hood changes j_summ() Cleaned examples Added wgttest() function, runs test assess need sampling weights linear regression","code":""},{"path":"/news/index.html","id":"jtools-043","dir":"Changelog","previous_headings":"","what":"jtools 0.4.3","title":"jtools 0.4.3","text":"matter , ’s nothing like seeing package CRAN open eyes typos, etc. ’ve put package.","code":""},{"path":"/news/index.html","id":"jtools-042--initial-cran-release","dir":"Changelog","previous_headings":"","what":"jtools 0.4.2 — Initial CRAN release","title":"jtools 0.4.2 — Initial CRAN release","text":"CRAN release: 2017-02-27 first CRAN release. Compared 0.4.1, prior Github release, dependencies removed several functions optimized speed.","code":""}]
